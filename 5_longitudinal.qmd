---
title: "Longitudinal models"
format: 
  html:
    toc: true
execute: 
  cache: true
---

Notes from Nilam:
Look at this part of the latent growth tutorial #observed residual variances (constrained to equality)- math2 ~~ sigma2_u*math2

the two-wave model:
change in inter-individual differences
vs. differences in intra-individual change


This markdown documents attempts to do longitudinal models for the Peekbank data.

```{r}
library(here)
source(here("helper","common.R"))
library(lavaan)
library(tidySEM)

d_sub <- readRDS(here("cached_intermediates","1_d_sub.Rds")) |>
  group_by(subject_id) |>
  arrange(age) |>
  mutate(admin_num = 1:n(), 
         time_since_t0 = age - age[1],
         delta_t = c(0, diff(age)))

```

```{r}
longitudinal <- d_sub |>
  group_by(dataset_name, subject_id) |>
  count() |>
  filter(n > 1)

d_sub_long <- d_sub |>
  filter(subject_id %in% longitudinal$subject_id) 

ggplot(d_sub_long, 
       aes(x = time_since_t0, fill = dataset_name)) +
  geom_histogram(binwidth = 1) + 
  # facet_wrap(~dataset_name) + 
  xlab("Time since first test")
```

# Reliability


How to do this right? WRONG RIGHT NOW

```{r}
MONTH_CUTOFF <- 3

d_reliability <- d_sub_long |>
  filter(admin_num <= 2) |>
  pivot_wider(id_cols = c("subject_id","dataset_name"), 
              names_from = "admin_num",
              values_from = c("log_rt", "log_rt_var", "long_window_accuracy", 
                              "long_window_acc_var", "prod", "comp"))

dataset_reliabilities <- d_reliability |>
  group_by(dataset_name) |>
  summarise(rt = cor(log_rt_1, log_rt_2, use = "pairwise.complete.obs"),
            acc = cor(long_window_accuracy_1, 
                          long_window_accuracy_2, use = "pairwise.complete.obs")) |>
  filter(dataset_name != "fernald_totlot") 
```


# Longitudinal factor analysis


```{r}
d_sub_s <- d_sub |>
  ungroup() |>
  select(dataset_name, subject_id, administration_id, age, 
         time_since_t0, delta_t,
         log_rt, log_rt_var, 
         long_window_accuracy, long_window_acc_var, prod, comp, ) |>
  rename(acc = long_window_accuracy, 
         acc_sd = long_window_acc_var, 
         log_rt_sd = log_rt_var) |>
  ungroup() |>
  mutate(across(all_of(c("log_rt", "log_rt_sd", "acc", "acc_sd", 
                         "prod", "comp")), 
                       ~ age_scale(.x, age))) 
```

Check on amount of data.


# Two-time point

```{r}
d_sub_wide <- d_sub_s |> 
  mutate(t = cut(time_since_t0, breaks = c(0, 3, 6, 30), 
                 include.lowest = TRUE)) |>
  filter(t != "(6,30]") |>
  mutate(t = as.numeric(t)) |>
  group_by(subject_id, dataset_name, t) |>
  summarise(across(all_of(c("log_rt", "log_rt_sd", "acc",
                            "acc_sd", "prod", "comp")),
                   ~ mean(.x, na.rm=TRUE))) |> 
  mutate(across(all_of(c("log_rt", "log_rt_sd", "acc",
                         "acc_sd", "prod", "comp")),
                ~ ifelse(is.nan(.x), NA, .x))) |>
  pivot_wider(id_cols = c("subject_id","dataset_name"), 
              names_from = "t",
              values_from = c("log_rt", "log_rt_sd", "acc", 
                              "acc_sd", "prod", "comp"), 
              names_prefix = "t")

d_sub_wide |>
  ungroup() |>
  summarise(across(log_rt_t1:comp_t2, 
                   ~sum(!is.na(.x))))
```


```{r}
fa3_model_long <- "
# measurement model
vocab_t1 =~ 1*prod_t1 + s1*comp_t1
accuracy_t1 =~ 1*acc_t1 + s2*acc_sd_t1
speed_t1 =~ 1*log_rt_t1 + s3*log_rt_sd_t1

vocab_t2 =~ 1*prod_t2 + s1*comp_t1
accuracy_t2 =~ 1*acc_t2 + s2*acc_sd_t2
speed_t2 =~ 1*log_rt_t2 + s3*log_rt_sd_t2

# longitudinal relationships
vocab_t2 ~ vocab_t1 + speed_t1 + accuracy_t1
speed_t2 ~ vocab_t1 + speed_t1 + accuracy_t1
accuracy_t2 ~ vocab_t1 + speed_t1 + accuracy_t1

# factor covariances
vocab_t1 ~~ accuracy_t1
vocab_t1 ~~ speed_t1
accuracy_t1 ~~ speed_t1

vocab_t2 ~~ accuracy_t2
vocab_t2 ~~ speed_t2
accuracy_t2 ~~ speed_t2

# means for the latents
vocab_t1 ~ 1
vocab_t2 ~ 1
accuracy_t1 ~ 1
accuracy_t2 ~ 1
speed_t1 ~ 1
speed_t2 ~ 1

# residual variance for the latents
vocab_t1 ~~ NA*vocab_t1
vocab_t2 ~~ NA*vocab_t2
accuracy_t1 ~~ NA*accuracy_t1
accuracy_t2 ~~ NA*accuracy_t2
speed_t1 ~~ NA*speed_t1
speed_t2 ~~ NA*speed_t2
"

fit3_long <- sem(fa3_model_long, d_sub_wide, std.lv=TRUE, missing='fiml')

summary(fit3_long, fit.measures=TRUE, standardize=TRUE)


```
```{r}
layout_long = matrix(nrow=7, ncol = 7,
                     data = c("log_rt_sd_t1","log_rt_t1", "acc_t1", "acc_sd_t1", "prod_t1","comp_t1", NA,
                               NA, NA, NA, NA, NA, NA,  NA,
                              "speed_t1",NA,"accuracy_t1",NA,"vocab_t1",NA,  NA,
                              NA, NA, NA, NA, NA, NA,  NA,
                               NA,"speed_t2",NA,"accuracy_t2",NA,NA,"vocab_t2",
                               NA, NA, NA, NA, NA, NA,  NA,
                               NA,"log_rt_sd_t2","log_rt_t2", "acc_t2", "acc_sd_t2", "prod_t2", "comp_t2"), 
                     byrow = TRUE)
graph_sem(model = fit3_long, text_size = 2, layout = t(layout_long))
```


# Full longitudinal model

```{r}
d_sub_wide <- d_sub_s |> 
  mutate(t = cut(time_since_t0, breaks = c(0, 3, 6, 9, 12, 30), 
                 include.lowest = TRUE)) |>
  filter(t != "(12,30]") |>
  mutate(t = as.numeric(t)) |>
  group_by(subject_id, dataset_name, t) |>
  summarise(across(all_of(c("log_rt", "log_rt_sd", "acc",
                            "acc_sd", "prod", "comp")),
                   ~ mean(.x, na.rm=TRUE))) |> 
  mutate(across(all_of(c("log_rt", "log_rt_sd", "acc",
                         "acc_sd", "prod", "comp")),
                ~ ifelse(is.nan(.x), NA, .x))) |>
  pivot_wider(id_cols = c("subject_id","dataset_name"), 
              names_from = "t",
              values_from = c("log_rt", "log_rt_sd", "acc", 
                              "acc_sd", "prod", "comp"), 
              names_prefix = "t")

d_sub_wide |>
  ungroup() |>
  summarise(across(log_rt_t1:comp_t4, 
                   ~sum(!is.na(.x))))
```

```{r}
fa3_model_long <- "
# measurement model
vocab_t1 =~ 1*prod_t1 + s1*comp_t1
accuracy_t1 =~ 1*acc_t1 + s2*acc_sd_t1
speed_t1 =~ 1*log_rt_t1 + s3*log_rt_sd_t1

vocab_t2 =~ 1*prod_t2 
accuracy_t2 =~ 1*acc_t2 + s2*acc_sd_t2
speed_t2 =~ 1*log_rt_t2 + s3*log_rt_sd_t2

vocab_t3 =~ 1*prod_t3 
accuracy_t3 =~ 1*acc_t3 + s2*acc_sd_t3
speed_t3 =~ 1*log_rt_t3 + s3*log_rt_sd_t3

vocab_t4 =~ 1*prod_t4 
accuracy_t4 =~ 1*acc_t4 + s2*acc_sd_t4
speed_t4 =~ 1*log_rt_t4 + s3*log_rt_sd_t4

# factor covariances
vocab_t1 ~~ accuracy_t1
vocab_t1 ~~ speed_t1
accuracy_t1 ~~ speed_t1

vocab_t2 ~~ accuracy_t2
vocab_t2 ~~ speed_t2
accuracy_t2 ~~ speed_t2

vocab_t3 ~~ accuracy_t3
vocab_t3 ~~ speed_t3
accuracy_t3 ~~ speed_t3

vocab_t4 ~~ accuracy_t4
vocab_t4 ~~ speed_t4
accuracy_t4 ~~ speed_t4

# means for the latents
vocab_t1 ~ 1
vocab_t2 ~ 1
vocab_t3 ~ 1
vocab_t4 ~ 1
accuracy_t1 ~ 1
accuracy_t2 ~ 1
accuracy_t3 ~ 1
accuracy_t4 ~ 1
speed_t1 ~ 1
speed_t2 ~ 1
speed_t3 ~ 1
speed_t4 ~ 1

# regressions
accuracy_intercept =~ 1*accuracy_t1 + 1*accuracy_t2 + 1*accuracy_t3 + 1*accuracy_t4 
accuracy_slope =~ 1*accuracy_t1 + 2*accuracy_t2 + 3*accuracy_t3 + 4*accuracy_t4
speed_intercept =~ 1*speed_t1 + 1*speed_t2 + 1*speed_t3 + 1*speed_t4 
speed_slope =~ 1*speed_t1 + 2*speed_t2 + 3*speed_t3 + 4*speed_t4
vocab_intercept =~ 1*vocab_t1 + 1*vocab_t2 + 1*vocab_t3 + 1*vocab_t4 
vocab_slope =~ 1*vocab_t1 + 2*vocab_t2 + 3*vocab_t3 + 4*vocab_t4

# parameters for the regressions
vocab_intercept ~ 1
vocab_slope ~ 1
accuracy_intercept ~ 1
accuracy_slope ~ 1
speed_intercept ~ 1
speed_slope ~ 1

# # residual variance for the latents
# vocab_t1 ~~ NA*vocab_t1
# vocab_t2 ~~ NA*vocab_t2
# accuracy_t1 ~~ NA*accuracy_t1
# accuracy_t2 ~~ NA*accuracy_t2
# speed_t1 ~~ NA*speed_t1
# speed_t2 ~~ NA*speed_t2
"

fit3_long <- sem(fa3_model_long, d_sub_wide, std.lv=TRUE, missing='fiml')

summary(fit3_long, fit.measures=TRUE, standardize=TRUE)

```


```{r}
layout_dt = matrix(nrow=11, ncol = 7,
                   data = c("prod_t1", "prod_t2", "prod_t3", "prod_t4", "vocab_intercept", NA, NA,
                            NA, NA, NA, NA, NA, NA, NA,
                            "comp_t1", NA, NA, NA, "vocab_slope", NA,NA,
                            NA, NA, NA, NA, NA, NA, NA,
                            "accuracy_t1", "accuracy_t2", "accuracy_t3", "accuracy_t4", "accuracy_intercept", NA, NA,
                            NA, NA, NA, NA, NA, NA, NA,
                            "acc_sd_t1", "acc_sd_t2", "acc_sd_t3", "accuracy_sd_t4", "accuracy_slope", NA, NA,
                            NA, NA, NA, NA, NA, NA, NA,
                            "log_rt_t1", "log_rt_t2", "log_rt_t3", "log_rt_t4", "speed_int", NA, NA,
                            NA, NA, NA, NA, NA, NA, NA,
                            "log_rt_sd_t1", "log_rt_sd_t2", "log_rt_sd_t3", "log_rt_sd_t4", "speed_slope", NA, NA),
                   byrow = TRUE)


graph_sem(model = fit3_long, text_size = 3, layout = layout_dt)

```

