---
title: "Supplemental Information: Continuous developmental changes in word recognition support language learning across early childhood"
output: 
  pdf_document:
    fig_caption: yes
    keep_tex: yes
header-includes:
  - \usepackage{threeparttablex}
  - \usepackage{booktabs}
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE)
library(here)
source(here("helper","common.R"))
```

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
paper <- suppressMessages(knitr::purl(here("paper","paper.Rmd"), documentation = 0))
suppressMessages(source(paper))
```

# Dataset Description

Figure \ref{fig:dataset} gives the age distribution for each separate dataset. 

```{r dataset, fig.cap="\\label{fig:dataset} Age distribution for each dataset, using three-month bins.", fig.pos="h!"}
ggplot(d_sub, aes(x = age))+ 
  geom_histogram(binwidth = 3) + 
  facet_wrap(~dataset_name, scale = "free_y") +
  xlab("Age (months)") + 
  ylab("Number of participants")
```

Figure \ref{fig:longitudinal} shows the distribution of measurement intervals for longitudinal studies within the dataset.

```{r longitudinal, fig.cap="\\label{fig:longitudinal} Number of administrations for datasets with repeated measurements, plotted by dataset.", fig.pos="h!"}

d_sub_long <- d_sub |>
  filter(subject_id %in% longitudinal$subject_id) |>
  group_by(subject_id) |>
  arrange(age) |>
  mutate(admin_num = 1:n(), 
         delta_t = age - age[1])

ggplot(d_sub_long, 
       aes(x = delta_t, fill = dataset_name)) +
  geom_histogram(binwidth = 1) + 
  scale_fill_solarized(name = "Dataset") +
  theme(legend.position = "bottom") + 
  # facet_wrap(~dataset_name) + 
  xlab("Age since first test") + 
  ylab("Number of participants")
```

# Test-Retest Reliability

```{r reliability}
MONTH_CUTOFF <- 3

longitudinal <- d_sub |>
  group_by(dataset_name, subject_id) |>
  count() |>
  filter(n > 1)

d_long <- d_sub |>
  filter(subject_id %in% longitudinal$subject_id) |>
  group_by(subject_id) |>
  arrange(age) |>
  mutate(admin_num = 1:n(), 
         time_since_t0 = age - age[1],
         delta_t = c(0, diff(age)))


d_reliability <- d_long |>
  filter(time_since_t0 <= MONTH_CUTOFF, 
         admin_num <= 2) |>
  pivot_wider(id_cols = c("subject_id","dataset_name"), 
              names_from = "admin_num",
              values_from = c("log_rt", "long_window_accuracy", 
                              "short_window_accuracy"))

dataset_reliabilities <- d_reliability |>
  group_by(dataset_name) |>
  summarise(rt = cor(log_rt_1, log_rt_2, use = "pairwise.complete.obs"),
            acc_long = cor(long_window_accuracy_1, 
                           long_window_accuracy_2, use = "pairwise.complete.obs"),
            acc_short = cor(short_window_accuracy_1, 
                            short_window_accuracy_2, use = "pairwise.complete.obs")) 

global_reliabilities <- d_reliability |>
  ungroup() |>
  summarise(rt = cor(log_rt_1, log_rt_2, use = "pairwise.complete.obs"),
            acc_long = cor(long_window_accuracy_1, 
                           long_window_accuracy_2, use = "pairwise.complete.obs"),
            acc_short = cor(short_window_accuracy_1, 
                            short_window_accuracy_2, use = "pairwise.complete.obs"))
```


We examined test-retest reliability for our primary variables of interest by calculating Pearson correlations between pairs of administrations given no more than three months apart. Test-retest correlations were significant but relatively modest: $\rho_{long window acc} = `r round(global_reliabilities[2], 3)`$, $\rho_{short window acc} = `r round(global_reliabilities[3], 3)`$, $\rho_{rt} =  `r round(global_reliabilities[1],3)`$. These reliabilities were biased downwards by three factors, however. First, longitudinal assessments sometimes use variable items between testing sessions, leading to item-related variance in measurement. Second, even three months can lead to substantial change in some children's language abilities, thus correlations are attenuated by true change as well as measurement error. Third, longitudinal data in the dataset come primarily from the youngest children and hence are likely to show overall higher measurement error due to variability in children's behavior and an overall lower number of trials. 

# Correlations

Table \ref{tab:corrs} shows pairwise correlations between the primary variables of interest in the dataset.

\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\begin{tabular}{llllllllll}
\toprule
& \multicolumn{1}{l}{age} & \multicolumn{1}{l}{log age} & \multicolumn{1}{l}{RT} & \multicolumn{1}{l}{log RT} & \multicolumn{1}{l}{long acc} & \multicolumn{1}{l}{short acc } & \multicolumn{1}{l}{prod} & \multicolumn{1}{l}{comp}\\
\midrule
age &  1.00 &  &  &  &  &  &  & \\
log age  & 0.98 & 1.00 &  &  &  &  &  &\\
rt  & -0.33 & -0.35 & 1.00 &  &  &  &  & \\
log rt  & -0.34 & -0.36 & 0.96 & 1.00 &  &  &  & \\
long window accuracy  & 0.44 & 0.48 & -0.48 & -0.46 & 1.00 &  &  & \\
short window accuracy & 0.38 & 0.43 & -0.62 & -0.61 & 0.82 & 1.00 &  & \\
production vocabulary & 0.72 & 0.70 & -0.31 & -0.33 & 0.51 & 0.45 & 1.00 & \\
comprehension vocabulary & 0.42 & 0.42 & -0.25 & -0.24 & 0.24 & 0.24 & 0.59 & 1.00\\
\bottomrule
\end{tabular}
\end{threeparttable}
\end{center}
\caption{Pairwise correlations between primary variables of interest. \label{tab:corrs}}
\end{table}


```{r corrs, results = "asis", include = FALSE}

cor(select(d_sub, age, log_age, rt, log_rt, 
           long_window_accuracy, short_window_accuracy, prod, comp), 
    use = "pairwise.complete.obs") |>
  round(2) |>
  papaja::apa_table()

```

# Functional Form Model Comparison

Table \ref{tab:accmods} shows model comparison measures between for different models of the functional form of the relationship between accuracy and age and Table \ref{tab:rtmods} shows the same for reaction time. Age gradients are estimated substantially better with long window accuracies. Note that there are a greater number of observations for short window accuracies due to less missing data. We speculate that, on average, more participants looked away from the screen towards the end of trials, leading to a greater number of exclusions of long window trials based on the 50% criterion. Note that the total percentage of trials excluded is still small for both measures: `r round(mean(is.na(d_trial$long_window_accuracy)), 2)`% for long window accuracy and `r round(mean(is.na(d_trial$short_window_accuracy)), 2)`% for short window accuracy. 


\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\begin{tabular}{lllllllll}
\toprule
n. obs & \multicolumn{1}{c}{sigma} & \multicolumn{1}{c}{logLik} & \multicolumn{1}{c}{AIC} & \multicolumn{1}{c}{BIC} & \multicolumn{1}{c}{REMLcrit} & \multicolumn{1}{c}{df.residual} & \multicolumn{1}{c}{model} & \multicolumn{1}{c}{$r_2$}\\
\midrule
48354 & 0.28 & -8,338.83 & 16,691.65 & 16,753.16 & 16,677.65 & 48347 & Long window, linear age & 0.14\\
48354 & 0.28 & -8,305.39 & 16,624.78 & 16,686.28 & 16,610.78 & 48347 & Long window, log age & 0.12\\
50244 & 0.31 & -12,486.60 & 24,987.21 & 25,048.98 & 24,973.21 & 50237 & Short window, linear age & 0.09\\
50244 & 0.31 & -12,458.77 & 24,931.54 & 24,993.31 & 24,917.54 & 50237 & Short window, log age & 0.08\\
\bottomrule
\end{tabular}
\end{threeparttable}
\end{center}
\caption{Model comparison metrics for different functional forms of the relationship between accuracy and age. \label{tab:accmods}}
\end{table}

\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\begin{tabular}{lllllllll}
\toprule
n. obs & \multicolumn{1}{c}{sigma} & \multicolumn{1}{c}{logLik} & \multicolumn{1}{c}{AIC} & \multicolumn{1}{c}{BIC} & \multicolumn{1}{c}{REMLcrit} & \multicolumn{1}{c}{df.residual} & \multicolumn{1}{c}{model} & \multicolumn{1}{c}{$r_2$}\\
\midrule
18940 & 0.45 & -12,414.69 & 24,843.38 & 24,898.32 & 24,829.38 & 18933 & Log RT, linear age & 0.21\\
18940 & 0.45 & -12,393.27 & 24,800.53 & 24,855.48 & 24,786.53 & 18933 & Log RT, log age & 0.21\\
18940 & 570.49 & -147,644.43 & 295,302.87 & 295,357.81 & 295,288.87 & 18933 & Linear RT, linear age & 0.18\\
18940 & 570.02 & -147,622.67 & 295,259.34 & 295,314.29 & 295,245.34 & 18933 & Linear RT, log age & 0.18\\
\bottomrule
\end{tabular}
\end{threeparttable}
\end{center}
\caption{Model comparison metrics for different functional forms of the relationship between RT and age. \label{tab:rtmods}}
\end{table}

Note that with our current dataset we cannot specifically determine whether within-individual patterns of change conform to linear, power law, or exponential developmental patterns (Heathcote, Brown, \& Mewhort, 2000). Our current results apply to the form of the age gradient as opposed to the form of any individual's pattern of developmental change. 



```{r accmods, results="asis", include = FALSE}
papaja::apa_table(acc_mods_lmer_summary)
```


```{r results="asis", include = FALSE}
papaja::apa_table(rt_mods_lmer_summary)
```


# Factor Analysis 

```{r}
d_sub_mat <- d_sub |>
  ungroup() |>
  select(dataset_name, rt, rt_var, long_window_accuracy, long_window_acc_var, prod, comp, age) 

d_sub_mat_s <- d_sub_mat |>
  ungroup() |>
  mutate(across(all_of(c("rt", "rt_var", "long_window_accuracy", 
                         "long_window_acc_var", "prod", "comp")), 
                ~ age_scale(.x, age))) 
fa.parallel(select(d_sub_mat, -dataset_name, -age), fa = "fa", 
            use = "pairwise.complete.obs")
```

```{r}
fs <- fa(select(d_sub_mat, -dataset_name), nfactor = 3,
         use = "pairwise", rotate = "varimax")

as.data.frame(unclass(loadings(fs))) |> 
  kable(caption = "Factor loadings for the exploratory three factor solution using varimax rotation.", digits = 2)
```


# Alternative Factor Structures




- Alternative factor models: variances together, two factor, etc. etc. 

# Non-linear Growth Models

To test for the differentiation of vocabulary growth based on initial reaction time, we used the package `nlme` to fit a logistic growth model to the production data. This model has two parameters for the logistic curve, a scale and an intercept. Both were allowed to interact with initial reaction time. We also included random effects of logistic intercept and scale by participant and a grouping term across datasets. This model showed a significant effect of initial reaction time on the intercept of the logistic growth curve, but not on its scale (see Table \ref{tab:nlme}). 

% latex table generated in R 4.4.2 by xtable 1.8-4 package
% Thu Mar 13 13:10:30 2025
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
\hline
& Value & Std Error & DF & $t$-value & $p$-value \\ 
\hline
Growth Intercept & 2.26 & 2.70 & 1766.00 & 0.84 & 0.40 \\ 
Growth Intercept $\times$ $t_0$ RT & 3.30 & 0.38 & 1766.00 & 8.59 & 0.00 \\ 
Growth Scale & 2.05 & 2.60 & 1766.00 & 0.79 & 0.43 \\ 
Growth Scale $\times$ $t_0$ RT & 0.28 & 0.38 & 1766.00 & 0.75 & 0.46 \\ 
\hline
\end{tabular}
\caption{Fixed effects estimates from logistic growth model. \label{tab:nlme}}
\end{table}

Interpretation of growth in both this model and the linear growth model in the main text is complicated by the fact that the CDI form puts a ceiling on the total number of words that can be recorded; both the quadratic growth functions and the logistic functions come together at the form ceiling. Thus, a shift in quadratic growth in the linear model and a shift in intercept in the logistic model both point to the same overall effect, which is faster growth at the point of maximal sensitivity of the CDI. Neither model can estimate whether the overall growth trajectory is different beyond the range of the CDI. Thus, although these models might initially seem to be in conflict, we believe that they actually point to the same phenomenon, which is perhaps better described by the longitudinal SEM model reported in the main text. Children with greater skill in word recognition show an overall positive shift in the growth trajectory of vocabulary development.

```{r}
# xtable(summary(mod_nlme)$tTable)
```


# Latent Factor Growth


```{r}
fa3_model_long <- "
# measurement model
vocab_t1 =~ 1*prod_t1 + s1*comp_t1
accuracy_t1 =~ 1*acc_t1 + s2*acc_sd_t1
speed_t1 =~ 1*log_rt_t1 + s3*log_rt_sd_t1

vocab_t2 =~ 1*prod_t2 
accuracy_t2 =~ 1*acc_t2 + s2*acc_sd_t2
speed_t2 =~ 1*log_rt_t2 + s3*log_rt_sd_t2

vocab_t3 =~ 1*prod_t3 
accuracy_t3 =~ 1*acc_t3 + s2*acc_sd_t3
speed_t3 =~ 1*log_rt_t3 + s3*log_rt_sd_t3

vocab_t4 =~ 1*prod_t4 
accuracy_t4 =~ 1*acc_t4 + s2*acc_sd_t4
speed_t4 =~ 1*log_rt_t4 + s3*log_rt_sd_t4

# means for the latents
# vocab_t1 ~ 1
# vocab_t2 ~ 1
# vocab_t3 ~ 1
# vocab_t4 ~ 1
# accuracy_t1 ~ 1
# accuracy_t2 ~ 1
# accuracy_t3 ~ 1
# accuracy_t4 ~ 1
# speed_t1 ~ 1
# speed_t2 ~ 1
# speed_t3 ~ 1
# speed_t4 ~ 1

# autoregression for the latents
# vocab_t2 ~ 1 * vocab_t1
# vocab_t3 ~ 1 * vocab_t2
# vocab_t4 ~ 1 * vocab_t3
# accuracy_t2 ~ 1 * accuracy_t1
# accuracy_t3 ~ 1 * accuracy_t2
# accuracy_t4 ~ 1 * accuracy_t3
# speed_t2 ~ 1 * speed_t1
# speed_t3 ~ 1 * speed_t2
# speed_t4 ~ 1 * speed_t3

# regressions
accuracy_intercept =~ 1*accuracy_t1 + 1*accuracy_t2 + 1*accuracy_t3 + 1*accuracy_t4 
accuracy_slope =~ 1*accuracy_t1 + 2*accuracy_t2 + 3*accuracy_t3 + 4*accuracy_t4
speed_intercept =~ 1*speed_t1 + 1*speed_t2 + 1*speed_t3 + 1*speed_t4 
speed_slope =~ 1*speed_t1 + 2*speed_t2 + 3*speed_t3 + 4*speed_t4
vocab_intercept =~ 1*vocab_t1 + 1*vocab_t2 + 1*vocab_t3 + 1*vocab_t4 
vocab_slope =~ 1*vocab_t1 + 2*vocab_t2 + 3*vocab_t3 + 4*vocab_t4

# parameters for the regressions
vocab_intercept ~ 1
vocab_slope ~ 1
accuracy_intercept ~ 1
accuracy_slope ~ 1
speed_intercept ~ 1
speed_slope ~ 1

# residual variance for the latents
vocab_t1 ~~ NA*vocab_t1
vocab_t2 ~~ NA*vocab_t2
vocab_t3 ~~ NA*vocab_t3
vocab_t4 ~~ NA*vocab_t4
accuracy_t1 ~~ NA*accuracy_t1
accuracy_t2 ~~ NA*accuracy_t2
accuracy_t3 ~~ NA*accuracy_t3
accuracy_t4 ~~ NA*accuracy_t4
speed_t1 ~~ NA*speed_t1
speed_t2 ~~ NA*speed_t2
speed_t3 ~~ NA*speed_t3
speed_t4 ~~ NA*speed_t4

# residual variance for the other latents
vocab_intercept ~~ NA*vocab_intercept
vocab_slope ~~ NA*vocab_slope
accuracy_intercept ~~ NA*accuracy_intercept
accuracy_slope ~~ NA*accuracy_slope
speed_intercept ~~ NA*speed_intercept
speed_slope ~~ NA*speed_slope

# set observed intercepts to zero - these should go into the latents
prod_t1 ~ 0
prod_t2 ~ 0
prod_t3 ~ 0
prod_t4 ~ 0
comp_t1 ~ 0 
log_rt_t1 ~ 0
log_rt_t2 ~ 0
log_rt_t3 ~ 0
log_rt_t4 ~ 0
log_rt_sd_t1 ~ 0 
log_rt_sd_t2 ~ 0
log_rt_sd_t3 ~ 0 
log_rt_sd_t4 ~ 0 
acc_t1 ~ 0 
acc_t2 ~ 0 
acc_t3 ~ 0 
acc_t4 ~ 0 
acc_sd_t1 ~ 0
acc_sd_t2 ~ 0
acc_sd_t3 ~ 0
acc_sd_t4 ~ 0
"

fit3_long <- sem(fa3_model_long, d_sub_wide_fine, std.lv=TRUE, missing='fiml')

summary(fit3_long, fit.measures=TRUE, standardize=TRUE)

```


```{r}
layout <- read.csv(here("misc/layout_dt3.csv"), header = FALSE)
graph_sem(model = fit3_long, text_size = 3, layout=t(layout))

```


<!-- # Short Window Analysis -->

<!-- Need to redo all figures using short windows ugh.  -->
# References

Heathcote, A., Brown, S., \& Mewhort, D. J. K. (2000). The power law repealed: The case for an exponential law of practice. Psychonomic Bulletin & Review, 7(2), 185–207.