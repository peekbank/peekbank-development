---
title: "Supplemental Information: Continuous developmental changes in word recognition support language learning across early childhood"
output: 
  pdf_document:
    fig_caption: yes
    keep_tex: yes
header-includes:
  - \usepackage{threeparttablex}
  - \usepackage{booktabs}
  - \renewcommand{\thefigure}{S\arabic{figure}}
  - \renewcommand{\thetable}{S\arabic{table}}
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE)
library(here)
source(here("helper","common.R"))
```

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
paper <- suppressMessages(knitr::purl(here("paper","paper.Rmd"), documentation = 0))
suppressMessages(source(paper))
```

# Dataset Description

Figure \ref{fig:dataset} gives the age distribution of unique participants for each separate dataset at different ages. Note that for some datasets, there are multiple administrations (i.e., experimental test sessions) for each participant.

```{r dataset, fig.cap="\\label{fig:dataset} Age distribution of unique participants for each dataset, using three-month bins.", fig.pos="h!"}

# summarize participants by age bin
d_sub_admin_by_age <- d_sub |>
  mutate(age_bin = age %/% 3 * 3+1.5) |>
  group_by(dataset_name, age_bin) |>
  summarise(
    n_subj = n_distinct(subject_id),
    n_administration = n_distinct(administration_id)) |>
  ungroup()

# ggplot(d_sub, aes(x = age))+ 
#   geom_histogram(binwidth=3) + 
#   facet_wrap(~dataset_name, scale = "free_y") +
#   xlab("Age (months)") + 
#   ylab("Number of administrations")+
#   theme(strip.text.x = element_text(size = 5))

# plot number of participants across age
ggplot(d_sub_admin_by_age, aes(x = age_bin,y=n_subj))+ 
  geom_bar(stat="identity",width=3) + 
  facet_wrap(~dataset_name, scale = "free_y") +
  xlab("Age (months)") + 
  ylab("Number of participants")+
  theme(strip.text.x = element_text(size = 5))

```

Figure \ref{fig:longitudinal_descriptives} shows the distribution of measurement intervals for longitudinal studies within the dataset.

```{r longitudinal_descriptives, fig.cap="\\label{fig:longitudinal_descriptives} Distribution of retest administrations across datasets with repeated measurements, colored by dataset. Each count indicates a retest administration (initial administrations are excluded). Administrations listed with a retest interval of 0 indicate retests within a month of the initial administration.", fig.pos="h!"}

d_sub_long <- d_sub |>
  filter(subject_id %in% longitudinal$subject_id) |>
  group_by(subject_id) |>
  arrange(age) |>
  mutate(delta_t = age - age[1])

ggplot(filter(d_sub_long, admin_num > 1), 
       aes(x = delta_t, fill = dataset_name)) +
  geom_histogram(binwidth = 1) + 
  scale_fill_solarized(name = "Dataset") +
  theme(legend.position = "bottom") + 
  # facet_wrap(~dataset_name) + 
  xlab("Months since first test administration") + 
  ylab("Number of administrations")
```

# Reaction Time Computation

Eye-tracking data are stored in Peekbank as a time series of fixations to specific areas of interest (in particular, the target and distractor on each trial). Other fixations can be to areas not in the target or distractor as well to off-screen areas. This time series has a uniform sample rate of 25ms/sample, based on resampling of the data in Peekbank to 40 Hz during preprocessing [@zettersten2023peekbank]. Reaction times are computed by filtering trials to only those on which the child is fixating the distractor at the point of disambiguation ($t=0$) and then finding those trials on which the first non-missing fixation is to the target (hence excluding trials without a shift and trials on which a shift is to an off-screen location). The reaction time is then the total time from $t=0$ to the first timestep during which the child fixates the target. Consistent with standard practice in the literature following Fernald et al. (2008), RTs that are shorter than 367 ms are excluded as they are too short to be considered a response to the stimulus.

# Comparison of Reaction Times for Correct and Incorrect Trials: Re-analysis of Creel (2024)

```{r, eval=F}
#load data using Creel (2024) analysis scripts
# To run this script, you need to first pull in two datasets from the Creel (2024) OSF repository (https://osf.io/wszd5/):
#allfamiliars.csv and allnovels.csv
library(osfr)
library(here)
creel_proj <- osf_retrieve_node("wszd5")
#donwload familiar trials
#TO DO: separate this out so files are downloaded only once
creel_proj %>%
  osf_ls_files(pattern = "allfamiliars.csv") %>% # Replace "data.csv" with your file's name
  osf_download(path = here("supplemental_data","creel_2024"),conflicts = "overwrite")
creel_proj %>%
  osf_ls_files(pattern = "allnovels.csv") %>% # Replace "data.csv" with your file's name
  osf_download(path = here("supplemental_data","creel_2024"),conflicts = "overwrite")

creel_proj %>%
  osf_ls_files(pattern = "Step2aCorrsNDataPrep.R") %>% # Replace "data.csv" with your file's name
  osf_download(path = here("supplemental_data","creel_2024"),conflicts = "overwrite")
```


```{r, eval=F}
#run Creel prep script

#creel prep script expects files in root directory
setwd(here("supplemental_data","creel_2024"))
source("Step2aCorrsNDataPrep.R")
setwd(here())
# run Peekbank-style rt computation over Creel data
source(here("supplemental_data","creel_2024","creel_peekbank_acc_rt_analysis.R"))

 creel_plot <- ggplot(filter(subj_rt_acc,n_correct_trials>1&n_trials>1),aes(mean_rt,mean_rt_correct))+
  geom_point(aes(size=n_correct_trials),alpha=0.3,fill="black",stroke=NA)+
  geom_smooth(method="lm")+
  xlab("Mean Participant Reaction Time (ms)\nAll Trials")+
  ylab("Mean Participant Reaction Time (ms)\nTrials w/ Correct Pointing Response")+
  theme_cowplot(font_size=20)+
  #add correlation and p-value as text box
  annotate("text",x=500,y=1500,label=paste0("r = ",round(cor(filter(subj_rt_acc,n_correct_trials>1&n_trials>1)$mean_rt,filter(subj_rt_acc,n_correct_trials>1&n_trials>1)$mean_rt_correct,use="pairwise.complete.obs"),2)),size=9)+
  theme(legend.position=c(0.8,0.2))+
  scale_size_continuous(name="# Trials",breaks=c(2,5,10,15,20))
ggsave(here("supplemental_data","creel_2024","creel_rt_correlation_correcttrials_vs_alltrials.png"),width=9,height=6)

creel_correlation <- cor.test(filter(subj_rt_acc,n_correct_trials>1&n_trials>1)$mean_rt,filter(subj_rt_acc,n_correct_trials>1&n_trials>1)$mean_rt_correct,use="pairwise.complete.obs")

```

The Peekbank dataset only includes measurements of infants' looking behavior, with no measure of a final target selection. This contrasts with work in the visual-world paradigm with older children and adults, in which participants make a final explicit choice about which image matches the target label (e.g. Colby & McMurray, 2023). Having this additional response allows a clearer separation of accuracy and reaction times, because researchers can compute reaction times specifically on those trials in which participants responded correctly. This strategy helps avoid a possible mixing of reaction times for incorrect and correct responses, which might be generated by different underlying cognitive processes. A possible concern with the Peekbank datasets --- and reaction times in infant looking-while-listening studies more generally --- is that it is difficult to separate reaction times for correct vs. incorrect responses in the absence of an independent final choice response.

```{r}
# <!--To address this concern, we investigated data from a recent large-scale word recognition study with toddlers in which eyetracking measures were collected together with a final pointing response (Creel, 2024). This dataset included 914 responses from children (2.5-6.5 years) completing a looking-while listening procedure in which they also were instructed to point to the target image. Using this dataset, we investigated the correlation between reaction times (following the same procedure as in our main analyses, i.e. focusing specifically on distractor-to-target shifts) computed over all trials and reaction times computed only for those trials in which children selected the correct referent. The results are visualized below. Reaction times (i.e., distractor to target shifts) for correct trials only were highly correlated with reaction times across all trials (`r apa_print(creel_correlation)$full_result`). This result suggests that having the ability to filter out incorrect trials has a minimal impact on reaction time computation, even in young children. While there is some uncertainty about how these results may generalize to infants in our younger age ranges (i.e., below 2.5 years of age), who struggle to provide reliable pointing responses, it seems reasonable to assume that our reaction time results would stay largely the same if it were possible to filter out trials on which infants make an incorrect mapping between the target label and the target image using an eyetracking-independent final choice response.-->

```

```{r, eval=F}
creel_plot
```

# Separability of Variability from Other Measures

## Reaction Time

```{r}
library(fitdistrplus)

library(statmod)

library(gamlss.dist)

#note that fitdistrplus attaches MASS which also has a select function, and that's annoying
detach("package:dplyr", character.only = TRUE)
library("dplyr", character.only = TRUE)

rt_fitting  <- d_sub |>
  ungroup() |>
  filter(!is.na(rt)) |>
  mutate(age_bin = cut(age,
                       breaks = c(0,12,15,18,21,24,27,30,36,60), 
                       labels = c("<12", "12-15","15-18", "18-21", 
                                  "21-24", "24-27","27-30","30-36", ">36"))) |>
  select(age_bin, rt)


norm <- fitdist(rt_fitting$rt, distr = "norm", method = "mle")
lnorm <- fitdist(rt_fitting$rt, distr = "lnorm", method = "mle")
wald <- fitdist(rt_fitting$rt, distr = "invgauss", method = "mle", 
                start = list(mean = 1, shape = 1, dispersion = 1))
exgaus <- fitdist(rt_fitting$rt, distr = "exGAUS", method = "mle", 
                  start = list(mu = 1000, sigma = 500, nu = 1), 
                  lower = c(0, 0, 0))

BIC(norm)
BIC(lnorm)
BIC(wald)
BIC(exgaus)


rt_fits <- rt_fitting |>
  group_by(age_bin) |>
  nest(rt) |>
  mutate(
    norm = map(data, \(d) fitdist(d$rt, distr = "norm", method = "mle")),
    lnorm = map(data, \(d) fitdist(d$rt, distr = "lnorm", method = "mle")),
    wald = map(data, \(d) fitdist(d$rt, distr = "invgauss", method = "mle", 
                                  start = list(mean = 1, shape = 1, dispersion = 1))),
    exgaus = map(data, \(d) fitdist(d$rt, distr = "exGAUS", method = "mle", 
                                    start = list(mu = 1000, sigma = 500, nu = 1), 
                                    lower = c(0, 0, 0)))) |>
  select(-data) |>
  pivot_longer(norm:exgaus, names_to = "distribution", values_to = "fit") |>
  mutate(BIC = map_dbl(fit, BIC)) |>
  group_by(age_bin) |>
  mutate(min_bic = BIC == min(BIC))

ggplot(rt_fits, 
       aes(x = distribution, y = BIC, col = min_bic)) + 
  geom_point(stat = "identity", position = "dodge") + 
  scale_color_solarized(name = "Lowest BIC") + 
  xlab("Age bin") + 
  ylab("BIC") + 
  coord_flip() + 
  facet_wrap(~age_bin, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
rt_hist_data <- d_sub |>
  mutate(
    age_bin = cut(age,
                  breaks = c(0,12,15,18,21,24,27,30,36,60), 
                  labels = c("<12", "12-15","15-18", "18-21", 
                             "21-24", "24-27","27-30","30-36", ">36"))) 

bw = .2

rt_hist_summary <- rt_hist_data |>
  group_by(age_bin) |>
  summarise(m = mean(log_rt, na.rm = TRUE), 
            sd = sd(log_rt, na.rm = TRUE), 
            n = n()) |>
  expand_grid(log_rt = seq(6,8,.01)) |>
  mutate(norm = dnorm(log_rt, mean = m, sd = sd) * n * bw)


ggplot(rt_hist_data,
       aes(x = log_rt)) + 
  geom_histogram(binwidth = bw) + 
  geom_line(data = rt_hist_summary, aes(x = log_rt, y = norm), col = "blue") +
  xlab("Log RT (ms)") + 
  ylab("Number of trials") + 
  facet_wrap(~age_bin)+ 
  theme_few()
```

## Accuracy

```{r}
acc_hist_data <- d_sub |>
  mutate(
    age_bin = cut(age,
                  breaks = c(0,12,15,18,21,24,27,30,36,60), 
                  labels = c("<12", "12-15","15-18", "18-21", 
                             "21-24", "24-27","27-30","30-36", ">36"))) 

bw = .025

acc_hist_summary <- acc_hist_data |>
  group_by(age_bin) |>
  summarise(m = mean(long_window_accuracy, na.rm = TRUE),
            sd = sd(long_window_accuracy, na.rm = TRUE),
            n = n()) |>
  expand_grid(acc = seq(0,1,.01)) |>
  mutate(norm = dnorm(acc, mean = m, sd = sd) * n * bw)


ggplot(acc_hist_data,
       aes(x = long_window_accuracy)) + 
  geom_histogram(binwidth = bw) + 
  geom_line(data = acc_hist_summary, aes(x = acc, y = norm), col = "blue") +
  xlab("Long Window Accuracy") + 
  ylab("Number of trials") + 
  facet_wrap(~age_bin) + 
  theme_few()
```

```{r}

acc_fitting  <- d_sub |>
  ungroup() |>
  filter(!is.na(long_window_accuracy)) |>
  mutate(age_bin = cut(age,
                       breaks = c(0,12,15,18,21,24,27,30,36,60), 
                       labels = c("<12", "12-15","15-18", "18-21", 
                                  "21-24", "24-27","27-30","30-36", ">36"))) |>
  select(age_bin, long_window_accuracy)


norm <- fitdist(acc_fitting$long_window_accuracy, distr = "norm", method = "mle")
beta <- fitdist(acc_fitting$long_window_accuracy, distr = "beta", method = "mle")

BIC(norm)
BIC(beta)
```

```{r}

acc_fits <- acc_fitting |>
  group_by(age_bin) |>
  nest(long_window_accuracy) |>
  mutate(
    norm = map(data, \(d) fitdist(d$long_window_accuracy, distr = "norm", method = "mle")),
    beta = map(data, \(d) fitdist(d$long_window_accuracy, distr = "beta", method = "mle"))) |>
  select(-data) |>
  pivot_longer(norm:beta, names_to = "distribution", values_to = "fit") |>
  mutate(BIC = map_dbl(fit, BIC)) |>
  group_by(age_bin) |>
  mutate(min_bic = BIC == min(BIC))

ggplot(acc_fits, 
       aes(x = distribution, y = BIC, col = min_bic)) + 
  geom_point(stat = "identity", position = "dodge") + 
  scale_color_solarized(name = "Lowest BIC") + 
  xlab("Age bin") + 
  ylab("BIC") + 
  coord_flip() + 
  facet_wrap(~age_bin, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

# Test-Retest Reliability

```{r reliability}
MONTH_CUTOFF <- 3

longitudinal <- d_sub |>
  group_by(dataset_name, subject_id) |>
  count() |>
  filter(n > 1)

d_long <- d_sub |>
  filter(subject_id %in% longitudinal$subject_id) |>
  group_by(subject_id) |>
  arrange(age) |>
  mutate(admin_num = 1:n(), 
         time_since_t0 = age - age[1],
         delta_t = c(0, diff(age)))


d_reliability <- d_long |>
  filter(time_since_t0 <= MONTH_CUTOFF, 
         admin_num <= 2) |>
  pivot_wider(id_cols = c("subject_id","dataset_name"), 
              names_from = "admin_num",
              values_from = c("log_rt", "long_window_accuracy", 
                              "short_window_accuracy"))

dataset_reliabilities <- d_reliability |>
  group_by(dataset_name) |>
  summarise(rt = cor(log_rt_1, log_rt_2, use = "pairwise.complete.obs"),
            acc_long = cor(long_window_accuracy_1, 
                           long_window_accuracy_2, use = "pairwise.complete.obs"),
            acc_short = cor(short_window_accuracy_1, 
                            short_window_accuracy_2, use = "pairwise.complete.obs")) 

global_reliabilities <- d_reliability |>
  ungroup() |>
  summarise(rt = cor(log_rt_1, log_rt_2, use = "pairwise.complete.obs"),
            acc_long = cor(long_window_accuracy_1, 
                           long_window_accuracy_2, use = "pairwise.complete.obs"),
            acc_short = cor(short_window_accuracy_1, 
                            short_window_accuracy_2, use = "pairwise.complete.obs"))
```

We examined test-retest reliability for our primary variables of interest by calculating Pearson correlations between pairs of administrations given no more than three months apart. Test-retest correlations were significant but relatively modest: $\rho_{long window acc} = `r round(global_reliabilities[2], 3)`$, $\rho_{short window acc} = `r round(global_reliabilities[3], 3)`$, $\rho_{rt} =  `r round(global_reliabilities[1],3)`$. These reliabilities were biased downwards by three factors, however. First, longitudinal assessments sometimes use variable items between testing sessions, leading to item-related variance in measurement. Second, even three months can lead to substantial change in some children's language abilities, thus correlations are attenuated by true change as well as measurement error. Third, longitudinal data in the dataset come primarily from the youngest children and hence are likely to show overall higher measurement error due to variability in children's behavior and an overall lower number of trials.

# Correlations

Table \ref{tab:corrs} shows pairwise correlations between the primary variables of interest in the dataset.

```{=tex}
\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\begin{tabular}{llllllllll}
\toprule
& \multicolumn{1}{l}{age} & \multicolumn{1}{l}{log age} & \multicolumn{1}{l}{RT} & \multicolumn{1}{l}{log RT} & \multicolumn{1}{l}{long acc} & \multicolumn{1}{l}{short acc } & \multicolumn{1}{l}{prod} & \multicolumn{1}{l}{comp}\\
\midrule
age &  1.00 &  &  &  &  &  &  & \\
log age  & 0.98 & 1.00 &  &  &  &  &  &\\
rt  & -0.33 & -0.35 & 1.00 &  &  &  &  & \\
log rt  & -0.34 & -0.36 & 0.96 & 1.00 &  &  &  & \\
long window accuracy  & 0.44 & 0.48 & -0.48 & -0.46 & 1.00 &  &  & \\
short window accuracy & 0.38 & 0.43 & -0.62 & -0.61 & 0.82 & 1.00 &  & \\
production vocabulary & 0.72 & 0.70 & -0.31 & -0.33 & 0.51 & 0.45 & 1.00 & \\
comprehension vocabulary & 0.42 & 0.42 & -0.25 & -0.24 & 0.24 & 0.24 & 0.59 & 1.00\\
\bottomrule
\end{tabular}
\end{threeparttable}
\end{center}
\caption{Pairwise correlations between primary variables of interest. \label{tab:corrs}}
\end{table}
```
```{r corrs, results = "asis", include = FALSE}

cor(select(d_sub, age, log_age, rt, log_rt, 
           long_window_accuracy, short_window_accuracy, prod, comp), 
    use = "pairwise.complete.obs") |>
  round(2) |>
  papaja::apa_table()

```

# Functional Form Model Comparison

Table \ref{tab:accmods} shows model comparison measures between for different models of the functional form of the relationship between accuracy and age and Table \ref{tab:rtmods} shows the same for reaction time. Age gradients are estimated substantially better with long window accuracies. Note that there are a greater number of observations for short window accuracies due to less missing data. We speculate that, on average, more participants looked away from the screen towards the end of trials, leading to a greater number of exclusions of long window trials based on the 50% criterion. Note that the total percentage of trials excluded is still small for both measures: `r round(mean(is.na(d_trial$long_window_accuracy)), 3)*100`% for long window accuracy and `r round(mean(is.na(d_trial$short_window_accuracy)), 3)*100`% for short window accuracy.

```{=tex}
\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\begin{tabular}{lllllllll}
\toprule
n. obs & \multicolumn{1}{c}{sigma} & \multicolumn{1}{c}{logLik} & \multicolumn{1}{c}{AIC} & \multicolumn{1}{c}{BIC} & \multicolumn{1}{c}{REMLcrit} & \multicolumn{1}{c}{df.residual} & \multicolumn{1}{c}{model} & \multicolumn{1}{c}{$r_2$}\\
\midrule
48354 & 0.28 & -8,338.83 & 16,691.65 & 16,753.16 & 16,677.65 & 48347 & Long window, linear age & 0.14\\
48354 & 0.28 & -8,305.39 & 16,624.78 & 16,686.28 & 16,610.78 & 48347 & Long window, log age & 0.12\\
50244 & 0.31 & -12,486.60 & 24,987.21 & 25,048.98 & 24,973.21 & 50237 & Short window, linear age & 0.09\\
50244 & 0.31 & -12,458.77 & 24,931.54 & 24,993.31 & 24,917.54 & 50237 & Short window, log age & 0.08\\
\bottomrule
\end{tabular}
\end{threeparttable}
\end{center}
\caption{Model comparison metrics for different functional forms of the relationship between accuracy and age. \label{tab:accmods}}
\end{table}
```
```{=tex}
\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\begin{tabular}{lllllllll}
\toprule
n. obs & \multicolumn{1}{c}{sigma} & \multicolumn{1}{c}{logLik} & \multicolumn{1}{c}{AIC} & \multicolumn{1}{c}{BIC} & \multicolumn{1}{c}{REMLcrit} & \multicolumn{1}{c}{df.residual} & \multicolumn{1}{c}{model} & \multicolumn{1}{c}{$r_2$}\\
\midrule
18940 & 0.45 & -12,414.69 & 24,843.38 & 24,898.32 & 24,829.38 & 18933 & Log RT, linear age & 0.21\\
18940 & 0.45 & -12,393.27 & 24,800.53 & 24,855.48 & 24,786.53 & 18933 & Log RT, log age & 0.21\\
18940 & 570.49 & -147,644.43 & 295,302.87 & 295,357.81 & 295,288.87 & 18933 & Linear RT, linear age & 0.18\\
18940 & 570.02 & -147,622.67 & 295,259.34 & 295,314.29 & 295,245.34 & 18933 & Linear RT, log age & 0.18\\
\bottomrule
\end{tabular}
\end{threeparttable}
\end{center}
\caption{Model comparison metrics for different functional forms of the relationship between RT and age. \label{tab:rtmods}}
\end{table}
```
```{r accmods, results="asis", include = FALSE}
papaja::apa_table(acc_mods_lmer_summary)
```

```{r results="asis", include = FALSE}
papaja::apa_table(rt_mods_lmer_summary)
```

# Power Law Fits

In the literature on the "law of practice", although the log-log relationship we observed is commonly present in the aggregate across individuals, the situation is substantially more complex when relationships are measured within individuals. The best fitting curves for individuals are often exponentials or delayed exponentials (Evans et al., 2018; Heathcote, Brown, & Mewhort, 2000). With our current dataset we cannot specifically determine whether within-individual patterns of change conform to linear, power law, or exponential developmental patterns unfortunately, because we have insufficient data about individuals' improvement across time. Thus, our current results apply to the form of the age gradient as opposed to the form of any individual's pattern of developmental change.

Nevertheless, here we test for other forms of the aggregate relationship between age and reaction time. In particular, we consider further model comparison between the

```{r rt_more_mods}
rt_more_mods_lmer <- 
  list(log_log = lmer(log_rt ~ log_age_s + 
                        (log_age_s | dataset_name) + (1 | subject_id), 
                      data = d_trial),
       log_log_plus = lmer(log_rt ~ log_age_s + age_s +  
                             (log_age_s + age_s | dataset_name) + (1 | subject_id), 
                           data = d_trial), 
       lin_poly2 = lmer(rt ~ poly(age_s, 2) +  
                        (age_s | dataset_name) + (1 | subject_id), 
                      data = d_trial),
       lin_poly3 = lmer(rt ~ poly(age_s, 3) +  
                        (age_s | dataset_name) + (1 | subject_id), 
                      data = d_trial))


rt_more_mods_lmer_summary <- map_df(rt_more_mods_lmer, ~broom.mixed::glance(.x)) |>
  mutate(model = names(rt_more_mods_lmer), 
         r2 = map_dbl(rt_more_mods_lmer, ~performance::r2_nakagawa(.x)$R2_conditional))
```

# Mixed effects model specifications

Here we provide specifications for the mixed effects models used in the main text. These models are used to estimate the relationship between age and the primary variables of interest, controlling for dataset and subject-level variability.

\verbatim{lmer(long_window_acc_var ~ log_age_s + (log_age_s | dataset_name) + (1 | subject_id)}

FIXME

# Factor Analysis

Figure 3 shows the result of a parallel analysis supporting the presence of three factors in the exploratory factor analysis. Table \ref{tab:loadings} shows the factor loadings for the exploratory three-factor solution using varimax rotation. The first factor is primarily driven by vocabulary measures, the second by reaction time, and the third by accuracy measures.

```{r parallel, fig.cap="Parallel analysis scree plot showing the eigenvalues for each factor, for actual, simulated, and resampled data."}
d_sub_mat <- d_sub |>
  ungroup() |>
  select(dataset_name, rt, rt_var, long_window_accuracy, long_window_acc_var, prod, comp, age) 

d_sub_mat_s <- d_sub_mat |>
  ungroup() |>
  mutate(across(all_of(c("rt", "rt_var", "long_window_accuracy", 
                         "long_window_acc_var", "prod", "comp")), 
                ~ age_scale(.x, age))) 
outputs <- capture.output(fa.parallel(select(d_sub_mat, -dataset_name, -age), fa = "fa", 
                                      use = "pairwise.complete.obs"))
```

```{r eval=FALSE}
fs <- fa(select(d_sub_mat, -dataset_name), nfactor = 3,
         use = "pairwise", rotate = "varimax")

as.data.frame(unclass(loadings(fs))) |> 
  xtable(caption = "Factor loadings for the exploratory three factor solution using varimax rotation.", digits = 2)
```

<!-- % latex table generated in R 4.4.2 by xtable 1.8-4 package -->

<!-- % Mon Apr 14 12:25:14 2025 -->

```{=tex}
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
\hline
& F1 & F2 & F3 \\ 
\hline
RT & -0.19 & 0.81 & -0.30 \\ 
RT var & -0.10 & 0.81 & -0.22 \\ 
long window accuracy & 0.33 & -0.31 & 0.55 \\ 
long window accuracy var & -0.10 & 0.26 & -0.65 \\ 
production vocabulary & 0.95 & -0.04 & 0.30 \\ 
comprehension vocabulary & 0.61 & -0.16 & -0.01 \\ 
age & 0.63 & -0.14 & 0.37 \\ 
\hline
\end{tabular}
\caption{\label{tab:loadings}Factor loadings for the exploratory three factor solution using varimax rotation.} 
\end{table}
```
# Factor Analysis: First Administrations

```{r}
d_sub_mat_firstadmin <- d_sub_firstadmin |>
  ungroup() |>
  select(dataset_name, log_rt, log_rt_var, long_window_accuracy, long_window_acc_var, prod, comp, age, log_age) 


d_sub_mat_firstadmin_s <- d_sub_mat_firstadmin |>
  ungroup() |>
  mutate(across(all_of(c("log_rt", "log_rt_var", "long_window_accuracy", 
                         "long_window_acc_var", "prod", "comp")), 
                ~ age_scale(.x, age))) 
```

```{r}
fit3_firstadmin <- cfa(fa3_model, d_sub_mat_firstadmin_s, 
                       std.lv=TRUE, missing='fiml')

fit_stats_firstadmin <- suppressMessages(summary(fit3_firstadmin, 
                                                 fit.measures=TRUE, 
                                                 standardize=TRUE))
```

```{r}
d_sub_mat_firstadmin_s_renamed <- d_sub_mat_firstadmin_s |>
  rename(acc = long_window_accuracy, 
         acc_sd = long_window_acc_var, 
         log_rt_sd = log_rt_var)

fit3_age_firstadmin <- cfa(fa3_age_model, 
                           d_sub_mat_firstadmin_s_renamed, 
                           std.lv=TRUE, missing='fiml')

fit3_age_summary_firstadmin <- 
  suppressMessages(summary(fit3_age_firstadmin, 
                           fit.measures=TRUE, 
                           standardize=TRUE))
```

```{r}
#remotes::install_github("dr-JT/semoutput")
library(semoutput)
semoutput::sem_fitmeasures(fit3)
semoutput::sem_fitmeasures(fit3_firstadmin)
semoutput::sem_fitmeasures(fit3_age)
semoutput::sem_fitmeasures(fit3_age_firstadmin)

```

# Alternative Factor Structures

In this section, we provide comparisons between the three-factor model we report in the main text and several alternative models, including:

-   a one-factor model;
-   a two-factor model with vocabulary separated from speed and accuracy;
-   a two-factor model with speed separated from accuracy and vocabulary; and
-   a two-factor model with variability terms separated from speed, accuracy, and vocabulary.

\noindent Table \ref{tab:modcomp} shows the result of these comparisons. The three-factor model shows the lowest AIC and BIC, as well as being significantly better fittign than the next-best model.

```{r, eval=FALSE}
fa1_model <-  "
F1  =~ log_rt + log_rt_var + long_window_accuracy + long_window_acc_var + prod + comp"
fa1_fit <- cfa(fa1_model, d_sub_mat_s, std.lv=TRUE, missing='fiml')

fa2_model <-  "
processing =~ log_rt + log_rt_var + long_window_accuracy + long_window_acc_var
vocabulary =~ prod + comp"
fa2_fit <- cfa(fa2_model, d_sub_mat_s, std.lv=TRUE, missing='fiml')

fa2b_model <-  "
accuracy =~ long_window_accuracy + long_window_acc_var + prod + comp
speed =~ log_rt + log_rt_var"
fa2b_fit <- cfa(fa2b_model, d_sub_mat_s, std.lv=TRUE, missing='fiml')

fa2v_model <-  "
language =~ log_rt + long_window_accuracy + prod + comp
variability =~  long_window_acc_var + log_rt_var"
fa2v_fit <- cfa(fa2v_model, d_sub_mat_s, std.lv=TRUE, missing='fiml')

fa3_model <-  "
speed =~ log_rt  + log_rt_var
accuracy =~ long_window_accuracy + long_window_acc_var 
vocab =~ prod + comp"
fa3_fit <- cfa(fa3_model, d_sub_mat_s, std.lv=TRUE, missing='fiml')

xtable(anova(fa1_fit, fa2_fit, fa2b_fit, fa2v_fit, fa3_fit), digits = 2)
```

<!-- xtable 1.8-4 package -->

<!-- % Fri Apr  4 15:15:52 2025 -->

```{=tex}
\begin{table}[ht]
\centering
\caption{Model comparison for alternative factor structures. $p$-values show differences between adjacent models; no $p$-values are shown for comparisons between non-nested models. \label{tab:modcomp}}
\begin{tabular}{lrrrrrrrr}
\hline
& Df & AIC & BIC & Chisq & Chisq diff & RMSEA & Df diff & Pr($>$Chisq) \\ 
\hline
Three-factor  & 6 & 46346.69 & 46475.43 & 91.96 &  &  &  &  \\ 
Two-factor (vocab)  & 8 & 46397.74 & 46514.22 & 147.01 & 55.05 & 0.09 & 2 & $<$ 0.0001 \\ 
Two-factor (speed) & 8 & 46486.96 & 46603.44 & 236.23 & 89.22 & 0.00 & 0 &  \\ 
Two-factor (variability) & 8 & 46536.10 & 46652.58 & 285.37 & 49.14 & 0 & 0 &  \\ 
One-factor & 9 & 46535.49 & 46645.84 & 286.76 & 1.39 & 0.01 & 1 & 0.24 \\ 
\hline
\end{tabular}
\end{table}
```
# Non-linear Growth Models

To test for the differentiation of vocabulary growth based on initial reaction time, we used the package `nlme` to fit a logistic growth model to the production data. This model has two parameters for the logistic curve, a scale and an intercept. Both were allowed to interact with initial reaction time. We also included random effects of logistic intercept and scale by participant and a grouping term across datasets. This model showed a significant effect of initial reaction time on the intercept of the logistic growth curve, but not on its scale (see Table \ref{tab:nlme}).

```{r}
# xtable(summary(mod_nlme)$tTable)
```

<!-- % latex table generated in R 4.4.2 by xtable 1.8-4 package -->

<!-- % Thu Mar 13 13:10:30 2025 -->

```{=tex}
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
\hline
& Value & Std Error & DF & $t$-value & $p$-value \\ 
\hline
Growth Intercept & 2.26 & 2.70 & 1766.00 & 0.84 & 0.40 \\ 
Growth Intercept $\times$ $t_0$ RT & 3.30 & 0.38 & 1766.00 & 8.59 & < 0.0001 \\ 
Growth Scale & 2.05 & 2.60 & 1766.00 & 0.79 & 0.43 \\ 
Growth Scale $\times$ $t_0$ RT & 0.28 & 0.38 & 1766.00 & 0.75 & 0.46 \\ 
\hline
\end{tabular}
\caption{Fixed effects estimates from logistic growth model. \label{tab:nlme}}
\end{table}
```
Interpretation of growth in both this model and the linear growth model in the main text is complicated by the fact that the CDI form puts a ceiling on the total number of words that can be recorded; both the quadratic growth functions and the logistic functions come together at the form ceiling. Thus, a shift in quadratic growth in the linear model and a shift in intercept in the logistic model both point to the same overall effect, which is faster growth at the point of maximal sensitivity of the CDI. Neither model can estimate whether the overall growth trajectory is different beyond the range of the CDI. Thus, although these models might initially seem to be in conflict, we believe that they actually point to the same phenomenon, which is perhaps better described by the longitudinal SEM model reported in the main text. Children with greater skill in word recognition show an overall positive shift in the growth trajectory of vocabulary development.

FIXME

```{r}
d_sub_prod <- filter(d_sub, !is.na(prod), !is.na(log_rt)) |>
  ungroup() |>
  mutate(log_rt_resid = resid(lm(log_rt ~ log_age))) |>
  group_by(subject_id) |>
  mutate(log_rt_0 = log_rt[1],
         log_rt_0_resid = log_rt_resid[1],
         acc_0 = long_window_accuracy[1]) |> 
  filter(!is.na(log_rt_0)) 


mod_nlme <- nlme(model = prod ~ SSlogis(age, Asym = 1, xmid, scale),
                 data = d_sub_prod,
                 fixed = xmid + scale ~ log_rt_0_resid,
                 random = xmid + scale ~ 1 | subject_id,
                 groups = ~ dataset_name,
                 start = c(xmid = 20, scale = 3, `xmid:log_rt_0_resid` = 1, `scale:log_rt_0_resid` = 3),
                 na.action = na.exclude, 
                 control = list(maxIter = 1000, tolerance = .1))

summary(mod_nlme)

# fixed
global_preds <- expand_grid(age = seq(min(d_sub_prod$age), 
                                      max(d_sub_prod$age), .1), 
                            log_rt_0_resid = c(quantile(d_sub_prod$log_rt_0_resid, 
                                                        c(.25,.75), 
                                                        na.rm=TRUE)))
global_preds$pred <- predict(mod_nlme, newdata = global_preds, level = 0)


#random effects
dataset_preds <- d_sub |>
  filter(!is.na(prod)) |> # filter on predictor
  group_by(dataset_name) |>
  summarise(min_age = min(age),
            max_age = max(age)) |>
  group_by(dataset_name) |>
  mutate(df = map2(min_age, max_age, ~expand_grid(age = seq(.x, .y, .1), log_rt_0_resid = c(quantile(d_sub_prod$log_rt_0_resid, 
                                                                                                     c(.25,.75), 
                                                                                                     na.rm=TRUE))))) |>
  select(-min_age, -max_age) |>
  unnest(col = "df") |>
  ungroup()


dataset_preds$pred <- predict(mod_nlme,
                              newdata = dataset_preds,
                              level = c(0,1))$predict.dataset_name

ggplot(d_sub_prod, aes(x = age, y = prod, col = as.factor(log_rt_0_resid))) + 
  geom_point(alpha = .03, pch = ".", col = "black") + 
  geom_line(aes(group = subject_id), alpha = .02, col = "black") + 
  geom_line(data = dataset_preds |>   
              filter(dataset_name %in% datasets_with_age_variation$dataset_name), 
            aes(y = pred, group = interaction(log_rt_0_resid, dataset_name)), lty="dashed", alpha=.5)+
  geom_line(data = global_preds, aes(y = pred, group = log_rt_0_resid, col = as.factor(log_rt_0_resid)), size=1)+
  scale_color_viridis(discrete=T, option = "H")+
  theme(legend.position = "none")+
  labs(y="Production", x="Age in months")

```

```{r}
library(brms)

d_sub_prod$age_c <- d_sub_prod$age - mean(d_sub_prod$age, na.rm = TRUE)
d_sub_prod$log_rt_0_c <- d_sub_prod$log_rt_0 - mean(d_sub_prod$log_rt_0, na.rm = TRUE)


# Define the nonlinear formula
nlform <- brms::bf(
  prod ~ 1 / (1 + exp((xmid - age_c) / exp(logscale))),
  xmid ~ 1 + log_rt_0_c  + (1 | dataset_name/subject_id),
  logscale ~ 1 + log_rt_0_c  + (1 | dataset_name/subject_id),
  # scale ~ 1 + log_rt_0_c,
  nl = TRUE
)

# xmid ~ 1 + log_rt_0_c + (1 | dataset_name/subject_id),
# scale ~ 1 + log_rt_0_c + (1 | dataset_name/subject_id),


priors <- c(
  prior(normal(0, 5), nlpar = "xmid", coef = "Intercept"),  # xmid near center of age_c
  prior(normal(1, 1), nlpar = "logscale", coef = "Intercept"), # scale > 0, mildly steep curve
  prior(normal(0, 1), nlpar = "logscale", coef = "log_rt_0_c"),
  prior(exponential(1), class = "sigma"),                # residual error
  prior(normal(0, 2), nlpar = "xmid", coef = "log_rt_0_c"),
  # prior(normal(0, 1), nlpar = "scale", lb = 0)
  
  # Random effects for xmid
  prior(exponential(1), class = "sd", nlpar = "xmid", group = "dataset_name"),
  prior(exponential(1), class = "sd", nlpar = "xmid", group = "dataset_name:subject_id"),
  
  # Random effects for scale
  prior(exponential(1), class = "sd", nlpar = "logscale", group = "dataset_name"),
  prior(exponential(1), class = "sd", nlpar = "logscale", group = "dataset_name:subject_id")
)
#

# Fit the model
mod_brms <- brm(
  formula = nlform,
  data = d_sub_prod,
  prior = priors,
  family = gaussian(),
  # init = 0,  # initialize all parameters to 0 on unconstrained scale (safe for centered priors)
  chains = 4, cores = 4,
  control = list(adapt_delta = 0.95),
  # backend = "cmdstanr",  # optional but faster
  save_pars = save_pars(all = TRUE),
  sample_prior = "yes"
)


new_data <- expand.grid(
  age_c = seq(min(d_sub_prod$age_c), max(d_sub_prod$age_c), length.out = 100),
  log_rt_0_c = c(-1, 0, 1)  # e.g., low, mean, high values
)

fitted_vals <- fitted(mod_brms, newdata = new_data, re_formula = NA, summary = TRUE)


new_data$fit <- fitted_vals[, "Estimate"]
new_data$lower <- fitted_vals[, "Q2.5"]
new_data$upper <- fitted_vals[, "Q97.5"]

ggplot(new_data, aes(x = age_c, y = fit, col = as.factor(log_rt_0_c))) +
  geom_line(linewidth = 2) +
  geom_ribbon(aes(ymin = lower, ymax = upper, fill = as.factor(log_rt_0_c), group = as.factor(log_rt_0_c)), 
              alpha = 0.2) +
  labs(x = "Centered Age", y = "Predicted prod (fixed effects only)") +
  theme_minimal() + 
  geom_point(data = d_sub_prod, aes(x = age_c, y = prod), col = "black") + 
  scale_color_solarized(name = "log RT at t0 (SD)") + 
  scale_fill_solarized(guide = FALSE)

```

```{r}
library(brms)

d_sub_prod$age_c <- d_sub_prod$age - mean(d_sub_prod$age, na.rm = TRUE)
d_sub_prod$log_rt_0_c <- d_sub_prod$log_rt_0 - mean(d_sub_prod$log_rt_0, na.rm = TRUE)

d_sub_prod$resid_log_rt_0_c <- resid(lm(log_rt_0_c ~ log(age), data = d_sub_prod))


# Define the nonlinear formula
nlform_resid <- brms::bf(
  prod ~ 1 / (1 + exp((xmid - age_c) / exp(logscale))),
  xmid ~ 1 + resid_log_rt_0_c  + (1 | dataset_name/subject_id),
  logscale ~ 1 + resid_log_rt_0_c  + (1 | dataset_name/subject_id),
  # scale ~ 1 + log_rt_0_c,
  nl = TRUE
)

# xmid ~ 1 + log_rt_0_c + (1 | dataset_name/subject_id),
# scale ~ 1 + log_rt_0_c + (1 | dataset_name/subject_id),


priors_resid <- c(
  prior(normal(0, 5), nlpar = "xmid", coef = "Intercept"),  # xmid near center of age_c
  prior(normal(1, 1), nlpar = "logscale", coef = "Intercept"), # scale > 0, mildly steep curve
  prior(normal(0, 1), nlpar = "logscale", coef = "resid_log_rt_0_c"),
  prior(exponential(1), class = "sigma"),                # residual error
  prior(normal(0, 2), nlpar = "xmid", coef = "resid_log_rt_0_c"),
  # prior(normal(0, 1), nlpar = "scale", lb = 0)
  
  # Random effects for xmid
  prior(exponential(1), class = "sd", nlpar = "xmid", group = "dataset_name"),
  prior(exponential(1), class = "sd", nlpar = "xmid", group = "dataset_name:subject_id"),
  
  # Random effects for scale
  prior(exponential(1), class = "sd", nlpar = "logscale", group = "dataset_name"),
  prior(exponential(1), class = "sd", nlpar = "logscale", group = "dataset_name:subject_id")
)
#

# Fit the model
resid_mod_brms <- brm(
  formula = nlform_resid,
  data = d_sub_prod,
  prior = priors_resid,
  family = gaussian(),
  # init = 0,  # initialize all parameters to 0 on unconstrained scale (safe for centered priors)
  chains = 4, cores = 4,
  control = list(adapt_delta = 0.95),
  # backend = "cmdstanr",  # optional but faster
  save_pars = save_pars(all = TRUE),
  sample_prior = "yes"
)


new_data_resid <- expand.grid(
  age_c = seq(min(d_sub_prod$age_c), max(d_sub_prod$age_c), length.out = 100),
  resid_log_rt_0_c = c(-1, 0, 1)  # e.g., low, mean, high values
)

fitted_vals <- fitted(mod_brms, newdata = new_data, re_formula = NA, summary = TRUE)


new_data_resid$fit <- fitted_vals[, "Estimate"]
new_data_resid$lower <- fitted_vals[, "Q2.5"]
new_data_resid$upper <- fitted_vals[, "Q97.5"]

ggplot(new_data_resid, aes(x = age_c, y = fit, col = as.factor(resid_log_rt_0_c))) +
  geom_line(linewidth = 2) +
  geom_ribbon(aes(ymin = lower, ymax = upper, fill = as.factor(resid_log_rt_0_c), group = as.factor(resid_log_rt_0_c)), 
              alpha = 0.2) +
  labs(x = "Centered Age", y = "Predicted prod (fixed effects only)") +
  theme_minimal() + 
  scale_color_viridis() + 
  geom_point(data = d_sub_prod, aes(x = age_c, y = prod), col = "black")

```

# SEM Longitudinal Missingness

FIXME

```{r}
colMeans(!is.na(d_sub_wide_fine))
```

# Additional References

Heathcote, A., Brown, S., & Mewhort, D. J. K. (2000). The power law repealed: The case for an exponential law of practice. Psychonomic Bulletin & Review, 7(2), 185–207.

Creel, S. (2024). Connecting the tots: Strong looking-pointing correlations in preschoolers' word learning and implications for continuity in language development. Child Development, 96, 87-103.
