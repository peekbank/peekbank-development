---
title: Continuous developmental changes in word recognition across early childhood support early language learning

# Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
author:
  - name: Alice Anonymous
    affiliation: a,1,2
  - name: Bob Security
    affiliation: a,b
address:
  - code: a
    address: Some Institute of Technology, Department, Street, City, State, Zip
  - code: b
    address: Another University Department, Street, City, State, Zip

corresponding_author:
  code: 2
  text: "To whom correspondence should be addressed. E-mail: bob@email.com"

# For footer text
lead_author_surname: Anonymous

author_contributions: |
  Please provide details of author contributions here.

abstract: |
  Being a fluent language user involves understanding language as it unfolds in time. How does this skill develop over the course of early childhood?  And how does facility in word recognition relate to the growth of vocabulary?  We address these questions using data from Peekbank, an open database of eye-tracking experiments on children's early word recognition.  Combining 24 datasets with data from almost 2,000 children ages 1--6 years, we show that word recognition becomes faster, more accurate, and less variable across development, both within and across studies. Factor analysis reveals a cross-sectional coupling of word recognition speed and accuracy to parent-reported vocabulary as well as a longitudinal relationship such that children with faster language processing tend to show larger vocabulary growth. Together, these findings support the view that language processing is –– among other things –– a skill, and that this skill plays a role in early language learning. 


significance: |
  Early language development is a key part of children's development that also sets the stage for later academic success. The efficiency with which children recognize words provides a measurement of their real-time language processing, which has been argued to be a key part of the learning process. Here we use a large dataset of eye-tracking data from many different experiments to map out the development of word recognition, finding that this process becomes faster, more accurate, and less variable in the period between one and six years of age, and that children who are better at word recognition tend to have larger and faster growing vocabularies. Understanding language is a skill that improves gradually with practice.

acknowledgements: |
  This work was supported by a grant from the Jacobs Foundation. 

keywords:
  - one
  - two
  - optional
  - optional
  - optional

## must be one of: pnasresearcharticle (usual two-column layout), pnasmathematics (one column layout), or pnasinvited (invited submissions only)
pnas_type: pnasresearcharticle

bibliography: peekbank.bib
csl: pnas.csl

## change to true to add optional line numbering
lineno: false

output: rticles::pnas_article
---


\dropcap{C}hildren acquiring a language are learning a body of knowledge -- a set of words and the ways they are combined -- but they are also learning to deploy this knowledge in the myriad complex, noisy, and fast-moving environments in which language is used. As children enter their second year, language explodes onto the scene; both vocabulary and grammatical abilities grow rapidly and in tandem [@bates1994developmental;@frank2021]. This growth in knowledge is also accompanied by changes in  language processing: children become quicker and more accurate in recognizing words and matching them with their referents [@fernald1998;@peter2019;@bergelson2020comprehension].

Yet unlike language production, which is manifest via overt behavior, evidence for word recognition is often more subtle. Very young children with incomplete knowledge may not be able to point to the correct referent of a word, but they may still have some representation of word meaning [@bergelson2012]. Eye tracking has thus emerged as a key method that allows the measurement of language comprehension with high temporal resolution: both adults and children reliably fixate the referent of a word soon after it is used [@tanenhaus1995integration;@altmann1999incremental;@fernald1998;@fernald2008;@macdonald2018]. The relative timecourse of fixation then can provide an index of both the comprehender's ability and the properties of the stimulus. 


\begin{table*}[h!]
\centering
\begin{tabular}{rlrrrrrrrll}
  \hline
 & dataset\_name & N subjects & N admins & Mean Age & Min Age & Max Age & Avg Trials & Avg RT Trials & CDIs & longitudinal \\ 
  \hline
1 & reflook\_v4 & 310 & 310 & 36.82 & 12.24 & 60.00 & 6.21 & 2.87 &  &  \\ 
  2 & yurovsky\_2017 & 282 & 282 & 25.64 & 12.59 & 58.65 & 5.95 & 2.79 &  &  \\ 
  3 & weaver\_zettersten\_2024 & 141 & 248 & 15.73 & 13.50 & 23.60 & 18.10 & 6.72 & x & x \\ 
  4 & fernald\_marchman\_2012 & 122 & 678 & 23.92 & 17.00 & 32.00 & 16.78 & 7.17 & x & x \\ 
  5 & sander-montant\_2022 & 122 & 122 & 21.94 & 12.02 & 31.11 & 10.07 & 4.20 & x &  \\ 
  6 & frank\_tablet\_2016 & 104 & 104 & 33.89 & 12.13 & 59.84 & 5.87 & 2.74 &  &  \\ 
  7 & baumgartner\_2014 & 100 & 100 & 12.01 & 12.00 & 13.00 & 4.00 & 2.31 & x &  \\ 
  8 & fmw\_2013 &  80 & 179 & 20.04 & 17.00 & 26.00 & 21.26 & 8.44 & x & x \\ 
  9 & adams\_marchman\_2018 &  69 & 711 & 23.57 & 12.00 & 38.00 & 18.44 & 7.92 & x & x \\ 
  10 & potter\_canine &  67 &  67 & 23.76 & 21.00 & 27.00 & 10.38 & 3.80 & x &  \\ 
  11 & fernald\_totlot &  63 & 229 & 19.68 & 15.00 & 25.00 & 15.22 & 6.05 & x & x \\ 
  12 & pomper\_prime &  63 &  63 & 39.73 & 37.90 & 42.00 & 12.98 & 5.34 &  &  \\ 
  13 & pomper\_saffran\_2016 &  60 &  60 & 44.27 & 41.00 & 47.00 & 7.55 & 3.30 &  &  \\ 
  14 & swingley\_aslin\_2002 &  50 &  50 & 15.09 & 14.13 & 16.00 & 11.74 & 3.79 & x &  \\ 
  15 & pomper\_salientme &  44 &  44 & 40.11 & 38.00 & 43.00 & 5.30 & 2.34 &  &  \\ 
  16 & perry\_cowpig &  42 &  42 & 20.45 & 19.00 & 22.00 & 14.88 & 5.43 &  &  \\ 
  17 & ronfard\_2021 &  40 &  40 & 19.95 & 18.00 & 24.00 & 18.54 & 7.62 & x &  \\ 
  18 & bacon\_gendercues &  38 &  38 & 22.87 & 22.00 & 24.00 & 18.16 & 8.00 & x &  \\ 
  19 & garrison\_bergelson\_2020 &  35 &  35 & 14.46 & 12.00 & 18.00 & 27.94 & 9.59 & x &  \\ 
  20 & pomper\_yumme &  32 &  32 & 26.38 & 25.00 & 28.00 & 7.62 & 2.31 &  &  \\ 
  21 & mahr\_coartic &  29 &  29 & 20.83 & 18.10 & 23.80 & 24.38 & 8.86 & x &  \\ 
  22 & ferguson\_eyetrackingr &  28 &  28 & 19.71 & 18.02 & 21.86 & 5.54 & 2.33 & x &  \\ 
  23 & potter\_remix &  23 &  44 & 22.59 & 18.00 & 29.00 & 6.07 & 2.58 & x & x \\ 
  24 & newman\_genderdistractor &  19 &  19 & 30.12 & 29.23 & 30.84 & 13.11 & 4.94 &  &  \\ 
   \hline
\end{tabular}
\caption{Characteristics of included datasets from Peekbank. `Admins` denotes separate experimental sessions.\label{tab:datasets}} 
\end{table*}

The version of this method that is used with children goes by many names, including the intermodal preferential looking paradigm and the "looking while listening" paradigm (LWL, the name we adopt here) [@hirsh1996intermodal;@reznick1990visual;@fernald2008]. In LWL experiments, children are typically shown a series of trials in which two images are displayed side by side and they are asked to find one of them. For example, a ball and a book might be shown, and the child might hear "Look at the ball! Can you find it?". Accuracy is then computed as the proportion of time they fixate the correct image within a fixed window after the onset of the noun ("ball" in this case). Reaction time is computed only on trials in which the child is fixating the distractor image (the book); in these cases, the average time it takes to shift fixation to the target is used as an index of processing speed. Early work using this method showed that children's speed and accuracy both increase rapidly across the second year [@fernald1998;@reznick1990visual], and related methods have provided a window into how children process phonological [@mani2011], syntactic [@trueswell1999kindergarten], and semantic [@mani2010;@bergelson2017] competition as well as how their lexical representations develop [@Swingley2002].

Word recognition ability is hypothesized to play a key role in language learning. Each word that a child experiences is an opportunity to learn; measurements of children's language input at home are consistently associated with their vocabulary size [@hart1995meaningful;@anderson2021linking]. These learning opportunities are likely helpful to different degrees, however [@kachergis2022toward;@mcmurray2007defusing]. 
<!-- Language input is more helpful for learning if it focused on the child's own interest and grounded in the particulars of their current environment -- for example, in a game, routine, or object -- and if it uses vocabulary and syntax that they know [@tomasello2001perceiving;@roy2015predicting;@cartmill2013quality].  -->
Recognizing incoming words and linking them with their referents is a prerequisite for learning. Consider a child hearing the utterance "can you put the ball in the box?" The faster and more accurately the child can recognize that the ball is a referent, the better they can use this evidence to help infer the speaker's intended meaning, perhaps making inferences about the meaning of "put" or "box" [@frank2009using]. Consistent with this idea, one important study found that children's word recognition speed mediated the relationship between home language input and vocabulary growth [@Weisleder2013].

Speed of word recognition has been used as an index of individual differences in early childhood [@fernald2006;@marchman2008;@peter2019;@fernald2012;@newbury2016interrelationships] and beyond [@colby2023efficiency;@jeppsen2022development;@mcmurray2022slow]. Word recognition speed at 18 months can predict children's later language ability over and above measures of vocabulary size [@marchman2008], though these predictions may be limited to particular ages or processing assessments [@peter2019]. Further, faster processing at age two is predictive of whether "late talkers" catch up to their peers or require further intervention [@fernald2012].  Critically, all of these assessments use words that children are reported to understand and produce -- they are not indices of vocabulary size but rather of how quickly and accurately they can recognize a spoken word and use it to guide their visual attention to a referent. 

<!-- % MCF: is this question statement sharp enough?  -->

Yet individual experiments measuring processing with young children typically recruit relatively small samples in a restricted range of ages. These samples provide neither the breadth of ages nor the number of participants to estimate the broader dynamics of how word recognition changes developmentally and how it connects with other aspects of language [as has been done with school-aged children: @mcmurray2022slow;@colby2023efficiency]. Here we investigate two hypotheses. 
First, one influential recent hypothesis characterizes language learning more broadly as a process of learning the skill of real-time processing  [@christiansen2016;@chater2018]. On this hypothesis, we should expect to see the signatures of expertise and skill learning in word recognition. We expect that accuracy will change linearly with the logarithm of age, reflecting gradual asymptotic convergence to mature levels of accuracy. In addition, the logarithm of processing speed should also decrease with the logarithm of age, potentially reflecting the  "power law of practice" [@snoddy1926;@kail1991;@anderson1982; cf @heathcote2000]. Further, trial-to-trial variability in both speed and accuracy should decrease with increasing expertise [@todorov2002optimal]. 

Second, previous findings have provided limited and sometimes conflicting evidence on the concurrent and predictive relations between word recognition and language learning. Initial reports showed strong predictive relationships between both speed and accuracy and later vocabulary growth [@fernald2006]. Two other studies extended this result to infants born preterm [@fernald2012] and to late talkers [@marchman2016]. Subsequent studies have primarily focused on speed of processing and found more mixed results, with reaction time measures only inconsistently predictive of later vocabulary outcomes [@peter2019;@newbury2016interrelationships;@lany2017]. To the extent that there are consistent relations between vocabulary and word recognition, these should be visible in a larger dataset. Further, by examining the relationship between speed, accuracy, and vocabulary, it should be possible to assess the extent to which processing speed specifically plays a role in vocabulary growth.


```{r loading, echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(psych))
suppressPackageStartupMessages(library(lmerTest))
suppressPackageStartupMessages(library(lavaan))
suppressPackageStartupMessages(library(tidySEM))
suppressPackageStartupMessages(library(xtable))
suppressPackageStartupMessages(library(papaja))

source(here("helper","common.R"))

d_trial <- readRDS(here("cached_intermediates","1_d_trial.Rds")) |>
  mutate(log_age = log(age))
d_sub <- readRDS(here("cached_intermediates","1_d_sub.Rds")) |>
  group_by(subject_id) |>
  arrange(age) |>
  mutate(admin_num = 1:n(), 
         time_since_t0 = age - age[1],
         delta_t = c(0, diff(age)))

d_trial$age_s <- scale(d_trial$age)[,1]
d_trial$log_age_s <- scale(d_trial$log_age)[,1]   
d_sub$age_s <- scale(d_sub$age)[,1]
d_sub$log_age_s <- scale(d_sub$log_age)[,1]   


AGEVAR_CUTOFF <- 6

knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE)
```


To address these questions, we made use of a new release of data in Peekbank, an open database of  looking while listening data from young children, stored in a harmonized format [@zettersten2023peekbank]. We retrieved data from children ages 1--6 years. Although experiments in Peekbank include a variety of different experimental manipulations, we analyzed data only from simple word recognition trials in which children were shown two pictures of concrete objects and heard a word; these trials often constituted control conditions for experiments. We focus here on English purely for practical reasons -- the Peekbank dataset contains limited data from other languages. 

These criteria yielded `r length(unique(d_sub$dataset_name))` datasets, including `r length(unique(d_sub$subject_id))` children and `r length(unique(d_sub$administration_id))` administrations of the LWL procedure (some datasets were longitudinal or involved multiple closely-spaced testing sessions). Table \ref{tab:datasets} shows the characteristics of individual datasets (see also Figures S1 and S2). The size of the combined dataset, the unified data processing pipeline, and the fact that individual studies used very similar implementations of the LWL experimental paradigm, all allowed us to make a more detailed exploration of the development of word recognition than has previously been possible.


```{r dataset_table}
dataset_characteristics <- d_sub |>
  group_by(dataset_name) |>
  summarise(`N subjects` = length(unique(subject_id)),
            `N admins` = n(), 
            `Mean Age` = mean(age), 
            `Min Age` = min(age), 
            `Max Age` = max(age), 
            `Avg Trials` = mean(n_trials[!is.na(long_window_accuracy)]),
            `Avg RT Trials` = mean(n_trials_rt[!is.na(rt)]),
            `CDIs` = ifelse(!is.na(any(prod)), "x", ""), 
            `longitudinal` = ifelse(any(duplicated(subject_id)), "x", "")) |>
  arrange(desc(`N subjects`)) 
```

```{r eval=FALSE}
xtable(dataset_characteristics, 
       caption = "Characteristics of included datasets from Peekbank. `Admins` denotes separate experimental sessions.")
```


# Results {.unnumbered}


## Speed and accuracy of word recognition increase {.unnumbered}


```{r acc_mods}
d_trial$age_s <- scale(d_trial$age)[,1]
d_trial$log_age_s <- scale(d_trial$log_age)[,1]   

acc_mods_lmer <- list(lwa_lin = lmer(long_window_accuracy ~ age_s  +
                                     + (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                      lwa_log = lmer(long_window_accuracy ~ log_age_s +
                                     + (log_age_s | dataset_name) + (1 | subject_id), data = d_trial),
                      swa_lin = lmer(short_window_accuracy ~ age_s  +
                                     + (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                      swa_log = lmer(short_window_accuracy ~ log_age_s +
                                     + (log_age_s | dataset_name) + (1 | subject_id), data = d_trial))

acc_mods_lmer_summary <- map_df(acc_mods_lmer, ~broom.mixed::glance(.x)) |>
  mutate(model = names(acc_mods_lmer), 
         r2 = map_dbl(acc_mods_lmer, ~performance::r2_nakagawa(.x)$R2_conditional))
```


```{r rt_mods}
rt_mods_lmer <- list(log_lin = lmer(log_rt ~ age_s + 
                                      (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                     log_log = lmer(log_rt ~ log_age_s + 
                                      (log_age_s | dataset_name) + (1 | subject_id), data = d_trial),
                     lin_lin = lmer(rt ~ age_s + 
                                      (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                     lin_log = lmer(rt ~ log_age_s +  
                                      (log_age_s | dataset_name) + (1 | subject_id), data = d_trial))

rt_mods_lmer_summary <- map_df(rt_mods_lmer, ~broom.mixed::glance(.x)) |>
  mutate(model = names(rt_mods_lmer), 
         r2 = map_dbl(rt_mods_lmer, ~performance::r2_nakagawa(.x)$R2_conditional))
```

We were first interested in developmental changes in speed and accuracy. We computed both reaction times and accuracies following standard practices in the literature [@fernald2008]. Because there is no consensus about the length of time windows for the computation of accuracy, we considered both a shorter window (from 200 -- 2200 ms after noun onset) and a longer window (from 200 -- 4000 ms). 
Our first question was about the functional form of the relationships between age, speed, and accuracy (see Table S-XYZ for raw correlations between variables). To investigate this question, we fit linear mixed effects models predicting accuracy and reaction time on each trial across the full dataset with random slopes of age by study and random intercepts by participant. We compared models that included both long and short accuracy windows, as well as logarithmic and linear effects of age, and logarithmic and linear transformations of reaction time. The best fitting model of accuracy predicted long window accuracy as a function of the logarithm of age,^[This longer window yielded overall higher cross-trial reliability as well, and so we report long window results in the main text. All findings reported here hold for both window sizes, however (see SI: Short Window Analyses).] and the best fitting model of speed predicted log reaction time as a function of log age as well (See Tables S1 and S2 for model fit statistics). 

Figure \ref{fig:devchange} shows these relationships. Log reaction time decreased significantly with age (`r papaja::apa_print(rt_mods_lmer[[2]])$full_result$log_age_s`) and accuracy increased significantly with age  (`r papaja::apa_print(acc_mods_lmer[[2]])$full_result$log_age_s`). In sum, we see continuing improvements in word recognition across the full age range in our dataset that appear roughly linear in the logarithm of age.  These logarithmic relationships follow theoretical expectations that both speed and accuracy should gradually asymptote to mature levels of performance as in skill learning more generally [@anderson1982,@snoddy1926]. 
<!-- With our current dataset we cannot specifically determine whether within-individual patterns of change conform to power law or exponential forms [@kail1991,@heathcote2000], but regardless we see clear patterns of developmental change related to skill acquisition. -->

```{r devchange, fig.cap="Participant-level accuracy and reaction time (log), plotted by age (log). The solid green line shows a linear fit and associated confidence interval. Individual dotted lines show linear fits for those datasets spanning six or more months of age. The dashed line for accuracy shows chance-level looking (.5)", fig.env="figure*", fig.height = 2.5}

datasets_with_age_variation <- d_trial |>
  group_by(dataset_name) |>
  summarise(age_range = max(age) - min(age)) |>
  filter(age_range >= AGEVAR_CUTOFF)

d_sub_agevar <- d_sub |>
  filter(dataset_name %in% datasets_with_age_variation$dataset_name)

a <- ggplot(d_sub,
       aes(x = age, y = long_window_accuracy)) + 
  geom_point(alpha = .05) + 
  geom_smooth(method = "lm") +
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .5, lty = 2) + 
  geom_hline(yintercept = .5, lty = 2) + 
  scale_x_log10() +
  scale_color_discrete(guide = FALSE) + 
  ylab("Accuracy") + 
  xlab("Age (months)")

b <- ggplot(d_sub,
       aes(x = age, y = rt)) + 
  geom_point(alpha = .05) + 
  geom_smooth(method = "lm") +
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .5, lty = 2) + 
  scale_x_log10() +
  scale_y_log10() +
  scale_color_discrete(guide = FALSE) + 
  theme(legend.position = "bottom") + 
  ylab("Reaction Time (log)") + 
  xlab("Age (months)")

cowplot::plot_grid(a,b)
```

## Variability of word recognition decreases {.unnumbered}

```{r var_mods}
acc_var_mod <- lmer(long_window_acc_var ~ log_age_s + (log_age_s | dataset_name) + 
                 (1 | subject_id), 
               data = d_sub)


rt_var_mod <- lmer(log_rt_var ~ log_age_s + (log_age_s | dataset_name) + 
                 (1 | subject_id), 
               data = d_sub)
```

One further hallmark of increasing skill is a decrease in task-relevant variability [@todorov2002optimal]. Both within and across datasets, variation in accuracy and reaction time decreased across datasets, again relatively continuously across the developmental range we examined (Figure \ref{fig:variance}). We fit mixed effects models to the standard deviation of both accuracy and reaction time for each testing session for each participant, including random slopes of log age by dataset and random intercepts for each participant. For both speed and accuracy, variability decreased with age (RT: `r papaja::apa_print(rt_var_mod)$full_result$log_age_s`; accuracy: `r papaja::apa_print(acc_var_mod)$full_result$log_age_s`). Thus, as well as being faster and more accurate, older children appear to be more consistent in their online word recognition.

```{r variance, fig.cap="Participant-level variability in accuracy and reaction time (log RT), plotted by age (log). Plotting conventions are as in Figure 1.", fig.env="figure*", fig.height = 2.5}
c <- ggplot(d_sub,
       aes(x = age, y = long_window_acc_var)) + 
  geom_point(alpha = .05) + 
  geom_smooth(method = "lm") +
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .5, lty = 2) + 
  scale_x_log10() +
  scale_color_discrete(guide = FALSE) + 
  ylab("SD of Accuracy)") + 
  xlab("Age (months)")

d <- ggplot(d_sub,
       aes(x = age, y = log_rt_var)) + 
  geom_point(alpha = .05) + 
  geom_smooth(method = "lm") +
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .5, lty = 2) + 
  scale_x_log10() +
  scale_color_discrete(guide = FALSE) + 
  theme(legend.position = "bottom") + 
  ylab("SD of log RT)") + 
  xlab("Age (months)")

cowplot::plot_grid(c,d)
```


## Speed and accuracy relate to vocabulary size {.unnumbered}

We were next interested in whether the various different aspects of word recognition -- including accuracy, reaction time, and the variability of each of these -- were related to other aspects of early language ability. Of the studies in our database, `r sum(str_length(dataset_characteristics$CDIs)>0)` gathered parent reports about children's early vocabulary using the MacArthur-Bates Communicative Development Inventory (CDI), a popular survey instrument that provides a reliable and valid holistic picture of children's early language [@marchman2023;@frank2021]. Different forms of the CDI can be used to measure either receptive and expressive vocabulary (for children up to 18 months) or expressive vocabulary only (for children 16 -- 30 months). 

```{r efa}
d_sub_mat <- d_sub |>
  ungroup() |>
  select(dataset_name, log_rt, log_rt_var, long_window_accuracy, long_window_acc_var, prod, comp, age, log_age) 


d_sub_mat_s <- d_sub_mat |>
  ungroup() |>
  mutate(across(all_of(c("log_rt", "log_rt_var", "long_window_accuracy", 
                         "long_window_acc_var", "prod", "comp")), 
                       ~ age_scale(.x, age))) 

parallel_ana <- capture.output(fa.parallel(select(d_sub_mat, -dataset_name, -age, -log_age), fa = "fa", 
            use = "pairwise.complete.obs", plot=FALSE))
```

```{r cfa}
fa3_model <- "vocab =~ prod + comp
              accuracy =~ long_window_accuracy + long_window_acc_var
              speed =~ log_rt + log_rt_var"

fit3 <- cfa(fa3_model, d_sub_mat_s, std.lv=TRUE, missing='fiml')

fit_stats <- suppressMessages(summary(fit3, fit.measures=TRUE, standardize=TRUE))
```

We fit a series of factor analytic models to explore the dimensionality of the data. Initial exploratory factor analysis using paralell analysis suggested that three factors explained substantial variance in the data (see SI: Factor Analysis). Due to missingness of data, we used confirmatory factory analysis with full information maximum likelihood to find the best set of loadings. The best fitting model was a three-factor model with factors for speed (reaction time and reaction time variability), accuracy (accuracy and accuracy variability), and vocabulary (comprehension and production from the CDI). Fit statistics for this model were generally good (Confirmatory fit index: `r round(fit_stats$fit["cfi"], 3)`, RMSE: `r round(fit_stats$fit["rmsea"], 3)`)`; see SI: Alternative Factor Structures). 


```{r age_regression, fig.env="figure*", fig.cap="Structural equation model showing the three-factor factor analysis with a regression of each latent variable on the logarithm of age. Observed variables are notated as squares and latent variables are notated as circles Factor loadings and regression coefficients are shown with straight, solid lines; covariances are shown with dashed lines; residual variances are shown as solid circular connections. Stars show conventional levels of statistical significance, e.g. * indicates p < .05, ** indicates p < .01, and *** indicates p < .001. Covariances reflect age-residualized correlations between variables. Abbreviations: acc = accuracy, prod = production vocabulary, comp = comprehension vocabulary.", fig.height = 3}

d_sub_mat_s_renamed <- d_sub_mat_s |>
  rename(acc = long_window_accuracy, 
         acc_sd = long_window_acc_var, 
         log_rt_sd = log_rt_var)

fa3_age_model <- "
# measurement model
vocab =~ prod + comp
accuracy =~ acc + acc_sd
speed =~ log_rt + log_rt_sd

# regressions
vocab ~ log_age
accuracy ~ log_age
speed ~ log_age
"

fit3_age <- cfa(fa3_age_model, d_sub_mat_s_renamed, std.lv=TRUE, missing='fiml')

fit3_age_summary <- suppressMessages(summary(fit3_age, fit.measures=TRUE, standardize=TRUE))
layout_age = matrix(nrow=5, ncol = 6,
                data = c(NA,NA,"log_age",NA, NA, NA,
                         NA, NA, NA, NA, NA, NA, 
                         "speed",NA,"accuracy",NA,"vocab",NA,
                         NA, NA, NA, NA, NA, NA, 
                         "log_rt","log_rt_sd", "acc",
                         "acc_sd", "prod","comp"), 
                byrow = TRUE)

graph_sem(model = fit3_age, text_size = 2, layout = t(layout_age))
```

Figure \ref{fig:age_regression} shows a regression model fit to this confirmatory factor analysis, with log age predicting each latent variable. This regression model allows interpretation of the covariances between latent factors as partial correlations (controlling for age). All three latent factors were significantly related to one another, with speed and accuracy showing strong negative covariance ($\beta=$ `r round(fit3_age_summary$pe[21,"est"],3)`, SE = `r round(fit3_age_summary$pe[21,"se"],3)`, $p < .0001$) and weaker but significant covariation between speed and vocabulary ($\beta=$ `r round(fit3_age_summary$pe[20,"est"],3)`, SE = `r round(fit3_age_summary$pe[20,"se"],3)`, $p < .0001$) and accuracy and vocabulary ($\beta=$ `r round(fit3_age_summary$pe[19,"est"],3)`, SE = `r round(fit3_age_summary$pe[19,"se"],3)`, $p < .0001$). This model supports the idea that individual variation in speed and accuracy of word recognition is concurrently related to vocabulary beyond effects of age. 


## Speed of processing relates to vocabulary growth {.unnumbered}

```{r reliability}
MONTH_CUTOFF <- 2

longitudinal <- d_sub |>
  group_by(dataset_name, subject_id) |>
  count() |>
  filter(n > 1)

d_long <- d_sub |>
  filter(subject_id %in% longitudinal$subject_id) |>
  group_by(subject_id) |>
  arrange(age) |>
  mutate(admin_num = 1:n(), 
         delta_t = age - age[1])


d_reliability <- d_long |>
  filter(delta_t <= MONTH_CUTOFF, 
         admin_num <= 2) |>
  pivot_wider(id_cols = c("subject_id","dataset_name"), 
              names_from = "admin_num",
              values_from = c("log_rt", "log_rt_var", "long_window_accuracy", 
                              "long_window_acc_var", "prod", "comp"))

dataset_reliabilities <- d_reliability |>
  group_by(dataset_name) |>
  summarise(rt = cor(log_rt_1, log_rt_2, use = "pairwise.complete.obs"),
            acc = cor(long_window_accuracy_1, 
                          long_window_accuracy_2, use = "pairwise.complete.obs")) |>
  filter(dataset_name != "fernald_totlot") 

# note this is not correct for CDIs because some CDIs can get grouped with two admins, inflating correlations
global_reliabilities <- d_reliability |>
  ungroup() |>
  summarise(rt = cor(log_rt_1, log_rt_2, use = "pairwise.complete.obs"),
            acc = cor(long_window_accuracy_1, 
                          long_window_accuracy_2, use = "pairwise.complete.obs"))
```



While we fit the latent variable models above to the full cross-sectional dataset, we are most interested in within-child developmental changes, as measured within individual studies. We first examined test-retest reliability for our primary variables of interest by calculating Pearson correlations between pairs of administrations given no more than two months apart. Test-retest correlations were significant but relatively modest ($\rho_{acc} = `r round(global_reliabilities[2], 3)`$, $\rho_{rt} =  `r round(global_reliabilities[1],3)`$), suggesting that, across studies, LWL measures from individual sessions provide relatively noisy measurements of individual children even if individual studies are able to achieve higher reliability by averaging across measurement occasions [e.g., @marchman2008].


```{r prep_long_data}
# rename and scale variables
d_sub_s <- d_sub |>
  ungroup() |>
  select(dataset_name, subject_id, administration_id, age, 
         time_since_t0, delta_t,
         log_rt, log_rt_var, 
         long_window_accuracy, long_window_acc_var, prod, comp, ) |>
  rename(acc = long_window_accuracy, 
         acc_sd = long_window_acc_var, 
         log_rt_sd = log_rt_var) |>
  ungroup() |>
  mutate(across(all_of(c("log_rt", "log_rt_sd", "acc", "acc_sd", 
                         "prod", "comp")), 
                       ~ age_scale(.x, age))) 

d_sub_wide <- d_sub_s |> 
  mutate(t = cut(time_since_t0, breaks = c(0, 6, 12, 30), 
                 include.lowest = TRUE)) |>
  filter(t != "(12,30]") |>
  mutate(t = as.numeric(t)) |>
  group_by(subject_id, dataset_name, t) |>
  summarise(across(all_of(c("log_rt", "log_rt_sd", "acc",
                            "acc_sd", "prod", "comp")),
                   ~ mean(.x, na.rm=TRUE))) |> 
  mutate(across(all_of(c("log_rt", "log_rt_sd", "acc",
                         "acc_sd", "prod", "comp")),
                ~ ifelse(is.nan(.x), NA, .x))) |>
  pivot_wider(id_cols = c("subject_id","dataset_name"), 
              names_from = "t",
              values_from = c("log_rt", "log_rt_sd", "acc", 
                              "acc_sd", "prod", "comp"), 
              names_prefix = "t")

```


```{r}
fa3_model_long <- "
# measurement model
vocab_t1 =~ 1*prod_t1 + s1*comp_t1
accuracy_t1 =~ 1*acc_t1 + s2*acc_sd_t1
speed_t1 =~ 1*log_rt_t1 + s3*log_rt_sd_t1

vocab_t2 =~ 1*prod_t2 
accuracy_t2 =~ 1*acc_t2 + s2*acc_sd_t2
speed_t2 =~ 1*log_rt_t2 + s3*log_rt_sd_t2

# longitudinal relationships
vocab_t2 ~ vocab_t1 + speed_t1 + accuracy_t1
speed_t2 ~ vocab_t1 + speed_t1 + accuracy_t1
accuracy_t2 ~ vocab_t1 + speed_t1 + accuracy_t1

# factor covariances
vocab_t1 ~~ accuracy_t1
vocab_t1 ~~ speed_t1
accuracy_t1 ~~ speed_t1

vocab_t2 ~~ accuracy_t2
vocab_t2 ~~ speed_t2
accuracy_t2 ~~ speed_t2

# means for the latents
vocab_t1 ~ 1
vocab_t2 ~ 1
accuracy_t1 ~ 1
accuracy_t2 ~ 1
speed_t1 ~ 1
speed_t2 ~ 1

# residual variance for the latents
vocab_t1 ~~ NA*vocab_t1
vocab_t2 ~~ NA*vocab_t2
accuracy_t1 ~~ NA*accuracy_t1
accuracy_t2 ~~ NA*accuracy_t2
speed_t1 ~~ NA*speed_t1
speed_t2 ~~ NA*speed_t2
"

fit3_long <- sem(fa3_model_long, d_sub_wide, std.lv=TRUE, missing='fiml')

fit3_long_summary <- suppressMessages(summary(fit3_long, fit.measures=TRUE, standardize=TRUE))
```

Given this relatively low reliability in our longitudinal datasets (which also tended to be from younger children), we chose to measure longitudinal relationships between LWL and vocabulary via a longitudinal latent factor model. We fit the same three-factor model, but this time averaging longitudinal administrations after splitting them into two categories: those datapoints within a two-month time period (which we designate as $t_1$) and those datapoints between three and six months from the initial measurement ($t_2$) (see SI: Sensitivity Analysis for Longitudinal Models). To ensure measurement invariance, we coupled the factor loadings across the two time-points. Next, to investigate coupling between the different measures, we fit regressions linking the two time points. 

The fitted longitudinal model is shown in Figure \ref{fig:longitudinal}. Overall fit statistics were generally good (Confirmatory fit index: `r round(fit_stats$fit["cfi"], 3)`, RMSE: `r round(fit3_long_summary$fit["rmsea"], 3)`, RMSE $p$-value: `r round(fit3_long_summary$fit["rmsea.pvalue"], 3)`). Each latent factor was significantly coupled across time, again indicating moderate longitudinal stability of these abilities. 


```{r longitudinal, fig.env="figure*", height = 3.5, fig.cap = "Structural equation model showing longitudinal couplings between latent factors. Variables marked t1 are measures from two or fewer months from study initiation; variables marked t2 are measures from 3--6 months after study initiation. Factor loadings are constrained to be equivalent between t1 and t2. Plotting conventions are as in Figure 3."}
layout_long = matrix(nrow=7, ncol = 7,
                     data = c("log_rt_sd_t1","log_rt_t1", "acc_t1", "acc_sd_t1", "prod_t1","comp_t1", NA,
                               NA, NA, NA, NA, NA, NA,  NA,
                              "speed_t1",NA,"accuracy_t1",NA,"vocab_t1",NA,  NA,
                              NA, NA, NA, NA, NA, NA,  NA,
                               NA,"speed_t2",NA,"accuracy_t2",NA,NA,"vocab_t2",
                               NA, NA, NA, NA, NA, NA,  NA,
                               NA,"log_rt_sd_t2","log_rt_t2", "acc_t2", "acc_sd_t2", NA, "prod_t2"), 
                     byrow = TRUE)
graph_sem(model = fit3_long, text_size = 2, layout = t(layout_long))
```

```{r}
fa3_model_long_control <- "
# measurement model
vocab_t1 =~ 1*prod_t1 + s1*comp_t1
accuracy_t1 =~ 1*acc_t1 + s2*acc_sd_t1
speed_t1 =~ 1*log_rt_t1 + s3*log_rt_sd_t1

vocab_t2 =~ 1*prod_t2 + s1*comp_t2
accuracy_t2 =~ 1*acc_t2 + s2*acc_sd_t2
speed_t2 =~ 1*log_rt_t2 + s3*log_rt_sd_t2

# longitudinal relationships
vocab_t2 ~ vocab_t1 + 0*speed_t1 + accuracy_t1
speed_t2 ~ vocab_t1 + speed_t1 + accuracy_t1
accuracy_t2 ~ vocab_t1 + speed_t1 + accuracy_t1

# factor covariances
vocab_t1 ~~ accuracy_t1
vocab_t1 ~~ speed_t1
accuracy_t1 ~~ speed_t1

vocab_t2 ~~ accuracy_t2
vocab_t2 ~~ speed_t2
accuracy_t2 ~~ speed_t2

# means for the latents
vocab_t1 ~ 1
vocab_t2 ~ 1
accuracy_t1 ~ 1
accuracy_t2 ~ 1
speed_t1 ~ 1
speed_t2 ~ 1

# residual variance for the latents
vocab_t1 ~~ NA*vocab_t1
vocab_t2 ~~ NA*vocab_t2
accuracy_t1 ~~ NA*accuracy_t1
accuracy_t2 ~~ NA*accuracy_t2
speed_t1 ~~ NA*speed_t1
speed_t2 ~~ NA*speed_t2
"

fit3_long_control <- sem(fa3_model_long_control, d_sub_wide, std.lv=TRUE, missing='fiml')
speed_vocab_anova <- anova(fit3_long, fit3_long_control)
speed_vocab_anova$p = speed_vocab_anova$`Pr(>Chisq)`
speed_vocab_anova$c2d = speed_vocab_anova$`Chisq diff`
```

Critically, LWL processing speed at time 1 predicted vocabulary at time 2 ($\beta=$ `r round(fit3_long_summary$pe[14,"est"],3)`, SE = `r round(fit3_long_summary$pe[21,"se"],3)`, $p =$ `r round(fit3_long_summary$pe[14,"pvalue"],3)`). This model significantly improved fit compared with a model that set this coupling parameter to zero but was otherwise unchanged ($\chi^2 = `r round(speed_vocab_anova$c2d[2], 2)`$, $p =  `r round(speed_vocab_anova$p[2], 4)`$). These findings are consistent with the claim that faster processing is related to longitudinal growth in vocabulary [@fernald2006;@Weisleder2013]. 

# Discussion {.unnumbered}

How does word recognition change across early childhood, and how does it relate to language learning? We investigated these questions using a new dataset of developmental eye-tracking measurements. We found continuous developmental changes from ages 1 -- 6 years. Speed and accuracy both improved asymptotically, with evidence that recognition speed showed the log-log relationship associated with the power law of practice, that is, gradually converging on mature levels of processing efficiency. Further, older children showed less variability in accuracy and reaction time across trials, indicating more robust execution of this skilled behavior. Speed and accuracy were both related to vocabulary size concurrently, and processing speed was also related to later vocabulary growth.

By aggregating data from many pre-existing studies, we were able to overcome the limitations of prior investigations, which typically had samples sizes at least an order of magnitude smaller than ours. The presence of multiple studies with longitudinal data, 


These findings are consistent with theories that posit that language learning is a process of skill acquisition, in which children become skillful at quickly converting ephemeral signals into meaning [@christiansen2016].  




FACTOR PARAGRAPH

These data suggest graded, continual changes in word recognition starting in early childhood and continuing at least through elementary school. Notably, the experiments included in our datasets used simple words that children of this age almost surely "know" (e.g., "ball," which is learned very early, or occasionally "scissors" or "zebra," which are learned slightly later). Even for these "easy" words, careful measurement reveals increasing efficiency. 

<!-- % address causal indeterminacy issue  -->
<!-- % https://www.degruyter.com/document/doi/10.1515/jci-2022-0074/html -->


<!-- DISCUSS G EXPLANATION - fernald fundamentally speedier processor -->

<!-- INPUT VS MATURATION? PROBABLY BOTH -->


Consistent with this idea,  trial-to-trial variability in children's cognitive task performance decreases with age and has some predictive relationships with skill in other tasks, including language [@judd2021working;@galeano2018variability;@kautto2023introducing].

What explains variability in language performance? Integrating information from parent-report measures of vocabulary development with infant behavioral data, we show that infants' word recognition.


<!-- Leave these lines as they are at the end of your .Rmd file to ensure placement of methods & acknowledgements sections before the references-->
\showmatmethods
\showacknow
\pnasbreak

\newpage 
