---
title: Continuous developmental changes in word recognition across early childhood

# Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
author:
  - name: Alice Anonymous
    affiliation: a,1,2
  - name: Bob Security
    affiliation: a,b
address:
  - code: a
    address: Some Institute of Technology, Department, Street, City, State, Zip
  - code: b
    address: Another University Department, Street, City, State, Zip

corresponding_author:
  code: 2
  text: "To whom correspondence should be addressed. E-mail: bob@email.com"

# For footer text
lead_author_surname: Anonymous

author_contributions: |
  Please provide details of author contributions here.

abstract: |
  Being a fluent language user involves not just knowing how to combine words into meaningful sentences, but also being able to understand language as it unfolds in time. How does this skill develop over the course of early childhood?  And how does facility in word recognition relate to the growth of vocabulary?  We address these questions using data from Peekbank, an open database of eye-tracking experiments on children's early word recognition.  Combining 24 datasets with data from almost 2,000 children ages 1--6 years, we show that word recognition becomes faster, more accurate, and less variable across development, both within and across studies. Factor analysis revealed a cross-sectional coupling of word recognition speed and accuracy to parent-reported vocabulary and a longitudinal relationship such that children with faster language processing showed larger vocabulary growth. Together, these findings are consistent with the view that language processing is –– among other things –– a skill, and language learning is a process of skill learning. 


significance: |
  Early language development is a key part of children's development that also sets the stage for later academic success. The efficiency with which children recognize words provides a measurement of their real-time language processing, which has been argued to be a key part of the learning process. Here we use a large dataset of eye-tracking data from many different experiments to map out the development of word recognition, finding that this process becomes faster, more accurate, and less variable in the period between one and six years of age. This trajectory is consistent with the idea that understanding language is a skill that improves gradually with practice.

acknowledgements: |
  This work was supported by a grant from the Jacobs Foundation. 

keywords:
  - one
  - two
  - optional
  - optional
  - optional

## must be one of: pnasresearcharticle (usual two-column layout), pnasmathematics (one column layout), or pnasinvited (invited submissions only)
pnas_type: pnasresearcharticle

bibliography: peekbank.bib
csl: pnas.csl

## change to true to add optional line numbering
lineno: false

output: rticles::pnas_article
---


\dropcap{C}hildren acquiring a language are learning a body of knowledge -- a set of words and the ways they are combined -- but they are also learning to deploy this knowledge in the myriad complex, noisy, and fast-moving environments in which language is used. As children enter their second year, language explodes onto the scene; children's vocabulary and grammatical abilities grow rapidly in tandem [@bates1994developmental;@frank2021]. This growth in knowledge is also accompanied by changes in their language processing: they become quicker and more accurate in recognizing words and matching them with their referents [@fernald1998;@peter2019;@bergelson2020comprehension].

Yet unlike language production, which is manifest via overt behavior, evidence for word recognition is often more subtle. Very young children with incomplete knowledge may not be able to point to the correct referent of a word, but they may still have some representation of word meaning [@bergelson2012]. Eye tracking has thus emerged as a key method that allows the measurement of language comprehension with high temporal resolution: both adults and children reliably fixate the referent of a spoken word soon after it is spoken [@tanenhaus1995integration;@altmann1999incremental;@fernald1998;@fernald2008]. The relative timecourse of fixation then can provide an index of both the comprehender's ability and the properties of the stimulus. 

The version of this method that is used with children goes by many names, including the "intermodal preferential looking paradigm" and the "looking while listening" paradigm (or LWL, the name we adopt here) [@hirsh1996intermodal;@reznick1990visual;@fernald2008]. In these experiments, children are typically shown a series of trials in which two images are displayed side by side and they are asked to find one of them. For example, a ball and a book might be shown, and the child might hear "Look at the ball! Can you find it?" Accuracy is then computed as the proportion of time they fixate the correct image within a fixed window after the onset of the noun ("ball" in this case). Reaction time is typically computed only on trials in which the child is fixating the distractor image (the book); in these cases, the average time it takes to shift fixation to the target is used as an index of processing speed. 
The seminal work using this method showed that children's speed and accuracy both increase rapidly across the second year [@fernald1998;@reznick1990visual]. 

<!-- % MCF: we go back and forth now between word recognition and language processing. is this oK? -->
<!-- % MCF: I haven't adopted the fernald "efficiency" term, which groups speed and accuracy as one process... in part this seems to presuppose the answer to some bits of our factor analysis... -->

Language processing ability is hypothesized to play a key role in language learning. Each word that a child hears is an opportunity to learn; measurements of children's language input at home are consistently associated with their vocabulary size [@hart1995meaningful;@anderson2021linking]. These opportunities are likely helpful to different degrees, however [@kachergis2022toward;@mcmurray2007defusing]. Language is likely to be a better learning signal if it is focused on the child's own interest, grounded in the particulars of their current environment -- for example, in a game, routine, or object -- and uses vocabulary and syntax that they know [@tomasello2001perceiving;@roy2015predicting;@cartmill2013quality]. But processing is also prerequisite for learning. Consider a child hearing the utterance "can you put the ball in the box?" The faster and more accurately the child can recognize that the ball is a referent, the better they can use this evidence to help infer the speaker's intended meaning, perhaps making inferences about the meaning of "put" or "box" [@frank2009using]. Consistent with this idea, in one study, children's language processing skill mediated the relationship between home language input and vocabulary growth [@Weisleder2013].


<!-- % This method has provided an important window into how children process phonological [@???}, syntactic [@trueswell1999kindergarten}, and semantic [@mani} competition; how their lexical representations develop [@Swingley2002}; etc. -->

Speed of word recognition has been used as an index of individual differences in early childhood [@marchman2008;@peter2019;@fernald2012;@newbury2016interrelationships] and beyond [@colby2023efficiency;@jeppsen2022development;@mcmurray2022slow]. Word recognition speed at 18 months can predict children's later language ability over and above measures of vocabulary size [@marchman2008], though these predictions may be limited to particular ages or processing assessments [@peter2019]. Further, faster processing at age two is predictive of whether "late talkers" catch up to their peers or require further intervention [@fernald2012].  Critically, all of these assessments use words that children are reported to understand and produce -- they are not indices of vocabulary size but rather of how quickly and accurately they can recognize a spoken word and use it to guide their visual attention to a referent. 

<!-- % MCF: is this question statement sharp enough?  -->

Yet individual experiments measuring processing with young children typically recruit relatively small samples in a restricted range of ages. These samples provide neither the range of ages nor the number of participants to estimate the broader dynamics of how word recognition changes developmentally and how it connects with broader changes across the lifespan [@mcmurray2022slow;@colby2023efficiency]. Further, previous findings do not shed light on whether processing efficiency indexes a separate construct and might vary independently from vocabulary size, or whether it is tightly coupled to vocabulary such that children with larger vocabularies are also better language processors. 

% suggest that speed of processing is related to concurrent and later language ability [@peter2019;@marchman2008]. This work is consistent with several explanations, however. First, it is possible that processing speed indexes a different construct than accuracy. On this kind of account, speedier processors may be differentiated from those children with a larger vocabulary; identifying these children thus helps to increase predictive accuracy. An alternative account, however, is that processing speed and accuracy reflect two aspects of how a single construct is translated into behavior (in this case, eye movements). On this second account, the increase in predictive accuracy by using reaction times is accounted for because each has independent measurement error -- the inclusion of both into a model thus increases precision. Thus, the factor structure of early language processing -- and in particular, whether there is evidence for orthogonal variation in early language related to processing speed -- is an open question. 

```{r loading, echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(psych))
suppressPackageStartupMessages(library(lmerTest))
suppressPackageStartupMessages(library(lavaan))
suppressPackageStartupMessages(library(tidySEM))
suppressPackageStartupMessages(library(xtable))
suppressPackageStartupMessages(library(kableExtra))


source(here("helper","common.R"))
d_trial <- readRDS(here("cached_intermediates","1_d_trial.Rds")) |>
  mutate(log_age = log(age))
d_sub <- readRDS(here("cached_intermediates","1_d_sub.Rds"))

d_trial$age_s <- scale(d_trial$age)[,1]
d_trial$log_age_s <- scale(d_trial$log_age)[,1]   
d_sub$age_s <- scale(d_sub$age)[,1]
d_sub$log_age_s <- scale(d_sub$log_age)[,1]   


AGEVAR_CUTOFF <- 6

knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE)
```


To address these questions, we made use of Peekbank, an open database of  looking while listening data from young children, stored in a harmonized format [@zettersten2023peekbank]. Aiming to map the development of language processing across ages 1 -- 6 years, we analyzed data from simple word recognition trials in which children were shown two pictures of concrete objects and heard an English word. (We focused on English purely for practical reasons -- we had very limited data from other languages). These criteria yielded `r length(unique(d_sub$dataset_name))` datasets, including `r length(unique(d_sub$subject_id))` children and `r length(unique(d_sub$administration_id))` administrations of the LWL procedure (some datasets were longitudinal or involved multiple closely-spaced testing sessions). Table \ref{tab:datasets} shows the characteristics of individual datasets. The size of the combined dataset, the unified data processing pipeline, and the fact that individual studies used very similar implementations of the LWL experimental paradigm, all allow us to take a more detailed look at early language processing than has previously been possible. 


```{r dataset_table}
dataset_characteristics <- d_sub |>
  group_by(dataset_name) |>
  summarise(`N subjects` = length(unique(subject_id)),
            `N admins` = n(), 
            `Mean Age` = mean(age), 
            `Min Age` = min(age), 
            `Max Age` = max(age), 
            `Avg Trials` = mean(n_trials[!is.na(long_window_accuracy)]),
            `Avg RT Trials` = mean(n_trials_rt[!is.na(rt)]),
            `CDIs` = ifelse(!is.na(any(prod)), "x", ""), 
            `longitudinal` = ifelse(any(duplicated(subject_id)), "x", "")) |>
  arrange(desc(`N subjects`)) 
```

```{r eval=FALSE}
xtable(dataset_characteristics, 
       caption = "Characteristics of included datasets from Peekbank. `Admins` denotes separate experimental sessions.")
```

\begin{table*}[t!]
\centering
\begin{tabular}{rlrrrrrrrll}
  \hline
 & dataset\_name & N subjects & N admins & Mean Age & Min Age & Max Age & Avg Trials & Avg RT Trials & CDIs & longitudinal \\ 
  \hline
1 & reflook\_v4 & 310 & 310 & 36.82 & 12.24 & 60.00 & 6.21 & 2.87 &  &  \\ 
  2 & yurovsky\_2017 & 282 & 282 & 25.64 & 12.59 & 58.65 & 5.95 & 2.79 &  &  \\ 
  3 & weaver\_zettersten\_2024 & 141 & 248 & 15.73 & 13.50 & 23.60 & 18.10 & 6.72 & x & x \\ 
  4 & fernald\_marchman\_2012 & 122 & 678 & 23.92 & 17.00 & 32.00 & 16.78 & 7.17 & x & x \\ 
  5 & sander-montant\_2022 & 122 & 122 & 21.94 & 12.02 & 31.11 & 10.07 & 4.20 & x &  \\ 
  6 & frank\_tablet\_2016 & 104 & 104 & 33.89 & 12.13 & 59.84 & 5.87 & 2.74 &  &  \\ 
  7 & baumgartner\_2014 & 100 & 100 & 12.01 & 12.00 & 13.00 & 4.00 & 2.31 & x &  \\ 
  8 & fmw\_2013 &  80 & 179 & 20.04 & 17.00 & 26.00 & 21.26 & 8.44 & x & x \\ 
  9 & adams\_marchman\_2018 &  69 & 711 & 23.57 & 12.00 & 38.00 & 18.44 & 7.92 & x & x \\ 
  10 & potter\_canine &  67 &  67 & 23.76 & 21.00 & 27.00 & 10.38 & 3.80 & x &  \\ 
  11 & fernald\_totlot &  63 & 229 & 19.68 & 15.00 & 25.00 & 15.22 & 6.05 & x & x \\ 
  12 & pomper\_prime &  63 &  63 & 39.73 & 37.90 & 42.00 & 12.98 & 5.34 &  &  \\ 
  13 & pomper\_saffran\_2016 &  60 &  60 & 44.27 & 41.00 & 47.00 & 7.55 & 3.30 &  &  \\ 
  14 & swingley\_aslin\_2002 &  50 &  50 & 15.09 & 14.13 & 16.00 & 11.74 & 3.79 & x &  \\ 
  15 & pomper\_salientme &  44 &  44 & 40.11 & 38.00 & 43.00 & 5.30 & 2.34 &  &  \\ 
  16 & perry\_cowpig &  42 &  42 & 20.45 & 19.00 & 22.00 & 14.88 & 5.43 &  &  \\ 
  17 & ronfard\_2021 &  40 &  40 & 19.95 & 18.00 & 24.00 & 18.54 & 7.62 & x &  \\ 
  18 & bacon\_gendercues &  38 &  38 & 22.87 & 22.00 & 24.00 & 18.16 & 8.00 & x &  \\ 
  19 & garrison\_bergelson\_2020 &  35 &  35 & 14.46 & 12.00 & 18.00 & 27.94 & 9.59 & x &  \\ 
  20 & pomper\_yumme &  32 &  32 & 26.38 & 25.00 & 28.00 & 7.62 & 2.31 &  &  \\ 
  21 & mahr\_coartic &  29 &  29 & 20.83 & 18.10 & 23.80 & 24.38 & 8.86 & x &  \\ 
  22 & ferguson\_eyetrackingr &  28 &  28 & 19.71 & 18.02 & 21.86 & 5.54 & 2.33 & x &  \\ 
  23 & potter\_remix &  23 &  44 & 22.59 & 18.00 & 29.00 & 6.07 & 2.58 & x & x \\ 
  24 & newman\_genderdistractor &  19 &  19 & 30.12 & 29.23 & 30.84 & 13.11 & 4.94 &  &  \\ 
   \hline
\end{tabular}
\caption{Characteristics of included datasets from Peekbank. `Admins` denotes separate experimental sessions.\label{tab:datasets}} 
\end{table*}

# Results {.unnumbered}


## Speed and accuracy of word recognition increase {.unnumbered}


```{r acc_mods}
d_trial$age_s <- scale(d_trial$age)[,1]
d_trial$log_age_s <- scale(d_trial$log_age)[,1]   

acc_mods_lmer <- list(lwa_lin = lmer(long_window_accuracy ~ age_s  +
                                     + (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                      lwa_log = lmer(long_window_accuracy ~ log_age_s +
                                     + (log_age_s | dataset_name) + (1 | subject_id), data = d_trial),
                      swa_lin = lmer(short_window_accuracy ~ age_s  +
                                     + (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                      swa_log = lmer(short_window_accuracy ~ log_age_s +
                                     + (log_age_s | dataset_name) + (1 | subject_id), data = d_trial))

acc_mods_lmer_summary <- map_df(acc_mods_lmer, ~broom.mixed::glance(.x)) |>
  mutate(model = names(acc_mods_lmer), 
         r2 = map_dbl(acc_mods_lmer, ~performance::r2_nakagawa(.x)$R2_conditional))
```


```{r rt_mods}
rt_mods_lmer <- list(log_lin = lmer(log_rt ~ age_s + 
                                      (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                     log_log = lmer(log_rt ~ log_age_s + 
                                      (log_age_s | dataset_name) + (1 | subject_id), data = d_trial),
                     lin_lin = lmer(rt ~ age_s + 
                                      (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                     lin_log = lmer(rt ~ log_age_s +  
                                      (log_age_s | dataset_name) + (1 | subject_id), data = d_trial))

rt_mods_lmer_summary <- map_df(rt_mods_lmer, ~broom.mixed::glance(.x)) |>
  mutate(model = names(rt_mods_lmer), 
         r2 = map_dbl(rt_mods_lmer, ~performance::r2_nakagawa(.x)$R2_conditional))
```

We were first interested in developmental changes in speed and accuracy. We computed both reaction times and accuracies following standard practices in the literature [@fernald2008]. Because there is no consensus about the length of time windows for the computation of accuracy, we considered both a shorter window (from 200 -- 2200 ms after noun onset) and a longer window (from 200 -- 4000 ms). 

Our first question was about the functional form of the relationships between age, speed, and accuracy. To investigate this question, we fit linear mixed effects models predicting accuracy and reaction time on each trial across the full dataset with random slopes of age by study and random intercepts by participant. We compared models that included both long and short accuracy windows, as well as logarithmic and linear effects of age, and logarithmic and linear transformations of reaction time. The best fitting model of accuracy predicted long window accuracy as a function of the logarithm of age,^[This longer window yielded overall higher cross-trial reliability as well, and so we report long window results in the main text. All findings reported here hold for both window sizes, however.] and the best fitting model of speed predicted log reaction time as a function of log age as well (See Supplemental Tables 1 and 2 for model fit statistics). 

Figure \ref{fig:devchange} shows these relationships. Log reaction time decreased significantly with age (`r papaja::apa_print(rt_mods_lmer[[2]])$full_result$log_age_s`) and accuracy increased significantly with age  (`r papaja::apa_print(acc_mods_lmer[[2]])$full_result$log_age_s`). In sum, we see continuing improvements in word recognition across the full age range in our dataset that appear roughly linear in the logarithm of age.  These logarithmic relationships follow theoretical expectations that both speed and accuracy should gradually asymptote to mature levels of performance as in skill learning more generally [@anderson1982,@snoddy1926]. With our current dataset we cannot specifically determine whether within-individual patterns of change conform to power law or exponential forms [@kail1991,@heathcote2000], but regardless we see clear patterns of developmental change related to skill acquisition.

```{r devchange, fig.cap="Participant-level accuracy and reaction time (log), plotted by age (log). The solid green line shows a linear fit and associated confidence interval. Individual dotted lines show linear fits for those datasets spanning six or more months of age. The dashed line for accuracy shows chance-level looking (.5)", fig.env="figure*", fig.height = 2.5}

datasets_with_age_variation <- d_trial |>
  group_by(dataset_name) |>
  summarise(age_range = max(age) - min(age)) |>
  filter(age_range >= AGEVAR_CUTOFF)

d_sub_agevar <- d_sub |>
  filter(dataset_name %in% datasets_with_age_variation$dataset_name)

a <- ggplot(d_sub,
       aes(x = age, y = long_window_accuracy)) + 
  geom_point(alpha = .05) + 
  geom_smooth(method = "lm") +
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .5, lty = 2) + 
  geom_hline(yintercept = .5, lty = 2) + 
  scale_x_log10() +
  scale_color_discrete(guide = FALSE) + 
  ylab("Accuracy") + 
  xlab("Age (months)")

b <- ggplot(d_sub,
       aes(x = age, y = rt)) + 
  geom_point(alpha = .05) + 
  geom_smooth(method = "lm") +
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .5, lty = 2) + 
  scale_x_log10() +
  scale_y_log10() +
  scale_color_discrete(guide = FALSE) + 
  theme(legend.position = "bottom") + 
  ylab("Reaction Time (log)") + 
  xlab("Age (months)")

cowplot::plot_grid(a,b)
```

## Variability of word recognition decreases {.unnumbered}

```{r var_mods}
acc_var_mod <- lmer(long_window_acc_var ~ log_age_s + (log_age_s | dataset_name) + 
                 (1 | subject_id), 
               data = d_sub)


rt_var_mod <- lmer(log_rt_var ~ log_age_s + (log_age_s | dataset_name) + 
                 (1 | subject_id), 
               data = d_sub)
```

One further hallmark of increasing skill is a decrease in task-relevant variability [@todorov2002optimal]. Both within and across datasets, variation in accuracy and reaction time decreased across datasets, again relatively continuously across the developmental range we examined (Figure \ref{fig:variance}). We fit mixed effects models to the standard deviation of both accuracy and reaction time for each testing session for each participant, including random slopes of log age by dataset and random intercepts for each participant. For both speed and accuracy, variability decreased with age (RT: `r papaja::apa_print(rt_var_mod)$full_result$log_age_s`; accuracy: `r papaja::apa_print(acc_var_mod)$full_result$log_age_s`). Thus, as well as being faster and more accurate, older children appear to be more consistent in their online word recognition.

```{r variance, fig.cap="Participant-level variability in accuracy and reaction time (log RT), plotted by age (log). Plotting conventions are as in Figure 1.", fig.env="figure*", fig.height = 2.5}
c <- ggplot(d_sub,
       aes(x = age, y = long_window_acc_var)) + 
  geom_point(alpha = .05) + 
  geom_smooth(method = "lm") +
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .5, lty = 2) + 
  scale_x_log10() +
  scale_color_discrete(guide = FALSE) + 
  ylab("SD of Accuracy)") + 
  xlab("Age (months)")

d <- ggplot(d_sub,
       aes(x = age, y = log_rt_var)) + 
  geom_point(alpha = .05) + 
  geom_smooth(method = "lm") +
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .5, lty = 2) + 
  scale_x_log10() +
  scale_color_discrete(guide = FALSE) + 
  theme(legend.position = "bottom") + 
  ylab("SD of log RT)") + 
  xlab("Age (months)")

cowplot::plot_grid(c,d)
```


## Speed and accuracy covary with vocabulary {.unnumbered}

We were next interested in whether the various different aspects of word recognition -- including accuracy, reaction time, and the variability of each of these -- were related to other aspects of early language ability. Of the studies in our database, `r sum(str_length(dataset_characteristics$CDIs)>0)` gathered parent reports about children's early vocabulary using the MacArthur-Bates Communicative Development Inventory (CDI), a popular survey instrument that provides a reliable and valid holistic picture of children's early language [@marchman2023;@frank2021]. Different forms of the CDI can be used to measure either receptive and expressive vocabulary (for children up to 18 months) or expressive vocabulary only (for children 16 -- 30 months). 

```{r efa}
d_sub_mat <- d_sub |>
  ungroup() |>
  select(dataset_name, rt, rt_var, long_window_accuracy, long_window_acc_var, prod, comp, age, log_age) 


d_sub_mat_s <- d_sub_mat |>
  ungroup() |>
  mutate(across(all_of(c("rt", "rt_var", "long_window_accuracy", 
                         "long_window_acc_var", "prod", "comp")), 
                       ~ age_scale(.x, age))) 

parallel_ana <- capture.output(fa.parallel(select(d_sub_mat, -dataset_name, -age, -log_age), fa = "fa", 
            use = "pairwise.complete.obs", plot=FALSE))
```

```{r cfa}
fa3_model <- "vocab =~ prod + comp
              accuracy =~ long_window_accuracy + long_window_acc_var
              speed =~ rt + rt_var"

fit3 <- cfa(fa3_model, d_sub_mat_s, std.lv=TRUE, missing='fiml')

fit_stats <- suppressMessages(summary(fit3, fit.measures=TRUE, standardize=TRUE))
```

We fit a series of factor analytic models to explore the dimensionality of the data. Initial exploratory factor analysis using paralell analysis suggested that three factors explained substantial variance in the data. Due to missingness of data, we used confirmatory factory analysis with full information maximum likelihood to find the best set of loadings. The best fitting model was a three-factor model with factors for speed (reaction time and reaction time variability), accuracy (accuracy and accuracy variability), and vocabulary (comprehension and production from the CDI). Fit statistics for this model were generally good (Confirmatory fit index: `r round(fit_stats$fit["cfi"], 3)`, RMSE: `r round(fit_stats$fit["rmsea"], 3)`, RMSE $p$-value: `r round(fit_stats$fit["rmsea.pvalue"], 3)`). 


```{r age_regression, fig.env="figure*", fig.cap="Structural equation model showing the three-factor factor analysis with a regression of each latent variable on the logarithm of age. Squares show  Solid lines show regression coefficients and factor loadings, and dotted lines show covariances (reflecting age-residualized correlations). Abbreviations: acc = accuracy, prod = production vocabulary, comp = comprehension vocabulary.", fig.height = 3}

d_sub_mat_s_renamed <- d_sub_mat_s |>
  rename(acc = long_window_accuracy, 
         acc_sd = long_window_acc_var, 
         rt_sd = rt_var)

fa3_age_model <- "
# measurement model
vocab =~ prod + comp
accuracy =~ acc + acc_sd
speed =~ rt + rt_sd

# regressions
vocab ~ log_age
accuracy ~ log_age
speed ~ log_age
"

fit3_age <- cfa(fa3_age_model, d_sub_mat_s_renamed, std.lv=TRUE, missing='fiml')

fit3_age_summary <- suppressMessages(summary(fit3_age, fit.measures=TRUE, standardize=TRUE))
layout_age = matrix(nrow=5, ncol = 6,
                data = c(NA,NA,"log_age",NA, NA, NA,
                         NA, NA, NA, NA, NA, NA, 
                         "speed",NA,"accuracy",NA,"vocab",NA,
                         NA, NA, NA, NA, NA, NA, 
                         "rt_sd","rt", "acc",
                         "acc_sd", "prod","comp"), 
                byrow = TRUE)

graph_sem(model = fit3_age, text_size = 2, layout = t(layout_age))
```

Figure \ref{fig:age_regression} shows a regression model fit to this confirmatory factor analysis, with log age predicting each latent variable. This regression model allows interpretation of the covariances between latent factors as partial correlations (controlling for age). All three latent factors were significantly related to one another, with speed and accuracy showing strong negative covariance ($\beta=$ `r fit3_age_summary$pe[21,"est"]`, SE = `r fit3_age_summary$pe[21,"se"]`, $p < .0001$) and weaker but significant covariation between speed and vocabulary ($\beta=$ `r fit3_age_summary$pe[20,"est"]`, SE = `r fit3_age_summary$pe[20,"se"]`, $p < .0001$) and accuracy and vocabulary ($\beta=$ `r fit3_age_summary$pe[19,"est"]`, SE = `r fit3_age_summary$pe[19,"se"]`, $p < .0001$). This model supports the idea that individual variation in speed and accuracy of word recognition is concurrently related to vocabulary beyond effects of age. 


## Speed of processing relates to vocabulary growth {.unnumbered}

```{r reliability}
MONTH_CUTOFF <- 2

longitudinal <- d_sub |>
  group_by(dataset_name, subject_id) |>
  count() |>
  filter(n > 1)

d_long <- d_sub |>
  filter(subject_id %in% longitudinal$subject_id) |>
  group_by(subject_id) |>
  arrange(administration_id) |>
  mutate(admin_num = 1:n(), 
         delta_t = c(0,diff(age))) 


d_reliability <- d_long |>
  filter(delta_t <= MONTH_CUTOFF, 
         admin_num <= 2) |>
  pivot_wider(id_cols = c("subject_id","dataset_name"), 
              names_from = "admin_num",
              values_from = c("log_rt", "log_rt_var", "long_window_accuracy", 
                              "long_window_acc_var", "prod", "comp"))

dataset_reliabilities <- d_reliability |>
  group_by(dataset_name) |>
  summarise(rt = cor(log_rt_1, log_rt_2, use = "pairwise.complete.obs"),
            acc = cor(long_window_accuracy_1, 
                          long_window_accuracy_2, use = "pairwise.complete.obs")) |>
  filter(dataset_name != "fernald_totlot") 

# note this is not correct for CDIs because some CDIs can get grouped with two admins, inflating correlations
global_reliabilities <- d_reliability |>
  ungroup() |>
  summarise(rt = cor(log_rt_1, log_rt_2, use = "pairwise.complete.obs"),
            acc = cor(long_window_accuracy_1, 
                          long_window_accuracy_2, use = "pairwise.complete.obs"))
```



While we fit the latent variable models above to the full cross-sectional dataset, we are most interested in within-child developmental changes, as measured within individual studies. We first examined test-retest reliability for our primary variables of interest by calculating Pearson correlations between pairs of administrations given no more than two months apart. Test-retest correlations were significant but relatively modest ($\rho_{acc} = `r round(global_reliabilities[2], 3)`$, $\rho_{rt} =  `r round(global_reliabilities[1],3)`$), suggesting that, across studies, LWL measures from individual sessions provide relatively noisy measurements of individual children even if individual studies are able to achieve higher reliability by averaging across measurement occasions [e.g., @marchman2008].


```{r prep_long_data}
d_sub_long <- d_sub |>
  mutate(across(all_of(c("rt", "rt_var", "long_window_accuracy",
                         "long_window_acc_var", "prod", "comp")),
                ~ age_scale(.x,age))) |>
  group_by(subject_id) |>
  arrange(administration_id) |>
  mutate(admin_num = 1:n(), 
         delta_t = c(0, diff(age)))

d_sub_long_t <- d_sub_long |> 
  mutate(t = ifelse(delta_t > MONTH_CUTOFF, "t2", "t1")) |>
  group_by(subject_id, dataset_name, t) |>
  summarise(across(all_of(c("rt", "rt_var", "long_window_accuracy",
                            "long_window_acc_var", "prod", "comp")),
                   ~ mean(.x, na.rm=TRUE))) |> 
  mutate(across(all_of(c("rt", "rt_var", "long_window_accuracy",
                         "long_window_acc_var", "prod", "comp")),
                ~ ifelse(is.nan(.x), NA, .x)))

d_sub_wide <- d_sub_long_t |>
  pivot_wider(id_cols = c("subject_id","dataset_name"), 
              names_from = "t",
              values_from = c("rt", "rt_var", "long_window_accuracy", 
                              "long_window_acc_var", "prod", "comp"))
```


```{r}
fa3_model_long <- "
# measurement model
vocab_t1 =~ 1*prod_t1 + s1*comp_t1
accuracy_t1 =~ 1*long_window_accuracy_t1 + s2*long_window_acc_var_t1
speed_t1 =~ 1*rt_t1 + s3*rt_var_t1

vocab_t2 =~ 1*prod_t2 + s1*comp_t2
accuracy_t2 =~ 1*long_window_accuracy_t2 + s2*long_window_acc_var_t2
speed_t2 =~ 1*rt_t2 + s3*rt_var_t2

# longitudinal relationships
vocab_t2 ~ vocab_t1 + speed_t1 + accuracy_t1
speed_t2 ~ vocab_t1 + speed_t1 + accuracy_t1
accuracy_t2 ~ vocab_t1 + speed_t1 + accuracy_t1

# factor covariances
vocab_t1 ~~ accuracy_t1
vocab_t1 ~~ speed_t1
accuracy_t1 ~~ speed_t1

vocab_t2 ~~ accuracy_t2
vocab_t2 ~~ speed_t2
accuracy_t2 ~~ speed_t2

# means for the latents
vocab_t1 ~ 1
vocab_t2 ~ 1
accuracy_t1 ~ 1
accuracy_t2 ~ 1
speed_t1 ~ 1
speed_t2 ~ 1

# residual variance for the latents
vocab_t1 ~~ NA*vocab_t1
vocab_t2 ~~ NA*vocab_t2
accuracy_t1 ~~ NA*accuracy_t1
accuracy_t2 ~~ NA*accuracy_t2
speed_t1 ~~ NA*speed_t1
speed_t2 ~~ NA*speed_t2
"

fit3_long <- sem(fa3_model_long, d_sub_wide, std.lv=TRUE, missing='fiml')

fit3_long_summary <- suppressMessages(summary(fit3_long, fit.measures=TRUE, standardize=TRUE))
```

Given this relatively low reliability in our longitudinal datasets (which also tended to be from younger children), we chose to measure longitudinal relationships between LWL and vocabulary via a longitudinal latent factor model. We fit the same three-factor model, but this time averaging longitudinal administrations after splitting them into two categories: those datapoints within a two-month time period (which we designate as $t_1$) and those datapoints between three and six months from the initial measurement ($t_2$). To ensure measurement invariance, we coupled the factor loadings across the two time-points. Next, to investigate coupling between the different measures, we fit regressions linking the two time points. 

The fitted longitudinal model is shown in \ref{fig:longitudinal}. Overall fit statistics were generally good (Confirmatory fit index: `r round(fit_stats$fit["cfi"], 3)`, RMSE: `r round(fit3_long_summary$fit["rmsea"], 3)`, RMSE $p$-value: `r round(fit3_long_summary$fit["rmsea.pvalue"], 3)`). Each latent factor was significantly coupled across time, again indicating moderate longitudinal stability of these abilities. 


```{r longitudinal, fig.env="figure*", height = 3.5, fig.cap = "Coupled change model."}
layout_long = matrix(nrow=7, ncol = 7,
                     data = c("rt_var_t1","rt_t1", "long_window_accuracy_t1", "long_window_acc_var_t1", "prod_t1","comp_t1", NA,
                               NA, NA, NA, NA, NA, NA,  NA,
                              "speed_t1",NA,"accuracy_t1",NA,"vocab_t1",NA,  NA,
                              NA, NA, NA, NA, NA, NA,  NA,
                               NA,"speed_t2",NA,"accuracy_t2",NA,NA,"vocab_t2",
                               NA, NA, NA, NA, NA, NA,  NA,
                               NA,"rt_var_t2","rt_t2", "long_window_accuracy_t2", "long_window_acc_var_t2", "prod_t2","comp_t2"), 
                     byrow = TRUE)
graph_sem(model = fit3_long, text_size = 3, layout = t(layout_long))
```

```{r}
fa3_model_long_control <- "
# measurement model
vocab_t1 =~ 1*prod_t1 + s1*comp_t1
accuracy_t1 =~ 1*long_window_accuracy_t1 + s2*long_window_acc_var_t1
speed_t1 =~ 1*rt_t1 + s3*rt_var_t1

vocab_t2 =~ 1*prod_t2 + s1*comp_t2
accuracy_t2 =~ 1*long_window_accuracy_t2 + s2*long_window_acc_var_t2
speed_t2 =~ 1*rt_t2 + s3*rt_var_t2

# longitudinal relationships
vocab_t2 ~ vocab_t1 + 0*speed_t1 + accuracy_t1
speed_t2 ~ vocab_t1 + speed_t1 + accuracy_t1
accuracy_t2 ~ vocab_t1 + speed_t1 + accuracy_t1

# factor covariances
vocab_t1 ~~ accuracy_t1
vocab_t1 ~~ speed_t1
accuracy_t1 ~~ speed_t1

vocab_t2 ~~ accuracy_t2
vocab_t2 ~~ speed_t2
accuracy_t2 ~~ speed_t2

# means for the latents
vocab_t1 ~ 1
vocab_t2 ~ 1
accuracy_t1 ~ 1
accuracy_t2 ~ 1
speed_t1 ~ 1
speed_t2 ~ 1

# residual variance for the latents
vocab_t1 ~~ NA*vocab_t1
vocab_t2 ~~ NA*vocab_t2
accuracy_t1 ~~ NA*accuracy_t1
accuracy_t2 ~~ NA*accuracy_t2
speed_t1 ~~ NA*speed_t1
speed_t2 ~~ NA*speed_t2
"

fit3_long_control <- sem(fa3_model_long_control, d_sub_wide, std.lv=TRUE, missing='fiml')
speed_vocab_anova <- anova(fit3_long, fit3_long_control)
speed_vocab_anova$p = speed_vocab_anova$`Pr(>Chisq)`
speed_vocab_anova$c2d = speed_vocab_anova$`Chisq diff`
```

Critically, LWL processing speed at time 1 predicted vocabulary at time 2 ($\beta=$ `r fit3_long_summary$pe[14,"est"]`, SE = `r fit3_long_summary$pe[21,"se"]`, $p =$ `r fit3_long_summary$pe[14,"pvalue"]`). This model significantly improved fit compared with a model that set this coupling parameter to zero but was otherwise unchanged ($\chi^2 =$ `r round(speed_vocab_anova$c2d[2], 2)`, $p = $ `r round(speed_vocab_anova$p[2], 4)`). These findings are consistent with the claim that faster processing is related to longitudinal growth in vocabulary [@fernald2012,@Weisleder2013]. 


# Discussion {.unnumbered}

Spoken word recognition has been argued to be a fundamental part of language development, but there is still a lack of clarity about how this ability changes across early childhood and how it relates to other aspects of language development. Here we used a large open dataset of experimental measurements to address these questions. Across all data, the development of both speed and accuracy of word recognition was approximately linear with the logarithm of age, that is, gradually converging on mature levels of processing efficiency. Further, older children showed less variability in accuracy and reaction time across trials, indicating more robust execution of this skilled behavior. Word recognition is not a unifactorial ability, however. Our best fitting model showed two distinct components: speed and accuracy. Notably, the reaction time variables grouped together, while accuracy and parent reports of vocabulary loaded on the same latent construct. These two latent constructs -- speed and accuracy -- both showed approximately linear change in the log of age both within and across children and datasets.

These data suggest graded, continual changes in word recognition starting in early childhood and continuing at least through elementary school. Notably, the experiments included in our datasets used simple words that children of this age almost surely "know" (e.g., "ball," which is learned very early, or occasionally "scissors" or "zebra," which are learned slightly later). Even for these "easy" words, careful measurement reveals increasing efficiency. 

<!-- % address causal indeterminacy issue  -->
<!-- % https://www.degruyter.com/document/doi/10.1515/jci-2022-0074/html -->


<!-- DISCUSS G EXPLANATION - fernald fundamentally speedier processor -->

<!-- INPUT VS MATURATION? PROBABLY BOTH -->


Consistent with this idea,  trial-to-trial variability in children's cognitive task performance decreases with age and has some predictive relationships with skill in other tasks, including language [@judd2021working;@galeano2018variability;@kautto2023introducing].

What explains variability in language performance? Integrating information from parent-report measures of vocabulary development with infant behavioral data, we show that infants' word recognition.


<!-- Leave these lines as they are at the end of your .Rmd file to ensure placement of methods & acknowledgements sections before the references-->
\showmatmethods
\showacknow
\pnasbreak

\newpage 

<!-- # Supplemental Figures {.unnumbered} -->


<!-- ```{r} -->
<!-- kbl(acc_mods_lmer_summary, digits = 3, longtable=FALSE) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- kbl(rt_mods_lmer_summary, digits = 3) -->
<!-- ``` -->


```{r reliability_table, eval=FALSE}
xtable(reliabilities)
```

<!-- % latex table generated in R 4.3.1 by xtable 1.8-4 package -->
<!-- % Fri Nov 15 12:22:42 2024 -->
<!-- \begin{table}[ht] -->
<!-- \centering -->
<!-- \begin{tabular}{rlrrrrrr} -->
<!--   \hline -->
<!--  & dataset name & rt & rt\_var & acc & acc\_var & prod & comp \\  -->
<!--   \hline -->
<!-- 1 & adams\_marchman\_2018 & 0.37 & 0.25 & 0.56 & 0.60 &  & 0.98 \\  -->
<!--   2 & fernald\_marchman\_2012 & 0.45 & 0.18 & 0.54 & 0.33 & 0.99 & 0.99 \\  -->
<!--   3 & fmw\_2013 & 0.40 & -0.07 & 0.25 & 0.47 & 0.96 & 0.98 \\  -->
<!--   4 & potter\_remix & 0.17 & 0.64 & 0.32 & 0.32 & 1.00 &  \\  -->
<!--   5 & weaver\_zettersten\_2024 & 0.30 & 0.18 & 0.41 & 0.45 &  &  \\  -->
<!--    \hline -->
<!-- \end{tabular} -->
<!-- \caption{\label{reliabilities} Overall test-retest reliabilities (Pearson correlation) for each of the measures for longitudinal administrations within two months of one another.   -->
<!-- \end{table} -->