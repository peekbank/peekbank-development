---
title: Continuous developmental changes in word recognition support language learning across early childhood 

shorttitle: Continuous developmental changes
# Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
author:
  - name: Michael C. Frank
    affiliation: a, 1
  - name: Virginia A. Marchman
    affiliation: a
  - name: Claire Augusta Bergey
    affiliation: b
  - name: Veronica Boyce
    affiliation: a
  - name: Mika Braginsky
    affiliation: a
  - name: George Kachergis
    affiliation: a
  - name: Jess Mankewitz
    affiliation: c
  - name: Stephan Meylan
    affiliation: d
  - name: Ben Prystawski
    affiliation: a
  - name: Nilam Ram
    affiliation: a, e
  - name: Robert Z. Sparks
    affiliation: a
  - name: Adrian Steffan
    affiliation: f
  - name: Alvin Wei Ming Tan
    affiliation: a
  - name: Martin Zettersten
    affiliation: g
address:
  - code: a
    address: Department of Psychology, Stanford University, Stanford, CA, USA
  - code: b
    address: Department of Linguistics, Stanford University, Stanford, CA, USA
  - code: c
    address: Department of Psychology, University of Wisconsin, Madison, WI, USA
  - code: d
    address: Department of Linguistics, University of California, Berkeley, CA, USA
  - code: e
    address: Department of Communication, Stanford University, Stanford, CA, USA
  - code: f
    address: Department of Psychology, Ludwig Maximilian University, Munich, Germany
  - code: g
    address: Department of Cognitive Science, University of California, San Diego, CA, USA

corresponding_author:
  code: 1
  text: "To whom correspondence should be addressed. E-mail: mcfrank@stanford.edu"

# For footer text
lead_author_surname: Frank

author_contributions: |
  Please provide details of author contributions here.

abstract: |
  Being a fluent language user involves recognizing words as they unfold in time. How does this skill develop over the course of early childhood?  And how does facility in word recognition relate to the growth of vocabulary knowledge?  We address these questions using data from Peekbank, an open database of experiments measuring children's eye movements during early word recognition.  Combining 24 datasets from almost 2,000 children ages 1--6 years, we show that word recognition becomes faster, more accurate, and less variable across development, consistent with a process of skill learning. Factor analysis reveals covariation of word recognition speed and accuracy with children's vocabulary size in cross-sectional analysis. Further, across a range of longitudinal models, speed, accuracy, and vocabulary show coupled growth such that children with faster word recognition tend to show faster vocabulary growth. Together, these findings support the view that word recognition is a skill that develops gradually across early childhood and that this skill plays a role in supporting early language learning. 


significance: |
  The efficiency with which children recognize words provides a measurement of their real-time language processing, which has been argued to be a key part of the language learning process. Here, we use a large dataset of eye-tracking data from many different experiments to map out the development of word recognition, finding that this process becomes faster, more accurate, and less variable in the period between one and six years of age, and that children who are better at word recognition tend to have larger and faster-growing vocabularies. These data suggest that understanding language in real time is an important part of early language learning and that it improves gradually with practice across early childhood.

acknowledgements: |
  This work was supported by a grant from the Jacobs Foundation. 

keywords:
  - language development
  - word recognition
  - developmental change
  - skill acquisition
  - eye-tracking

## must be one of: pnasresearcharticle (usual two-column layout), pnasmathematics (one column layout), or pnasinvited (invited submissions only)
pnas_type: pnasresearcharticle

bibliography: peekbank.bib
csl: pnas.csl

## change to true to add optional line numbering
lineno: false
floatsintext: yes
output: papaja::apa6_pdf
header-includes:
  - \usepackage{threeparttablex}
  - \usepackage{booktabs}
  - \usepackage{placeins}
  - \usepackage{float}
  - \renewcommand{\textfraction}{0.00}
  - \renewcommand{\topfraction}{1}
  - \renewcommand{\bottomfraction}{1}
  - \renewcommand{\floatpagefraction}{1}
  - \setcounter{topnumber}{5}
  - \setcounter{bottomnumber}{5}
  - \setcounter{totalnumber}{6}  

nocite: |
  @yurovsky2017,
  @yurovksky_2017,
  @weaver2024,
  @fernald2012,
  @sander-montant2023,
  @frank2016,
  @baumgartner2014,
  @fernald2013,
  @Adams2018,
  @PotterLewWilliamsUnpub,
  @fernald2006,
  @pomper2016,
  @Swingley2002,
  @pomper2019,
  @perry2017,
  @ronfard2022,
  @bacon2022,
  @Garrison2020,
  @Mahr2015,
  @ferguson2014,
  @potter2019,
  @newman2017
---

Children acquiring a language are learning a body of knowledge -- a set of words and the ways they are combined -- but they are also learning to deploy this knowledge in the myriad complex, noisy, and fast-moving environments in which language is used. As children enter their second year, language explodes onto the scene; both vocabulary and grammatical abilities grow rapidly and in tandem [@bates1994developmental;@frank2021]. This growth in knowledge is also accompanied by changes in language processing efficiency: children become quicker and more accurate in recognizing words and matching them with their referents [@fernald1998;@peter2019;@bergelson2020comprehension].

Yet unlike language production, which is manifest via overt behavior, evidence for word recognition is often more subtle. Very young children with incomplete knowledge may not be able to point to the correct referent of a word, but they may still have some representation of word meaning [@bergelson2012]. Eye tracking has thus emerged as a key method that allows the measurement of language comprehension with high temporal resolution: both adults and children reliably fixate the referent of a word soon after it is used [@tanenhaus1995integration;@altmann1999incremental;@fernald1998;@fernald2008;@macdonald2018]. The relative timecourse of fixation then can provide an index of an individual comprehender's ability or be used to measure the difference between two stimulus conditions. 

The version of this method that is used with children goes by many names, including the "intermodal preferential looking" paradigm and the "looking while listening" paradigm (LWL, the name we adopt here) [@hirsh1996intermodal;@reznick1990visual;@fernald2008]. In LWL experiments, children are typically shown two images displayed side by side and asked to find one of them. For example, a ball and a book might be shown, and the child might hear "Look at the ball! Can you find it?". Accuracy is then computed as the proportion of time their eyes fixate the correct image within a fixed window after the onset of the noun ("ball" in this case). Reaction time is computed only on trials in which the child is fixating the distractor image (the book) at word onset; in these cases, the average time it takes for the child to shift fixation from the distractor to the target image is used as an index of processing speed. Early work using this method showed that both children's speed and accuracy increase rapidly across the second year [@fernald1998;@reznick1990visual]. Related methods have provided a window into how children process phonological [@mani2011], morphological [@meylan2025], lexical [@Swingley2002], syntactic [@trueswell1999kindergarten], and semantic [@mani2010;@bergelson2017] information.

Word recognition ability, as measured by LWL, is hypothesized to play a key role in language learning. Measurements of children's language input at home are consistently associated with their vocabulary size [@hart1995meaningful;@anderson2021linking]. The mechanism posited to drive this association is that each word that a child experiences is an opportunity to learn. But each word must first be recognized during the short window of time when it is present in the child's memory. Consider a child hearing the utterance "Can you put the ball in the crate?" The faster and more accurately the child can recognize the word "ball", the better they can use this evidence to help infer the speaker's intended meaning, allowing possible inferences about the meaning of the less familiar word, "crate" [@frank2009using]. Consistent with this idea, one important study found that children's word recognition speed mediated the longitudinal relationship between home language input and vocabulary growth [@Weisleder2013].

\begin{table}[ht]
\centering
\setlength\tabcolsep{2pt}
\begin{scriptsize}
\begin{tabular}{rlrrrrrrrll}
  \hline
 & Dataset Name & N subjects & N Admins & Mean Age & Min Age & Max Age & Avg Trials & Avg RT Trials & CDIs & longitudinal \\ 
  \hline
1 & Yurovsky et al. (2017) & 310 & 310 & 36.82 & 12.24 & 60.00 & 6.21 & 2.87 &  &  \\ 
  2 & Yurovsky et al. (2017b) & 282 & 282 & 25.64 & 12.59 & 58.65 & 5.95 & 2.79 &  &  \\ 
  3 & Weaver \& Zettersten (2024) & 141 & 248 & 15.73 & 13.50 & 23.60 & 18.10 & 6.72 &  & x \\ 
  4 & Fernald \& Marchman (2012) & 122 & 678 & 23.92 & 17.00 & 32.00 & 16.89 & 7.21 & x & x \\ 
  5 & Sander-Montant et al. (2023) & 122 & 122 & 21.94 & 12.02 & 31.11 & 10.07 & 4.20 & x &  \\
  6 & Frank et al. (2016) & 104 & 104 & 33.89 & 12.13 & 59.84 & 5.87 & 2.74 &  &  \\ 
  7 & Baumgartner (2014) & 100 & 100 & 12.01 & 12.00 & 13.00 & 4.00 & 2.31 & x &  \\ 
  8 & Fernald et al. (2013) &  80 & 179 & 20.04 & 17.00 & 26.00 & 21.26 & 8.44 & x & x \\ 
  9 & Adams et al. (2018) &  69 & 711 & 23.58 & 13.00 & 38.00 & 18.44 & 7.92 & x & x \\ 
  10 & Potter \& Lew Williams (n.d.) &  67 &  67 & 23.76 & 21.00 & 27.00 & 10.38 & 3.80 & x &  \\ 
  11 & Fernald et al. (2006) &  63 & 229 & 19.68 & 15.00 & 25.00 & 15.25 & 6.06 & x & x \\ 
  12 & Pomper \& Saffran (n.d.) &  63 &  63 & 39.73 & 37.90 & 42.00 & 12.98 & 5.34 &  &  \\ 
  13 & Pomper \& Saffran (2016) &  60 &  60 & 44.27 & 41.00 & 47.00 & 7.55 & 3.30 &  &  \\ 
  14 & Swingley \& Aslin (2002) &  50 &  50 & 15.09 & 14.13 & 16.00 & 11.74 & 3.79 & x &  \\ 
  15 & Pomper \& Saffran (2019) &  44 &  44 & 40.11 & 38.00 & 43.00 & 5.30 & 2.34 &  &  \\ 
  16 & Perry \& Saffan (2017) &  42 &  42 & 20.45 & 19.00 & 22.00 & 14.88 & 5.43 & x &  \\ 
  17 & Ronfard, Wei, \& Rowe (2022) &  40 &  40 & 19.95 & 18.00 & 24.00 & 18.54 & 7.62 & x &  \\ 
  18 & Bacon \& Saffran (2022) &  38 &  38 & 22.87 & 22.00 & 24.00 & 18.16 & 8.00 & x &  \\ 
  19 & Garrison \& Bergelson (2020) &  35 &  35 & 14.46 & 12.00 & 18.00 & 27.47 & 9.41 & x &  \\ 
  20 & Pomper \& Saffran (n.d.) &  32 &  32 & 26.38 & 25.00 & 28.00 & 7.62 & 2.31 &  &  \\ 
  21 & Mahr et al. (2015) & 29 &  29 & 20.83 & 18.10 & 23.80 & 24.38 & 8.86 & x &  \\ 
  22 & Ferguson, Graf, \& Waxman (2014) & 28 &  28 & 19.71 & 18.02 & 21.86 & 5.54 & 2.33 & x &  \\ 
  23 & Potter et al. (2019) &  23 &  44 & 22.59 & 18.00 & 29.00 & 6.07 & 2.58 & x & x \\ 
  24 & Newman \& Morini (2017)  &  19 &  19 & 30.12 & 29.23 & 30.84 & 13.11 & 4.94 &  &  \\ 
  \hline
    & Total & 1963 & 3554 & 24.73 & 12.00 & 60.00 & 12.74 & 5.05 & 15 & 6 \\ 
   \hline
\end{tabular}
\end{scriptsize}
\caption{Characteristics of included datasets from Peekbank. "Admins" denotes separate experimental sessions. "CDIs" refers to whether the dataset contains parent report vocabulary data from the MacArthur-Bates Communicative Development Inventory. \label{tab:datasets}} 
\end{table}

Word recognition speed has also been used as an index of individual differences in early childhood [@fernald2006;@marchman2008;@peter2019;@fernald2012;@newbury2016interrelationships] and beyond [@colby2023efficiency;@jeppsen2022development;@mcmurray2022slow]. Over and above measures of vocabulary size, word recognition speed at 18 months predicts children's standardized test scores years later [@marchman2008]. Further, faster processing at 18 months is predictive of whether "late talkers" catch up to their peers or could benefit from further intervention [@fernald2012].  Critically, these assessments use words that children at the target age are reported to understand and produce -- they are not indices of vocabulary size but rather of how quickly and accurately the child can recognize a familiar spoken word and use it to guide their visual attention to a referent. 

Yet given the logistical hurdles involved in sampling from this population, individual experiments measuring processing speed with young children typically recruit relatively small samples in a restricted range of ages. These samples provide neither the breadth of ages nor the number of participants needed to estimate how word recognition changes developmentally and how it connects with other aspects of early language development (see [@colby2023efficiency; @mcmurray2022slow] for examples of these analyses in school-aged children). To overcome these limitations, we created Peekbank, an open database of LWL data from young children, stored in a harmonized format [@zettersten2023peekbank]. This dataset unifies and carefully curates a large amount of eye-tracking data from studies with infants and toddlers, representing cumulatively over 12 million individual samples of children's eye movements during real-time language processing. The Peekbank dataset allows us to gain an unprecedented view of the development of word recognition across a large sample of children. 

We investigate two specific hypotheses here. First, one influential theory posits that language learning is a process of skill learning, in which the child is learning the skill of fluent conversation with other language users [@christiansen2016;@chater2018]. In this theory, the major information processing challenge of language learning is that incoming language is ephemeral and must be processed quickly before it is lost (the "now-or-never bottleneck"). On this kind of account, we should expect to see the signatures of expertise and skill learning in word recognition, which is one of the primary skills involved in processing incoming language in real time. Accuracy should change linearly with the logarithm of age, reflecting gradual asymptotic convergence to mature levels of accuracy. In addition, we might observe what is known as the "power law of practice," the regularity found in many cases of skill learning that the logarithm of reaction time decreases with the logarithm of experience across participants [@snoddy1926;@kail1991;@anderson1982; cf. @heathcote2000; @evans2018]. Indeed, this pattern is predicted by an influential associative process model of early word learning [@mcmurray2012].  In our case, we expect that chronological age is a proxy for experience and so the logarithm of reaction time should decrease linearly with the logarithm of age. Finally, trial-to-trial variability in both speed and accuracy should decrease with increasing expertise, as is found in studies of motor expertise [@todorov2002optimal]. 

Second, previous findings have provided limited and sometimes conflicting evidence on the concurrent and predictive relations between word recognition and language learning. Initial reports showed strong predictive relationships between both speed and accuracy and later vocabulary growth [@fernald2006], with replications in infants born preterm [@marchman2016] and late talkers [@fernald2012]. Subsequent studies have primarily focused on speed of processing and found more mixed results, with reaction time measures found to be only inconsistently predictive of later vocabulary outcomes [@peter2019;@newbury2016interrelationships;@lany2018]. A larger dataset should allow us to make a more definitive test of the presence of these relationships. Further, by examining the relationship between speed, accuracy, and vocabulary, it should be possible to assess the extent to which processing speed specifically plays a role in vocabulary growth.


```{r loading, echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(psych))
suppressPackageStartupMessages(library(lmerTest))
suppressPackageStartupMessages(library(lavaan))
suppressPackageStartupMessages(library(tidySEM))
suppressPackageStartupMessages(library(xtable))
suppressPackageStartupMessages(library(papaja))
suppressPackageStartupMessages(library(viridis))
#suppressPackageStartupMessages(library(nlme))
suppressPackageStartupMessages(library(cowplot))

source(here("helper","common.R"))

source(here("helper/modified_sem_plot.R"))

#load d_aoi for timecourse plot
d_aoi <- readRDS(here("cached_intermediates","0_d_aoi.Rds"))
d_trial <- readRDS(here("cached_intermediates","1_d_trial.Rds")) |>
  mutate(log_age = log(age))
d_sub <- readRDS(here("cached_intermediates","1_d_sub.Rds")) |>
  group_by(subject_id) |>
  arrange(age) |>
  mutate(admin_num = 1:n(), 
         time_since_t0 = age - age[1],
         delta_t = c(0, diff(age)))

d_trial$age_s <- scale(d_trial$age)[,1]
d_trial$log_age_s <- scale(d_trial$log_age)[,1]   
d_sub$age_s <- scale(d_sub$age)[,1]
d_sub$log_age_s <- scale(d_sub$log_age)[,1]   

AGEVAR_CUTOFF <- 6

datasets_with_age_variation <- d_trial |>
  group_by(dataset_name) |>
  summarise(age_range = max(age) - min(age)) |>
  filter(age_range >= AGEVAR_CUTOFF)

d_sub_agevar <- d_sub |>
  filter(dataset_name %in% datasets_with_age_variation$dataset_name)

longitudinal <- d_sub |>
  group_by(dataset_name, subject_id) |>
  count() |>
  filter(n > 1)

d_sub_firstadmin <- d_sub |>
  group_by(dataset_name, subject_id) |>
  filter(admin_num == 1) |>
  ungroup() |>
  select(-admin_num, -time_since_t0, -delta_t)

knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE)

#set to TRUE the first time running the document to ensure all cached elements are created (FALSE thereafter)
FIRST_TIME = FALSE
```

# Results {.unnumbered}

We retrieved data from Peekbank, focusing on data from English-speaking children ages 1--6 years and on simple word recognition trials in which children were shown two pictures of concrete objects and heard a label for an object (typically embedded in a simple carrier phrase such as "Look at the ..."). While other experimental manipulations and languages are included in the database, we narrowed our sample to English-speaking children because they are well-represented across our age range and excluded manipulations which aimed to capture phenomena other than simple concrete noun reference (e.g., adjective comprehension or novel word learning). These criteria yielded `r length(unique(d_sub$dataset_name))` datasets, including `r length(unique(d_sub$subject_id))` children and `r length(unique(d_sub$administration_id))` administrations of the LWL procedure (some datasets were longitudinal or involved multiple closely-spaced testing sessions). 

Table \ref{tab:datasets} shows the characteristics of individual datasets (see also SI: Dataset Description). The size of the combined dataset, the unified data processing pipeline, and the fact that individual studies used very similar implementations of the LWL experimental paradigm all allowed us to make a more detailed study of the development of word recognition than has previously been possible. While our analyses are exploratory in nature, they are guided by the two hypotheses outlined above: the presence of 1) signatures of skill learning in word recognition, and 2) linkages between word recognition and vocabulary.


```{r dataset_table}
dataset_characteristics <- d_sub |>
  group_by(dataset_name) |>
  summarise(`N subjects` = length(unique(subject_id)),
            `N admins` = n(), 
            `Mean Age` = mean(age), 
            `Min Age` = min(age), 
            `Max Age` = max(age), 
            `Avg Trials` = mean(n_trials[!is.na(long_window_accuracy)]),
            `Avg RT Trials` = mean(n_trials_rt[!is.na(rt)]),
            `CDIs` = ifelse(!is.na(any(prod)), "x", ""), 
            `longitudinal` = ifelse(any(duplicated(subject_id)), "x", "")) |>
  arrange(desc(`N subjects`)) 

dataset_characteristics <- dataset_characteristics |>
  bind_rows(tibble(dataset_name = "Total", 
                       `N subjects` = sum(dataset_characteristics$`N subjects`),
                       `N admins` = sum(dataset_characteristics$`N admins`), 
                       `Mean Age` = mean(dataset_characteristics$`Mean Age`),
                       `Min Age` = min(dataset_characteristics$`Min Age`), 
                       `Max Age` = max(dataset_characteristics$`Max Age`), 
                       `Avg Trials` = mean(dataset_characteristics$`Avg Trials`),
                       `Avg RT Trials` = mean(dataset_characteristics$`Avg RT Trials`),
                       `CDIs` = as.character(sum(dataset_characteristics$CDIs != "")),
                       `longitudinal` = as.character(sum(dataset_characteristics$longitudinal != ""))))
```

```{r eval=FALSE}
xtable(dataset_characteristics, 
       caption = "Characteristics of included datasets from Peekbank. `Admins` denotes separate experimental sessions.")
```


## Speed and accuracy of word recognition increase {.unnumbered}

```{r timecourse, fig.cap="Timecourse of word recognition at different ages. The x-axis shows time (in ms) from the onset of the target label (vertical solid line). Colored lines show the average increase in proportion target looking post label onset at each age bin (in months). Age bins are larger for older children due to decreased data density. The dashed horizontal line represents chance looking. Error bands represent standard errors of the mean. Grey backgrounds highlight the short and long time windows used in subsequent analyses.", fig.env="figure", fig.height = 4, include=TRUE}

#summarize by subject
d_timecourse_by_dataset_age_subj <- d_aoi |>
  filter(t_norm>-2000) |> 
  #create age bins cutoffs
  mutate(
    age_bin = cut(age, breaks = c(0,12,15,18,21,24,27,30,36,60), 
                  labels = c("<12", "12-15","15-18", "18-21", "21-24", "24-27","27-30","30-36", ">36"))
  ) |>
  #downsample t_norm to 50ms binsv
  #mutate(t_norm_downsampled = round(t_norm/50)*50) |>
  group_by(dataset_name,dataset_id,subject_id,age_bin,t_norm) |> 
  #calculate proportion time spent looking at target
  summarize(
    n=n(),
    accuracy = mean(correct, na.rm=TRUE))

#by age bin, not representing dataset structure
d_timecourse_by_age_overall <- d_timecourse_by_dataset_age_subj |>
  filter(n>=5) |> 
  group_by(age_bin,t_norm) |>
  summarize(
    n_subj=n(),
    proportion_target_looking = mean(accuracy,na.rm=TRUE),
    sem = sd(accuracy,na.rm=TRUE)/sqrt(n_subj)
  ) |> 
  rename(accuracy=proportion_target_looking)

#overall plot
d_timecourse_by_age_overall |> 
  filter(age_bin!="<12") |> 
  filter(t_norm>-1000) |> 
  ggplot(aes(x=t_norm, y=accuracy, group=age_bin, color=age_bin)) +
  geom_rect(xmin=2000,xmax=4000,ymin=0,ymax=1.2,fill="#DFDFDF",color=NA,alpha=0.05)+
  geom_rect(xmin=200,xmax=2000,ymin=0,ymax=1.2,fill="#F2F2F2",color=NA,alpha=0.05)+
  geom_smooth(stat="identity", aes(y=accuracy, ymin=accuracy-sem, ymax=accuracy+sem,fill=age_bin))+
  #geom_smooth(stat="smooth")+
  geom_hline(yintercept=0.5, linetype="dashed")+
  geom_vline(xintercept=0, linetype="solid")+
  #add text
  annotate("text", x=50, y=0.85, label="Label Onset", hjust=0, vjust=0,size=3)+
  annotate("text", x=400, y=0.99, label="SHORT WINDOW",hjust=0, vjust=0,size=2.5)+
  annotate("text", x=1500, y=0.93, label="LONG WINDOW",hjust=0, vjust=0,size=2.5)+
  geom_segment(aes(x = 1000, y = 0.98, xend = 200, yend = 0.98),
               arrow = arrow(type = "closed", angle = 20, length = unit(0.05, "inches")), color="black")+
  geom_segment(aes(x = 1000, y = 0.98, xend = 2000, yend = 0.98),
               arrow = arrow(type = "closed", angle = 20, length = unit(0.05, "inches")), color="black")+
  geom_segment(aes(x = 2000, y = 0.92, xend = 200, yend = 0.92),
               arrow = arrow(type = "closed", angle = 20, length = unit(0.05, "inches")), color="black")+
  geom_segment(aes(x = 2000, y = 0.92, xend = 4000, yend = 0.92),
               arrow = arrow(type = "closed", angle = 20, length = unit(0.05, "inches")), color="black")+
  scale_color_viridis_d(name="Age Bin\n(mos)", guide = guide_legend(reverse = TRUE))+
  scale_fill_viridis_d(name="Age Bin\n(mos)", guide = guide_legend(reverse = TRUE))+
  #facet_wrap(~age_bin)+
  scale_y_continuous(breaks=seq(0.4,1,0.1),limits=c(0.4,1))+
  scale_x_continuous(breaks=seq(-1000,4000,1000),limits=c(-1050,4000))+
  xlab("Time from trial onset (ms)")+
  ylab("Proportion Target Looking")+
  theme_cowplot()+
  theme(legend.key.size = unit(0.3, 'cm'), #change legend key size
        legend.key.height = unit(0.3, 'cm'), #change legend key height
        legend.key.width = unit(0.3, 'cm'), #change legend key width
        legend.text = element_text(size=9),
        legend.title = element_text(size=9),
        legend.position=c(0.03,0.6),
        axis.title = element_text(size=12),
        axis.text = element_text(size=10))
```


```{r acc_mods}
d_trial$age_s <- scale(d_trial$age)[,1]
d_trial$log_age_s <- scale(d_trial$log_age)[,1]   

acc_mods_lmer <- list(lwa_lin = lmer(long_window_accuracy ~ age_s  +
                                     + (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                      lwa_log = lmer(long_window_accuracy ~ log_age_s +
                                     + (log_age_s | dataset_name) + (1 | subject_id), data = d_trial),
                      swa_lin = lmer(short_window_accuracy ~ age_s  +
                                     + (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                      swa_log = lmer(short_window_accuracy ~ log_age_s +
                                     + (log_age_s | dataset_name) + (1 | subject_id), data = d_trial))

acc_mods_lmer_summary <- map_df(acc_mods_lmer, ~broom.mixed::glance(.x)) |>
  mutate(model = names(acc_mods_lmer), 
         r2 = map_dbl(acc_mods_lmer, ~performance::r2_nakagawa(.x)$R2_conditional))
```


```{r rt_mods}
rt_mods_lmer <- list(log_lin = lmer(log_rt ~ age_s + 
                                      (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                     log_log = lmer(log_rt ~ log_age_s + 
                                      (log_age_s | dataset_name) + (1 | subject_id), data = d_trial),
                     lin_lin = lmer(rt ~ age_s + 
                                      (age_s | dataset_name) + (1 | subject_id), data = d_trial),
                     lin_log = lmer(rt ~ log_age_s +  
                                      (log_age_s | dataset_name) + (1 | subject_id), data = d_trial))

rt_mods_lmer_summary <- map_df(rt_mods_lmer, ~broom.mixed::glance(.x)) |>
  mutate(model = names(rt_mods_lmer), 
         r2 = map_dbl(rt_mods_lmer, ~performance::r2_nakagawa(.x)$R2_conditional))
```

We began by examining developmental changes in children's word recognition. Figure \ref{fig:timecourse} depicts the average timecourse at different ages across all datasets (not controlling for any variation in items and procedures across age groups). Intuitively, these timecourses show gradual increases in accuracy (higher overall proportion target looking) and speed (faster looking to the target after hearing a label) as age increases. To characterize age gradients in speed and accuracy across children, we computed both RTs (reaction times) and accuracies (proportion looking at the target image) following standard practices in the literature [@fernald2008]. Reaction times were computed only on trials for which the child was fixating the distractor at the point of disambiguation (label onset), and were defined as the time from label onset to the first fixation on the target image (see SI: Reaction Time Computation). 

Because there is no consensus about the length of time windows for the computation of accuracy, we considered both a shorter window (from 200 -- 2000 ms after noun onset) and a longer window (from 200 -- 4000 ms). For each window, we averaged all fixations within the window to compute a continuous proportion of target looking between 0 (no fixation on the target during the window) and 1 (total fixation on the target during the window) on every trial. In this initial analysis, we treat observations of RT and target looking as direct measures of the constructs speed and accuracy (see SI: Test-Retest Reliability); in subsequent analyses we estimate latent variables representing these constructs.

Our first question was about the functional form of the relationships between age, speed, and accuracy (see SI: Correlations for raw pairwise correlations between variables). We began by fitting linear mixed-effects models predicting speed and accuracy on each trial across the full dataset with random slopes of child age nested within study (modeling item and procedural variation across studies) and random intercepts by participant. We compared models that included both long and short accuracy windows, as well as logarithmic and linear effects of age, and logarithmic and linear transformations of RT. The best fitting model of accuracy predicted long window accuracy as a function of the logarithm of age; the best fitting model of speed predicted log RT as a function of log age as well (see SI: Functional Form Model Comparison and SI: Power Law Fits). Because long window accuracies were more correlated with other variables and showed clearer age gradients, we focus on these in our analyses.

Figure \ref{fig:devchange} shows these age gradients. Log RT decreased significantly with age, reflecting increasing speed (`r papaja::apa_print(rt_mods_lmer[[2]])$full_result$log_age_s`) and accuracy also increased significantly with age  (`r papaja::apa_print(acc_mods_lmer[[2]])$full_result$log_age_s`). In sum, we see continuing improvements in word recognition across the full age range in our dataset that appear roughly linear in the logarithm of age. These logarithmic relationships follow theoretical expectations that both speed and accuracy should gradually asymptote to mature levels of performance, as seen in skill learning more generally [@anderson1982;@snoddy1926]. 

```{r devchange, fig.cap="Participant-level target looking and reaction time (log), plotted by age (log). Longitudinal datapoints are connected by lines. The solid blue line shows a linear fit and associated confidence interval. Thin colored lines show linear fits for those datasets spanning six or more months of age. The dashed line for accuracy shows chance-level looking (.5)", fig.env="figure", fig.height = 2.5}

#library(RColorBrewer)

mycolors = c("#1B9E77", "#D95F02", "#E7298A", "#66A61E", "#1B9E77", "#D95F02", "#E7298A", "#66A61E", "#1B9E77", "#D95F02", "#E7298A", "#66A61E","#1B9E77", "#D95F02")
# 4 colors from brewer scale "Dark2" that I thought had decent contrast against the grey/black background dots


a <- ggplot(d_sub,
            aes(x = age, y = long_window_accuracy)) + 
  geom_point(alpha = .02) + 
  geom_line(aes(group = subject_id), alpha = .05) + 
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = 1, method = "lm", size = .25, lty = 1) + 
  geom_smooth(method = "lm") +
  geom_hline(yintercept = .5, lty = 3) + 
  scale_x_log10(breaks = c(12,24,36,48,60)) +
  scale_color_manual(values=mycolors, guide = FALSE) + 
  ylab("Proportion Target Looking") + 
  xlab("Age (months)")

b <- ggplot(d_sub,
            aes(x = age, y = rt)) + 
  geom_point(alpha = .02) + 
  geom_line(aes(group = subject_id), alpha = .05) + 
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .25, lty = 1) + 
  geom_smooth(method = "lm") +
  scale_x_log10(breaks = c(12,24,36,48,60)) +
  scale_y_log10() +
  scale_color_manual(values=mycolors, guide = FALSE) + 
  theme(legend.position = "bottom") + 
  ylab("Reaction Time (log)") + 
  xlab("Age (months)")

cowplot::plot_grid(a,b)
```


## Variability of word recognition decreases {.unnumbered}

```{r var_mods}
acc_var_mod <- lmer(long_window_acc_var ~ log_age_s + (log_age_s | dataset_name) + 
                 (1 | subject_id), 
               data = d_sub)


rt_var_mod <- lmer(log_rt_var ~ log_age_s + (log_age_s | dataset_name) + 
                 (1 | subject_id), 
               data = d_sub)
```

One further hallmark of increasing skill is a decrease in task-relevant variability [@todorov2002optimal]. Both within and across datasets, within-individual variation in speed and accuracy decreased across the developmental range we examined (Figure \ref{fig:variance}). We fit mixed-effects models predicting the standard deviation of both speed and accuracy for each testing session for each participant, including random slopes of log age nested within dataset and random intercepts for each participant. For both speed and accuracy, within-individual variability decreased with age (speed: `r papaja::apa_print(rt_var_mod)$full_result$log_age_s`; accuracy: `r papaja::apa_print(acc_var_mod)$full_result$log_age_s`). Thus, as well as being faster and more accurate, older children were more consistent in their real-time word recognition than younger children.

```{r variance, fig.cap="Participant-level variability in target looking and reaction time (log RT), plotted by age (log). Plotting conventions are as in Figure 1.", fig.env="figure", fig.height = 2.5}
  mycolors = c("#1B9E77", "#D95F02", "#E7298A", "#66A61E", "#1B9E77", "#D95F02", "#E7298A", "#66A61E", "#1B9E77", "#D95F02", "#E7298A", "#66A61E","#1B9E77", "#D95F02")

c <- ggplot(d_sub,
       aes(x = age, y = long_window_acc_var)) + 
  geom_point(alpha = .02) + 
  geom_line(aes(group = subject_id), alpha = .05) + 
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .25, lty = 1) + 
    geom_smooth(method = "lm") +
  scale_x_log10(breaks = c(12,24,36,48,60)) +
  scale_color_manual(values=mycolors, guide = FALSE) + 
  ylab("SD of Prop Target Looking") + 
  xlab("Age (months)")

d <- ggplot(d_sub,
       aes(x = age, y = log_rt_var)) + 
  geom_point(alpha = .02) + 
  geom_line(aes(group = subject_id), alpha = .05) + 
  geom_smooth(data = d_sub_agevar,
              aes(group = dataset_name, col = dataset_name), se=FALSE,
              alpha = .1, method = "lm", size = .25, lty = 1) + 
    geom_smooth(method = "lm") +
  scale_x_log10(breaks = c(12,24,36,48,60)) +
  scale_color_manual(values=mycolors, guide = FALSE) + 
  theme(legend.position = "bottom") + 
  ylab("SD of log RT") + 
  xlab("Age (months)")

cowplot::plot_grid(c,d)
```


## Speed and accuracy relate to vocabulary size {.unnumbered}

We were next interested in whether the various aspects of word recognition -- including speed, accuracy, and the variability of each of these -- were related to other aspects of early language ability. Of the studies in our database, `r sum(dataset_characteristics$CDIs == "x")` gathered parent reports about children's early vocabulary using the MacArthur-Bates Communicative Development Inventory (CDI), a popular survey instrument that provides a reliable and valid estimate of children's early vocabulary [@marchman2023;@frank2021]. Different forms of the CDI can be used to measure either receptive and expressive vocabulary (for children up to 18 months) or expressive vocabulary only (for children 16 -- 30 months). 

```{r efa}
d_sub_mat <- d_sub |>
  ungroup() |>
  select(dataset_name, log_rt, log_rt_var, long_window_accuracy, long_window_acc_var, prod, comp, age, log_age) 


d_sub_mat_s <- d_sub_mat |>
  ungroup() |>
  mutate(across(all_of(c("log_rt", "log_rt_var", "long_window_accuracy", 
                         "long_window_acc_var", "prod", "comp")), 
                       ~ age_scale(.x, age))) 

parallel_ana <- capture.output(fa.parallel(select(d_sub_mat, -dataset_name, -age, -log_age), fa = "fa", 
            use = "pairwise.complete.obs", plot=FALSE))
```

```{r cfa}
fa3_model <- "vocab =~ prod + comp
              accuracy =~ long_window_accuracy + long_window_acc_var
              speed =~ log_rt + log_rt_var"

fit3 <- cfa(fa3_model, d_sub_mat_s, std.lv=TRUE, missing='fiml')

fit_stats <- suppressMessages(summary(fit3, fit.measures=TRUE, standardize=TRUE))
```

We fit a series of factor analytic models to explore the dimensionality of the parent report and child LWL data. Our goal in these analyses was to understand the underlying relatedness of the various measures of word recognition and vocabulary, and in particular to assess the evidence for 1) whether the speed, accuracy, and variability measures described above all index the same underlying language processing construct and 2) the nature of the relation between this construct (or set of constructs) and early vocabulary. We begin developing models using all data, treating each observation as independent even if it comes from a longitudinal study; this assumption is equivalent to asserting an invariant factor structure across development (for a test of this assumption, see SI: Factor Analysis on First Administrations). In subsequent models, we relax this assumption and explore longitudinal growth.

Initial exploratory factor analysis using parallel analysis to select the number of factors suggested that three factors explained substantial variance in the data (see SI: Factor Analysis). To better accommodate missing data under the assumption of data missing at random (e.g., missingness due to the age sampling schemes of the various datasets), we used confirmatory factor analysis with full information maximum likelihood to find the best set of loadings. The best fitting model was a three-factor model with factors for speed (RT and RT variability), accuracy (proportion looking to target on each trial and associated variability of this measure), and vocabulary (comprehension and production from the CDI). Fit statistics for this model were generally good (Confirmatory fit index: `r round(fit_stats$fit["cfi"], 3)`, RMSE: `r round(fit_stats$fit["rmsea"], 3)`); see SI: Alternative Factor Structures). 


```{r age-regression, fig.env="figure", fig.cap="Structural equation model showing the three-factor factor analysis with a regression of each latent variable on the logarithm of age. Observed variables are notated as squares and latent variables are notated as circles Factor loadings and regression coefficients are shown with straight, solid lines; covariances are shown with dashed lines; residual variances are shown as solid circular connections. Stars show conventional levels of statistical significance, e.g. * indicates p < .05, ** indicates p < .01, and *** indicates p < .001. Covariances reflect age-residualized correlations between variables.", fig.height = 3}

d_sub_mat_s_renamed <- d_sub_mat_s |>
  rename(acc = long_window_accuracy, 
         acc_sd = long_window_acc_var, 
         log_rt_sd = log_rt_var)

fa3_age_model <- "
# measurement model
vocab =~ prod + comp
accuracy =~ acc + acc_sd
speed =~ log_rt + log_rt_sd

# regressions
vocab ~ log_age
accuracy ~ log_age
speed ~ log_age
"

fit3_age <- cfa(fa3_age_model, d_sub_mat_s_renamed, std.lv=TRUE, missing='fiml')

fit3_age_summary <- suppressMessages(summary(fit3_age, fit.measures=TRUE, 
                                             standardize=TRUE))

layout_age = matrix(nrow=5, ncol = 6,
                data = c(NA,NA,"log_age",NA, NA, NA,
                         NA, NA, NA, NA, NA, NA, 
                         "speed",NA,"accuracy",NA,"vocab",NA,
                         NA, NA, NA, NA, NA, NA, 
                         "log_rt","log_rt_sd", "acc",
                         "acc_sd", "prod","comp"), 
                byrow = TRUE)


node_text <- tibble(name=c("acc", "acc_sd", "accuracy", "comp", "log_age", "log_rt", "log_rt_sd", "prod", "speed", "vocab"), pretty=c("Target Looking", "Target Looking (SD)", "Accuracy", "Comprehension", "Age (log months)", "log RT", "log RT (SD)", "Production", "Speed", "Vocabulary"))

nodes <- get_nodes(fit3_age) |> tibble() |> left_join(node_text) |> mutate(label=ifelse(shape=="oval",pretty, str_c(pretty, "\n", est_sig)))


edges <- get_edges(fit3_age) |> filter(label!="1.00") |> mutate(label_location=.5) |> mutate(label_hjust=.5, label_vjust=.5, label_lineheight=1.5)

edges[9, "label_hjust"]=1
edges[7, "label_hjust"]=1

edges[18, "label_hjust"]=0
edges[16, "label_hjust"]=0

edges[17,"curvature"]=50
edges[17,"label_location"]=.6
edges[, "label_fill"]="white"

source(here("helper/modified_sem_plot.R"))

#View(edges)
prepare_graph(edges=edges, nodes=nodes, text_size = 2.5, layout = t(layout_age),
          rect_width=4.2,
          rect_height=3,
          ellipses_width=3,
          ellipses_height=3,
          variance_height=2,
          variance_width=1.5,
          arrow_angle=15,
          arrow_length=.1,
          var_arrow_angle=15,
          var_arrow_length=.1,
          spacing_y=4,
          spacing_x=4,
          fix_coord=FALSE) |> plot_happy_arrows()
```

Figure \ref{fig:age-regression} shows a regression model fit to this confirmatory factor analysis, with log age predicting each latent variable. This regression model allows interpretation of the covariances between latent factors as partial correlations (controlling for age). The non-age related variance of all three latent factors was significantly related to that of the other factors, with speed and accuracy showing strong negative covariance ($\beta=$ `r round(fit3_age_summary$pe[21,"est"],3)`, SE = `r round(fit3_age_summary$pe[21,"se"],3)`, $p < .0001$) and weaker but significant covariation between RT and vocabulary ($\beta=$ `r round(fit3_age_summary$pe[20,"est"],3)`, SE = `r round(fit3_age_summary$pe[20,"se"],3)`, $p < .0001$) and accuracy and vocabulary ($\beta=$ `r round(fit3_age_summary$pe[19,"est"],3)`, SE = `r round(fit3_age_summary$pe[19,"se"],3)`, $p < .0001$). This model supports the idea that variation in speed and accuracy of word recognition is related to individual differences in parent-reported vocabulary beyond the effects of age. Further, the broader set of analyses support a factor structure in which speed and accuracy (and their associated variabilities) are related but distinct aspects of word recognition, rather than being measures of one single construct. These analyses treat all data as between person, however, rather than modeling change in these factors within individuals. 


## Speed of processing relates to vocabulary growth {.unnumbered}

```{r}
d_growth <- d_sub |>
  filter(!is.na(prod), subject_id %in% longitudinal$subject_id) |>
  group_by(subject_id) |>
  arrange(age) |>
  mutate(rt_t0 = log_rt[1]) |>
  ungroup() |>
  mutate(rt_t0_group = ifelse(rt_t0 < median(rt_t0, na.rm=TRUE), "low", "high"))

d_growth$age_15 <- d_growth$age - 15

# note that it's singular to add an age by dataset random effect
growth_mod <- lmer(prod ~ poly(age_15,2) *rt_t0 + (age  | subject_id) + (1 | dataset_name), 
     data = d_growth, 
     control = lmerControl(optimizer = "bobyqa"))

# summary(growth_mod)
```


To investigate within-person relationships between LWL and vocabulary, we began by fitting longitudinal growth models to the portion of the data containing multiple LWL sessions for individual children. We first reproduced the analysis reported in @fernald2012, in which between-person differences in longitudinal growth in productive vocabulary were predicted based on between-person differences in speed during the initial session of the study. We fit a mixed-effects model predicting growth in vocabulary as a quadratic function of age, RT at study initiation ($t_0$), and their interaction (as well as random effects of age nested within participant and also age nested within dataset). This model revealed a significant effect of $t_0$ RT (`r papaja::apa_print(growth_mod)$full_result$rt_t0`) and an interaction between $t_0$ RT and the quadratic age predictor (`r papaja::apa_print(growth_mod)$full_result$polyage_15_22_rt_t0`). This analysis suggests that children with faster initial RTs show both larger vocabularies and faster vocabulary growth over time. 

We confirmed this analysis using a non-linear growth model with a logistic shape, which provides a better fit to vocabulary size within a fixed-length form than the quadratic model (see SI: Non-Linear Growth Model) [@frank2021]. Figure \ref{fig:growth} shows predictions from this model, confirming the differentiation of growth curves for children with higher and lower initial reaction time. 

```{r}
d_sub_prod <- filter(d_sub, !is.na(prod), !is.na(log_rt)) |>
  ungroup() |>
  mutate(log_rt_resid = resid(lm(log_rt ~ log_age))) |>
  group_by(subject_id) |>
  mutate(log_rt_0 = log_rt[1],
         log_rt_0_resid = log_rt_resid[1],
         acc_0 = long_window_accuracy[1]) |> 
  filter(!is.na(log_rt_0)) 

d_sub_prod$age_c <- d_sub_prod$age - mean(d_sub_prod$age, na.rm = TRUE)
d_sub_prod$log_rt_0_c <- d_sub_prod$log_rt_0 - mean(d_sub_prod$log_rt_0, na.rm = TRUE)
```

```{r, eval=FIRST_TIME}
library(brms)

# Define the nonlinear formula
nlform <- brms::bf(
  prod ~ 1 / (1 + exp((xmid - age_c) / exp(logscale))),
  xmid ~ 1 + log_rt_0_c  + (1 | dataset_name/subject_id),
  logscale ~ 1 + log_rt_0_c  + (1 | dataset_name/subject_id),
  # scale ~ 1 + log_rt_0_c,
  nl = TRUE
)

# xmid ~ 1 + log_rt_0_c + (1 | dataset_name/subject_id),
# scale ~ 1 + log_rt_0_c + (1 | dataset_name/subject_id),


priors <- c(
  prior(normal(0, 5), nlpar = "xmid", coef = "Intercept"),  # xmid near center of age_c
  prior(normal(1, 1), nlpar = "logscale", coef = "Intercept"), # scale > 0, mildly steep curve
  prior(normal(0, 1), nlpar = "logscale", coef = "log_rt_0_c"),
  prior(exponential(1), class = "sigma"),                # residual error
  prior(normal(0, 2), nlpar = "xmid", coef = "log_rt_0_c"),
  # prior(normal(0, 1), nlpar = "scale", lb = 0)
  
  # Random effects for xmid
  prior(exponential(1), class = "sd", nlpar = "xmid", group = "dataset_name"),
  prior(exponential(1), class = "sd", nlpar = "xmid", group = "dataset_name:subject_id"),
  
  # Random effects for scale
  prior(exponential(1), class = "sd", nlpar = "logscale", group = "dataset_name"),
  prior(exponential(1), class = "sd", nlpar = "logscale", group = "dataset_name:subject_id")
)
#

# Fit the model
mod_brms <- brm(
  formula = nlform,
  data = d_sub_prod,
  prior = priors,
  family = gaussian(),
  # init = 0,  # initialize all parameters to 0 on unconstrained scale (safe for centered priors)
  chains = 4, cores = 4,
  control = list(adapt_delta = 0.95),
  # backend = "cmdstanr",  # optional but faster
  save_pars = save_pars(all = TRUE),
  sample_prior = "yes",
  file="brms1.rds"
)

summary(mod_brms)$fixed |> saveRDS("brms1_coef.rds")

new_data <- expand.grid(
  age_c = seq(min(d_sub_prod$age_c), max(d_sub_prod$age_c), length.out = 100),
  log_rt_0_c = c(-1, 0, 1)  # e.g., low, mean, high values
)

fitted_vals <- fitted(mod_brms, newdata = new_data, re_formula = NA, summary = TRUE)

saveRDS(fitted_vals, "brms1_fitted.rds")

```


```{r growth, fig.cap="Growth curves from a logistic growth model showing predicted vocabulary growth for children with initial reaction times one SD faster than the mean (blue), at the mean (red), and one SD slower than the mean (green). Individual longitudinal trajectories are shown in light gray. Solid lines show global model estimates and colored regions indicate 95% credible intervals.", fig.env="figure", fig.height = 4, fig.width=6, out.width=".6\\textwidth", include=TRUE}


fitted_vals <- readRDS("brms1_fitted.rds")


new_data <- expand.grid(
  age_c = seq(min(d_sub_prod$age_c), max(d_sub_prod$age_c), length.out = 100),
  log_rt_0_c = c(-1, 0, 1)  # e.g., low, mean, high values
)

new_data$fit <- fitted_vals[, "Estimate"]
new_data$lower <- fitted_vals[, "Q2.5"]
new_data$upper <- fitted_vals[, "Q97.5"]

ggplot(new_data, aes(x = age_c, y = fit, col = as.factor(log_rt_0_c))) +
    geom_line(data = d_sub_prod, aes(x = age_c, y = prod, group=subject_id), col = "black", alpha=.1) + 
  geom_line(linewidth = 2) +
  geom_ribbon(aes(ymin = lower, ymax = upper, fill = as.factor(log_rt_0_c), group = as.factor(log_rt_0_c)), 
              alpha = 0.3) +
  labs(x = "Centered Age", y = "Predicted prod (fixed effects only)") +
  theme_minimal() + 
  scale_color_solarized(name = "log RT at t0 (SD)") + 
  scale_fill_solarized(guide = FALSE)


```

```{r prep_long_data}
# rename and scale variables
d_sub_s <- d_sub |>
  ungroup() |>
  select(dataset_name, subject_id, administration_id, age, 
         time_since_t0, delta_t,
         log_rt, log_rt_var, 
         long_window_accuracy, long_window_acc_var, prod, comp, ) |>
  rename(acc = long_window_accuracy, 
         acc_sd = long_window_acc_var, 
         log_rt_sd = log_rt_var) |>
  ungroup() |>
  mutate(across(all_of(c("log_rt", "log_rt_sd", "acc", "acc_sd", 
                         "prod", "comp")), 
                       ~ age_scale(.x, age))) 

d_sub_wide_fine <- d_sub_s |>
  mutate(t = cut(time_since_t0, breaks = c(0, 2, 4, 6, 8, 10, 30), 
                 include.lowest = TRUE)) |>
  filter(t != "(12,30]") |>
  mutate(t = as.numeric(t) -1) |>
  group_by(subject_id, dataset_name, t) |>
  summarise(across(all_of(c("log_rt", "log_rt_sd", "acc",
                            "acc_sd", "prod", "comp")),
                   ~ mean(.x, na.rm=TRUE))) |> 
  mutate(across(all_of(c("log_rt", "log_rt_sd", "acc",
                         "acc_sd", "prod", "comp")),
                ~ ifelse(is.nan(.x), NA, .x))) |>
  pivot_wider(id_cols = c("subject_id","dataset_name"), 
              names_from = "t",
              values_from = c("log_rt", "log_rt_sd", "acc", 
                              "acc_sd", "prod", "comp"), 
              names_prefix = "t")


slopes_model_long <- "

# regressions
accuracy_intercept =~ 1*acc_t0 + 1*acc_t1 + 1*acc_t2 + 1*acc_t3 + 1*acc_t4
accuracy_slope =~ 1*acc_t0 + 2*acc_t1 + 3*acc_t2 + 4*acc_t3 + 5*acc_t4
speed_intercept =~ 1*log_rt_t0 + 1*log_rt_t1 + 1*log_rt_t2 + 1*log_rt_t3 + 1*log_rt_t4
speed_slope =~ 1*log_rt_t0 + 2*log_rt_t1 + 3*log_rt_t2 + 4*log_rt_t3 + 5*log_rt_t4
vocab_intercept =~ 1*prod_t0 + 1*prod_t1 + 1*prod_t2 + 1*prod_t3 + 1*prod_t4
vocab_slope =~ 1*prod_t0 + 2*prod_t1 + 3*prod_t2 + 4*prod_t3 + 5*prod_t4
# let variances of each latent vary
accuracy_intercept ~~ NA*accuracy_intercept
accuracy_slope ~~ NA*accuracy_slope
speed_intercept ~~ NA*speed_intercept
speed_slope ~~ NA*speed_slope
vocab_intercept ~~ NA*vocab_intercept
vocab_slope ~~ NA*vocab_slope
"

slopes_long <- growth(slopes_model_long, d_sub_wide_fine, std.lv=TRUE, missing='fiml')

slopes_long_summary <- suppressMessages(summary(slopes_long, fit.measures=TRUE, standardize=TRUE))
```

On the other hand, it is possible that differences in predicted growth trajectories are due to coupling between vocabulary size and language processing across the entire developmental period, rather than a predictive relationship specifically between $t_0$ RT and vocabulary growth. To test this relationship, we used longitudinal structural equation models. We separated the longitudinal speed, accuracy, and vocabulary data into two-month bins spanning up to 10 months from the initial measurement (i.e., $t_0, ..., t_4$) and fit individual growth across each of these variables. We used full-information maximum likelihood to handle the substantial missing data caused by the different longitudinal sampling schemes of studies in our dataset (se SI: SEM Longitudinal Missingness). The fitted longitudinal model is shown in Figure \ref{fig:longitudinal}. Overall fit statistics were generally acceptable (Confirmatory fit index: `r round(slopes_long_summary$fit["cfi"], 3)`, RMSE: `r round(slopes_long_summary$fit["rmsea"], 3)`, RMSE $p$-value: `r round(slopes_long_summary$fit["rmsea.pvalue"], 3)`). 

Our key question of interest concerned coupling among the (latent) intercepts and slopes of these growth models. Consistent with our earlier analysis showing that faster processing is related to vocabulary growth, we saw significant coupling between processing speed intercepts and vocabulary growth slopes ($\beta=$ `r round(slopes_long_summary$pe[63,"est"],3)`, SE = `r round(slopes_long_summary$pe[63,"se"],3)`, $p =$ `r round(slopes_long_summary$pe[63,"pvalue"],3)`) as well as a variety of other couplings. On the other hand, there was not significant coupling between *growth* in speed and *growth* in vocabulary ($\beta=$ `r round(slopes_long_summary$pe[65,"est"],3)`, SE = `r round(slopes_long_summary$pe[65,"se"],3)`, $p =$ `r round(slopes_long_summary$pe[65,"pvalue"],3)`). This null effect could be interpreted as being consistent with these abilities growing independently, but there are other possibilities. First, the longitudinal data we had might not have allowed sufficiently precise estimates of growth slopes, or second, since vocabulary growth is non-linear, the linear model we used here might not have captured coupling among nonlinear aspects of developmental change. 

In sum, these findings provide evidence consistent with the claim that differences in processing speed are related to differences in the rate of age-related change in vocabulary [@fernald2006;@Weisleder2013]. Children with greater skill in word recognition learn words faster.


```{r longitudinal, fig.env="figure", height = 3.5, fig.cap = "Structural equation model showing longitudinal couplings between growth parameters. "}
layout <- read.csv(here("misc/layout_slopes_observed_growth.csv"), header = FALSE)

acc_color <- "#B2DF8A"
rt_color <- "#FB9A99"
prod_color <- "#FFFF99"

intercept_color <- "#1F78B4"
intercept_background <- "#A6CEE3"
slope_color <- "#FF7F00"
slope_background <- "#FDBF6F"

#"#A6CEE3" "#1F78B4" "#B2DF8A" "#33A02C"
# [5] "#FB9A99" "#E31A1C" "#FDBF6F" "#FF7F00"
# [9] "#CAB2D6" "#6A3D9A" "#FFFF99" "#B15928"
node_text <- tribble(~name, ~ pretty, ~fill, 
                     "acc_t0", "t0 Target Looking", acc_color,
                     "acc_t1", "t1 Target Looking", acc_color,
                     "acc_t2", "t2 Target Looking",acc_color,
                     "acc_t3", "t3 Target Looking",acc_color,
                     "acc_t4", "t4 Target Looking",acc_color,
                     "accuracy_intercept", "Accuracy intercept",acc_color,
                     "accuracy_slope", "Accuracy slope",acc_color,
                     "log_rt_t0", "t0 log RT",rt_color,
                     "log_rt_t1", "t1 log RT",rt_color,
                     "log_rt_t2", "t2 log RT",rt_color,
                     "log_rt_t3", "t3 log RT",rt_color,
                     "log_rt_t4", "t4 log RT",rt_color,
                     "prod_t0" , "t0 Production", prod_color,
                     "prod_t1" , "t1 Production",  prod_color,
                     "prod_t2" , "t2 Production" ,  prod_color,
                     "prod_t3", "t3 Production",         prod_color,
                     "prod_t4", "t4 Production" , prod_color,
                     "speed_intercept" , "Speed intercept" , rt_color,
                     "speed_slope" , "Speed slope",rt_color,
                     "vocab_intercept", "Vocabulary intercept", prod_color,
                     "vocab_slope", "Vocabulary slope",  prod_color ) |> 
  mutate(alpha=.1)

nodes <- get_nodes(slopes_long) |> tibble() |> left_join(node_text) |> mutate(label=pretty)


edges <- get_edges(slopes_long) |> mutate(label_location=.5) |> mutate(label=ifelse(arrow=="last", NA, label)) |>  mutate(connect_from=ifelse(to==from, "right",NA),
                    connect_to=connect_from) |> 
  mutate(color="black", label_hjust=.5, label_location=.5, label_fill="white")

edges[52,"curvature"]=85
#edges[52,"color"]="blue"
edges[61,"curvature"]=85
#edges[61,"color"]="blue"
edges[66,"curvature"]=85
#edges[66,"color"]="blue"
edges[52, "label_hjust"]=0
edges[61, "label_hjust"]=0
edges[66, "label_hjust"]=0



edges[54,"curvature"]=85
edges[54, "label_hjust"]=0

edges[63,"curvature"]=85
edges[63, "label_hjust"]=0


edges[53,"curvature"]=80
edges[53,"color"]=intercept_color
edges[53, "label_fill"]=intercept_background
edges[55,"curvature"]=82
edges[55,"label_location"]=.55

edges[55,"color"]=intercept_color
edges[55, "label_fill"]=intercept_background

edges[62,"curvature"]=80
edges[62,"color"]=intercept_color
edges[62, "label_fill"]=intercept_background

edges[53, "label_location"]=.6
edges[53, "label_hjust"]=0.4



edges[58,"curvature"]=80
edges[58,"color"]=slope_color
edges[58, "label_fill"]=slope_background

edges[60,"curvature"]=82
edges[60,"color"]=slope_color
edges[60, "label_fill"]=slope_background
edges[60,"label_location"]=.45
edges[65,"curvature"]=80
edges[65,"color"]=slope_color
edges[65, "label_fill"]=slope_background
edges[65, "label_location"]=.4
edges[53, "label_hjust"]=0.4



edges[59,"curvature"]=77

edges[64,"curvature"]=75
edges[56,"curvature"]=75
edges[57,"curvature"]=75


source(here("helper/modified_sem_plot.R"))
#View(edges)
prepare_graph(edges=edges, nodes=nodes, text_size = 2, layout = t(layout),angle=0,
          rect_width=1.5,
          rect_height=2,
          ellipses_width=1.5,
          ellipses_height=3,
          variance_width= .5,
          variance_height=1.3,
          var_arrow_angle=10,
          var_arrow_length=.05,
          arrow_angle=15,
          arrow_length=.07,
          variance_diameter=1,
          spacing_y=2.5,
          spacing_x=1.5,
          fix_coord=FALSE) |> 
  edit_edges({connect_from=case_when(
    (to==from & from %in% c("accuracy_intercept","accuracy_slope","speed_slope",
                          "speed_intercept", "vocab_slope", "vocab_intercept"))~"bottom",
    to==from ~ "right",
    !is.na(curvature)~"left",
    T ~ "right")}) |> 
  plot_happy_arrows()
```


# Discussion {.unnumbered}

How does word recognition change across early childhood and how does it relate to language learning? We investigated these questions using a new, large-scale dataset of developmental eye-tracking measurements compiled across many prior studies. The age gradients for speed and accuracy indicated that both improve asymptotically. Gradients for recognition speed were consistent with the log-log relationship associated with the "power law of practice," that is, with a gradual convergence to mature levels of processing efficiency. Further, the age gradient suggested that trial-to-trial variability decreases with age, consistent with both the literature on skill learning [@todorov2002optimal] and other work on developmental changes in variability [@judd2021working;@galeano2018variability;@kautto2023introducing]. Speed and accuracy were both related to vocabulary size concurrently and processing speed was also related longitudinally to later vocabulary growth. 

Together, our findings are consistent with theories that posit that language learning is a process of skill acquisition, in which children become adept at quickly converting ephemeral signals into meaning [@christiansen2016]. This skill develops gradually over the course of early childhood and supports word learning. Further, our results point to consistency between skill development in early childhood and the continued refinement of language processing and language knowledge during middle childhood [@mcmurray2022slow;@colby2023efficiency].

By aggregating data from many pre-existing studies, we were able to overcome the limitations of prior investigations, which typically had sample sizes at least an order of magnitude smaller than ours. Our approach was to build on the time-consuming and meticulous data collection from previous infant and toddler eye-tracking studies -- representing cumulatively many thousands of hours of in-lab data collection and hand-annotation of the resulting videos of child looking behavior -- by harmonizing these data into a single, large-scale database. This approach illustrates how building harmonized databases can be especially powerful when composed of high-effort and high-quality datasets that are smaller in scope, maximizing the impact of previous data collection efforts and allowing us to ask broader questions about developmental change [@frank2021]. In contrast to individual studies, which typically have at best the statistical power to test one or two specific contrasts, our "big data" approach provided the sample sizes necessary to explore the relationships between different variables. Because early language is so variable, these kinds of samples -- with thousands, rather than dozens of children -- are likely to be required to gain further insight into the psychometrics of early language learning [@bergelson2023;@frank2021;@manybabies2020]. 

Our approach is both observational and exploratory. Thus, we cannot untangle the range of different causal models that explain the variation we observed. First, early word recognition skill could lead to faster word learning, but faster children could also be faster due to their larger vocabulary and stronger lexical representations. These two causal directions could also interact reciprocally, leading to a "rich get richer" process in which children with larger vocabularies process faster, and their faster processing helps them increase their vocabulary size more rapidly. Finally, a third shared factor -- perhaps general cognitive ability -- could underpin both processes. Our cross-sectional data cannot distinguish these hypotheses even in principle [@vanderweele2023dimensional], and our longitudinal data are likely too sparse to distinguish such complex causal models. Future work must also explore how the functional forms we observed here between individuals reflect processes of within-person change. Although the Peekbank dataset includes a variety of longitudinal data, most reflect a small number of measurements; denser longitudinal data collection is required to better estimate within-person growth models. 

The consistency of the trends we observed across datasets suggests that our qualitative conclusions are robust to some significant cross-laboratory and cross-sociodemographic variation. Nevertheless, these findings are still limited in their generalizability by the convenience samples that were used in most of the studies aggregated in Peekbank. These studies typically (but not always) represent children from well-educated parents living in university-adjacent communities. We would not expect that specific numerical parameters estimated in our aggregate convenience sample would generalize to other samples. 

More broadly, our results here suggest the continued importance of the looking-while-listening paradigm as an index of children's language processing abilities. If language learning is, at least in part, a process of skill learning, then measurement of this skill in larger samples provides a critical window into understanding the remarkable process of language learning.

# Materials and Methods {.unnumbered}

## Data {.unnumbered}

We included information from `r length(unique(d_sub$subject_id))` unique participants across `r length(unique(d_sub$dataset_name))` datasets. Dataset information is given in Table \ref{tab:datasets}. Although experiments in Peekbank include a variety of different experimental manipulations, we analyzed only data from simple word recognition trials; these trials were sometimes the main focus of the original studies and sometimes constituted control conditions for experiments with more complex manipulations. We focus here on English purely for practical reasons -- the Peekbank dataset at present contains limited data from other languages.

We excluded trials entirely if they were missing data on more than 50% of timepoints, and excluded RTs if they were based on fewer than 50% of timepoints in the short analytic window (200 -- 2000 ms). We also removed RTs shorter than 367 ms, as these were unlikely to be generated based on the specific linguistic stimulus. We then excluded participants from the analysis if they contributed fewer than four accuracy measurements or fewer than two reaction time measurements. At the participant level, these steps together led to `r round(mean(is.na(d_sub$rt)), 3)*100`% missingness for RTs and `r round(mean(is.na(d_sub$long_window_accuracy)), 3)*100`% missingness for long window accuracies.

## Analytic methods {.unnumbered}

We used `lme4` to fit linear mixed-effects models, `brms` to fit non-linear growth models, and `lavaan` to fit structural equation models. Random effects structures for each model are given in text; full model specifications are available in the Supplemental Information and in the reproducible code for this paper, available in the linked repository. To aid interpretability, all variables were standardized (z-scored) prior to inclusion in structural equation models. 

## Code and Data Availability {.unnumbered}

We retrieved all data from Peekbank release 2025.1 using the `peekbankr` package.  All code and data necessary to reproduce this manuscript are available at [http://github.com/peekbank/peekbank-development](). 

<!-- Leave these lines as they are at the end of your .Rmd file to ensure placement of methods & acknowledgements sections before the references-->
<!--\showmatmethods
\showacknow
\pnasbreak

\newpage -->
\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
